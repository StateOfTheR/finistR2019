19/08/28 14:34:35 INFO SparkContext: Running Spark version 2.2.0
19/08/28 14:34:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 14:34:35 INFO SparkContext: Submitted application: sparklyr
19/08/28 14:34:36 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 14:34:36 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 14:34:36 INFO SecurityManager: Changing view acls groups to: 
19/08/28 14:34:36 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 14:34:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 14:34:36 INFO Utils: Successfully started service 'sparkDriver' on port 57675.
19/08/28 14:34:36 INFO SparkEnv: Registering MapOutputTracker
19/08/28 14:34:36 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 14:34:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 14:34:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 14:34:36 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-b5c98537-c993-485e-bec3-b6daa9312ac7
19/08/28 14:34:36 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 14:34:36 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 14:34:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 14:34:36 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 14:34:36 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 14:34:36 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:57675/jars/sparklyr-2.0-2.11.jar with timestamp 1566995676969
19/08/28 14:34:37 INFO Executor: Starting executor ID driver on host localhost
19/08/28 14:34:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57696.
19/08/28 14:34:37 INFO NettyBlockTransferService: Server created on 127.0.0.1:57696
19/08/28 14:34:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 14:34:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57696, None)
19/08/28 14:34:37 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57696 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 57696, None)
19/08/28 14:34:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57696, None)
19/08/28 14:34:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57696, None)
19/08/28 14:34:37 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 14:34:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 14:34:37 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 14:34:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 14:34:39 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 14:34:39 INFO ObjectStore: ObjectStore, initialize called
19/08/28 14:34:39 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 14:34:39 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 14:34:40 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 14:34:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:34:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:34:42 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:34:42 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:34:42 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 14:34:42 INFO ObjectStore: Initialized ObjectStore
19/08/28 14:34:42 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 14:34:42 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 14:34:43 INFO HiveMetaStore: Added admin role in metastore
19/08/28 14:34:43 INFO HiveMetaStore: Added public role in metastore
19/08/28 14:34:43 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 14:34:43 INFO HiveMetaStore: 0: get_all_databases
19/08/28 14:34:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 14:34:43 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 14:34:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 14:34:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:34:43 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/6ee3a49f-818a-47fb-a7bd-541c0c84698e_resources
19/08/28 14:34:43 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/6ee3a49f-818a-47fb-a7bd-541c0c84698e
19/08/28 14:34:43 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/6ee3a49f-818a-47fb-a7bd-541c0c84698e
19/08/28 14:34:43 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/6ee3a49f-818a-47fb-a7bd-541c0c84698e/_tmp_space.db
19/08/28 14:34:43 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:34:43 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:43 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 14:34:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 14:34:43 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 14:34:43 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/51612830-83fd-43ae-8f46-0b1d3c67f83a_resources
19/08/28 14:34:43 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/51612830-83fd-43ae-8f46-0b1d3c67f83a
19/08/28 14:34:43 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/51612830-83fd-43ae-8f46-0b1d3c67f83a
19/08/28 14:34:44 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/51612830-83fd-43ae-8f46-0b1d3c67f83a/_tmp_space.db
19/08/28 14:34:44 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:34:44 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 14:34:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:34:46 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:46 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:34:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:34:46 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:34:46 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:34:46 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 14:34:46 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:34:46 INFO DAGScheduler: Missing parents: List()
19/08/28 14:34:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 14:34:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 14:34:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 14:34:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57696 (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:34:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 14:34:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 14:34:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 14:34:46 INFO Executor: Fetching spark://127.0.0.1:57675/jars/sparklyr-2.0-2.11.jar with timestamp 1566995676969
19/08/28 14:34:47 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57675 after 19 ms (0 ms spent in bootstraps)
19/08/28 14:34:47 INFO Utils: Fetching spark://127.0.0.1:57675/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e\fetchFileTemp6296942014112459723.tmp
19/08/28 14:34:47 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7/userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e/sparklyr-2.0-2.11.jar to class loader
19/08/28 14:34:47 INFO CodeGenerator: Code generated in 193.574249 ms
19/08/28 14:34:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/08/28 14:34:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 715 ms on localhost (executor driver) (1/1)
19/08/28 14:34:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 14:34:47 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,737 s
19/08/28 14:34:47 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,942304 s
19/08/28 14:34:47 INFO SparkSqlParser: Parsing command: iris
19/08/28 14:34:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 14:34:47 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 19.203355 ms
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 8.870105 ms
19/08/28 14:34:48 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:34:48 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 14:34:48 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:34:48 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 14:34:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 14:34:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 14:34:48 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57696 (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 14:34:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:34:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 12.909816 ms
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 42.975192 ms
19/08/28 14:34:48 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:57696 (size: 5.6 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 6.734878 ms
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 23.251429 ms
19/08/28 14:34:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/08/28 14:34:48 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 14:34:48 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 14:34:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 355 ms on localhost (executor driver) (1/1)
19/08/28 14:34:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 14:34:48 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,357 s
19/08/28 14:34:48 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:34:48 INFO DAGScheduler: running: Set()
19/08/28 14:34:48 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 14:34:48 INFO DAGScheduler: failed: Set()
19/08/28 14:34:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 14:34:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:34:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 14:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 144 ms
19/08/28 14:34:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:57696 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57696 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1667 bytes result sent to driver
19/08/28 14:34:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 179 ms on localhost (executor driver) (1/1)
19/08/28 14:34:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 14:34:48 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,180 s
19/08/28 14:34:48 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,592930 s
19/08/28 14:34:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 14:34:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:34:48 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 14:34:48 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:34:48 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 14:34:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 14:34:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 14:34:48 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57696 (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 14:34:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:34:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 14:34:48 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:34:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/08/28 14:34:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:34:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 14:34:48 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,018 s
19/08/28 14:34:48 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:34:48 INFO DAGScheduler: running: Set()
19/08/28 14:34:48 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 14:34:48 INFO DAGScheduler: failed: Set()
19/08/28 14:34:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:34:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:34:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:34:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 14:34:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:34:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 14:34:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:34:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:34:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/08/28 14:34:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:34:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 14:34:48 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,008 s
19/08/28 14:34:48 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,056443 s
19/08/28 14:34:48 INFO CodeGenerator: Code generated in 8.889492 ms
19/08/28 14:34:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 14:34:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:34:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:34:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:34:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:34:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:34:49 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:34:49 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 14:34:49 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:34:49 INFO DAGScheduler: Missing parents: List()
19/08/28 14:34:49 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 14:34:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 14:34:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 14:34:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57696 (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:34:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:49 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 14:34:49 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:34:49 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 14:34:49 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:34:49 INFO CodeGenerator: Code generated in 47.797603 ms
19/08/28 14:34:49 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 14:34:49 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1398 bytes result sent to driver
19/08/28 14:34:49 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 107 ms on localhost (executor driver) (1/1)
19/08/28 14:34:49 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,108 s
19/08/28 14:34:49 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 14:34:49 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,122051 s
19/08/28 14:34:49 INFO CodeGenerator: Code generated in 10.764706 ms
19/08/28 14:34:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:34:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:34:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:34:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:34:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:34:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:34:50 INFO CodeGenerator: Code generated in 6.006157 ms
19/08/28 14:34:50 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:34:50 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:34:50 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 14:34:50 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:34:50 INFO DAGScheduler: Missing parents: List()
19/08/28 14:34:50 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 14:34:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 14:34:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 14:34:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57696 (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:34:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 14:34:50 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:34:50 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 14:34:50 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 934 bytes result sent to driver
19/08/28 14:34:50 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on localhost (executor driver) (1/1)
19/08/28 14:34:50 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 14:34:50 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,017 s
19/08/28 14:34:50 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,027320 s
19/08/28 14:34:58 INFO SparkSqlParser: Parsing command: flights
19/08/28 14:34:58 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 14:34:58 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 14:34:59 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:34:59 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 14:34:59 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:34:59 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 14:34:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 14:34:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 14:34:59 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 14:34:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 14:34:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 14:34:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57696 (size: 11.7 KB, free: 912.3 MB)
19/08/28 14:34:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 14:34:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:34:59 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 14:34:59 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:34:59 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:34:59 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 14:35:00 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 14:35:00 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57696 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 14:35:00 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 14:35:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57696 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:35:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57696 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 14:35:00 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 14:35:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 14:35:00 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 14:35:00 INFO CodeGenerator: Code generated in 19.309413 ms
19/08/28 14:35:00 INFO CodeGenerator: Code generated in 104.661082 ms
19/08/28 14:35:09 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 14:35:09 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:57696 (size: 22.5 MB, free: 889.8 MB)
19/08/28 14:35:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 14:35:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10673 ms on localhost (executor driver) (1/1)
19/08/28 14:35:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 14:35:09 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 10,675 s
19/08/28 14:35:09 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:09 INFO DAGScheduler: running: Set()
19/08/28 14:35:09 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 14:35:09 INFO DAGScheduler: failed: Set()
19/08/28 14:35:09 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 14:35:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:35:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:35:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:35:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 14:35:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 14:35:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1538 bytes result sent to driver
19/08/28 14:35:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (executor driver) (1/1)
19/08/28 14:35:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 14:35:09 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,018 s
19/08/28 14:35:09 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 10,755689 s
19/08/28 14:35:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 14:35:09 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:10 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:10 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 14:35:10 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:35:10 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 14:35:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 14:35:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 14:35:10 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 14:35:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 14:35:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57696 (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:35:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:10 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 14:35:10 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 14:35:10 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:35:11 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:35:11 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 14:35:11 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:35:11 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 14:35:11 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 1536 ms on localhost (executor driver) (1/1)
19/08/28 14:35:11 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 14:35:11 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 1,538 s
19/08/28 14:35:11 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:11 INFO DAGScheduler: running: Set()
19/08/28 14:35:11 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 14:35:11 INFO DAGScheduler: failed: Set()
19/08/28 14:35:11 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:35:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:35:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:35:11 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:11 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 14:35:11 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:11 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 14:35:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:35:11 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1538 bytes result sent to driver
19/08/28 14:35:11 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 20 ms on localhost (executor driver) (1/1)
19/08/28 14:35:11 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 14:35:11 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,026 s
19/08/28 14:35:11 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 1,608282 s
19/08/28 14:35:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 14:35:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:35:12 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:12 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:12 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:12 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:35:12 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:35:12 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:35:12 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 14:35:12 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 14:35:12 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:12 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:12 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 14:35:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 14:35:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 14:35:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57696 (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:35:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 14:35:12 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 14:35:12 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:12 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:12 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 14:35:12 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 14:35:12 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 934 bytes result sent to driver
19/08/28 14:35:12 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 17 ms on localhost (executor driver) (1/2)
19/08/28 14:35:12 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 980 bytes result sent to driver
19/08/28 14:35:12 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 26 ms on localhost (executor driver) (2/2)
19/08/28 14:35:12 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 14:35:12 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,027 s
19/08/28 14:35:12 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,049555 s
19/08/28 14:35:18 INFO SparkSqlParser: Parsing command: batting
19/08/28 14:35:18 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 14:35:18 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 14:35:18 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:35:18 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 14:35:18 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:35:18 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 14:35:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 14:35:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 14:35:18 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 14:35:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.7 MB)
19/08/28 14:35:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 14:35:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57696 (size: 11.6 KB, free: 889.8 MB)
19/08/28 14:35:18 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:18 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 14:35:18 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:18 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:35:18 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 14:35:18 INFO CodeGenerator: Code generated in 15.997284 ms
19/08/28 14:35:18 INFO CodeGenerator: Code generated in 176.156774 ms
19/08/28 14:35:19 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 14:35:19 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 14:35:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57696 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:35:19 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:35:20 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 14:35:20 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:57696 (size: 3.4 MB, free: 886.4 MB)
19/08/28 14:35:20 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 14:35:20 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 2633 ms on localhost (executor driver) (1/1)
19/08/28 14:35:20 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 14:35:20 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 2,649 s
19/08/28 14:35:20 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:20 INFO DAGScheduler: running: Set()
19/08/28 14:35:20 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 14:35:20 INFO DAGScheduler: failed: Set()
19/08/28 14:35:20 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 14:35:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:35:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:35:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:35:20 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:20 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 14:35:20 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:20 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 14:35:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:20 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1495 bytes result sent to driver
19/08/28 14:35:20 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:35:20 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,014 s
19/08/28 14:35:20 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 14:35:20 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 2,796022 s
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 14:35:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:21 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 14:35:21 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:35:21 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 14:35:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 14:35:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 14:35:21 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.2 MB)
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.2 MB)
19/08/28 14:35:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57696 (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:35:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:21 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 14:35:21 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:21 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:35:21 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 14:35:21 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 14:35:21 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1647 bytes result sent to driver
19/08/28 14:35:21 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 97 ms on localhost (executor driver) (1/1)
19/08/28 14:35:21 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,098 s
19/08/28 14:35:21 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:21 INFO DAGScheduler: running: Set()
19/08/28 14:35:21 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 14:35:21 INFO DAGScheduler: failed: Set()
19/08/28 14:35:21 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.2 MB)
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.2 MB)
19/08/28 14:35:21 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 14:35:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 14:35:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:21 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 14:35:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:21 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1495 bytes result sent to driver
19/08/28 14:35:21 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
19/08/28 14:35:21 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,006 s
19/08/28 14:35:21 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 14:35:21 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,133306 s
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:35:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:35:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:35:21 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:35:21 INFO DAGScheduler: Got job 10 (collect at utils.scala:44) with 3 output partitions
19/08/28 14:35:21 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:44)
19/08/28 14:35:21 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:21 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:21 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[72] at map at utils.scala:41), which has no missing parents
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.4 KB, free 886.2 MB)
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.2 MB)
19/08/28 14:35:21 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57696 (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:35:21 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:21 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 16 (MapPartitionsRDD[72] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 14:35:21 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks
19/08/28 14:35:21 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:21 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:21 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:21 INFO Executor: Running task 1.0 in stage 16.0 (TID 18)
19/08/28 14:35:21 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 14:35:21 INFO Executor: Finished task 1.0 in stage 16.0 (TID 18). 894 bytes result sent to driver
19/08/28 14:35:21 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 894 bytes result sent to driver
19/08/28 14:35:21 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 18) in 7 ms on localhost (executor driver) (1/3)
19/08/28 14:35:21 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 9 ms on localhost (executor driver) (2/3)
19/08/28 14:35:21 INFO Executor: Running task 2.0 in stage 16.0 (TID 19)
19/08/28 14:35:21 INFO Executor: Finished task 2.0 in stage 16.0 (TID 19). 848 bytes result sent to driver
19/08/28 14:35:21 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 19) in 15 ms on localhost (executor driver) (3/3)
19/08/28 14:35:21 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:44) finished in 0,016 s
19/08/28 14:35:21 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 14:35:21 INFO DAGScheduler: Job 10 finished: collect at utils.scala:44, took 0,024779 s
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:35:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:35:21 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1272 - dep_delay.nullCount#1271) > 0)
19/08/28 14:35:21 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1270 <= 2.0) && (2.0 <= dep_delay.upperBound#1269))
19/08/28 14:35:21 INFO CodeGenerator: Code generated in 13.461774 ms
19/08/28 14:35:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:21 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:35:21 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:204)
19/08/28 14:35:21 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:21 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:21 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 34.7 KB, free 886.2 MB)
19/08/28 14:35:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 12.6 KB, free 886.2 MB)
19/08/28 14:35:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57696 (size: 12.6 KB, free: 886.3 MB)
19/08/28 14:35:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:21 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/08/28 14:35:21 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 14:35:21 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57696 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:35:21 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 14:35:21 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:21 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:35:21 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57696 in memory (size: 3.5 KB, free: 886.4 MB)
19/08/28 14:35:21 WARN TaskSetManager: Stage 17 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:21 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 14:35:21 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
19/08/28 14:35:22 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:35:22 INFO CodeGenerator: Code generated in 11.658406 ms
19/08/28 14:35:22 INFO CodeGenerator: Code generated in 18.673826 ms
19/08/28 14:35:22 INFO Executor: 1 block locks were not released by TID = 20:
[rdd_33_0]
19/08/28 14:35:22 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 2273 bytes result sent to driver
19/08/28 14:35:22 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 519 ms on localhost (executor driver) (1/1)
19/08/28 14:35:22 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:204) finished in 0,519 s
19/08/28 14:35:22 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 14:35:22 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0,535589 s
19/08/28 14:35:22 INFO CodeGenerator: Code generated in 17.660001 ms
19/08/28 14:35:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:35:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `aqrqummpyu`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `nbrveewiof`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `hwhyzuqsxr`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `wgxpyekfjc`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 31.093645 ms
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 48.726657 ms
19/08/28 14:35:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:23 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/08/28 14:35:23 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:35:23 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/08/28 14:35:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
19/08/28 14:35:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
19/08/28 14:35:23 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 50.3 KB, free 886.2 MB)
19/08/28 14:35:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.8 KB, free 886.2 MB)
19/08/28 14:35:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:57696 (size: 19.8 KB, free: 886.3 MB)
19/08/28 14:35:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:23 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 14:35:23 WARN TaskSetManager: Stage 18 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:23 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:35:23 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 14:35:23 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 13.92326 ms
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 6.109554 ms
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 8.236037 ms
19/08/28 14:35:23 INFO CodeGenerator: Code generated in 6.918484 ms
19/08/28 14:35:24 INFO CodeGenerator: Code generated in 9.578299 ms
19/08/28 14:35:24 INFO CodeGenerator: Code generated in 4.086467 ms
19/08/28 14:35:24 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57696 in memory (size: 11.8 KB, free: 886.3 MB)
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 228
19/08/28 14:35:24 INFO ContextCleaner: Cleaned shuffle 2
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 385
19/08/28 14:35:24 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:57696 in memory (size: 12.6 KB, free: 886.4 MB)
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 237
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 288
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 378
19/08/28 14:35:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:57696 in memory (size: 11.7 KB, free: 886.4 MB)
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 440
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 296
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 231
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 229
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 441
19/08/28 14:35:24 INFO ContextCleaner: Cleaned shuffle 4
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 438
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 236
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 298
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 446
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 232
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 447
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 226
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 439
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 227
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 295
19/08/28 14:35:24 INFO ContextCleaner: Cleaned shuffle 3
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 292
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 381
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 379
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 444
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 443
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 380
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 291
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 445
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 234
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 287
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 383
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 294
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 386
19/08/28 14:35:24 INFO ContextCleaner: Cleaned shuffle 5
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 437
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 382
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 289
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 233
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 230
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 375
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 235
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 442
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 293
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 297
19/08/28 14:35:24 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:57696 in memory (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 436
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 376
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 377
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 290
19/08/28 14:35:24 INFO ContextCleaner: Cleaned accumulator 384
19/08/28 14:35:24 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1964 bytes result sent to driver
19/08/28 14:35:24 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 1137 ms on localhost (executor driver) (1/1)
19/08/28 14:35:24 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 14:35:24 INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:204) finished in 1,138 s
19/08/28 14:35:24 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:24 INFO DAGScheduler: running: Set()
19/08/28 14:35:24 INFO DAGScheduler: waiting: Set(ResultStage 19)
19/08/28 14:35:24 INFO DAGScheduler: failed: Set()
19/08/28 14:35:24 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:24 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 27.0 KB, free 886.3 MB)
19/08/28 14:35:24 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.3 MB)
19/08/28 14:35:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:57696 (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:35:24 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:24 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 14:35:24 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:24 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 14:35:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:24 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 22
19/08/28 14:35:24 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 2648 bytes result sent to driver
19/08/28 14:35:24 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 21 ms on localhost (executor driver) (1/1)
19/08/28 14:35:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 14:35:24 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0,022 s
19/08/28 14:35:24 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 1,183179 s
19/08/28 14:35:24 INFO CodeGenerator: Code generated in 9.16281 ms
19/08/28 14:35:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `hrbccwwpiw`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:35:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `dwzujegtre`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `artqizyggq`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:25 INFO DAGScheduler: Registering RDD 84 (collect at utils.scala:204)
19/08/28 14:35:25 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 4 output partitions
19/08/28 14:35:25 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/08/28 14:35:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 14:35:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 14:35:25 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[84] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:25 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 50.3 KB, free 886.2 MB)
19/08/28 14:35:25 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.0 KB, free 886.2 MB)
19/08/28 14:35:25 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:57696 (size: 20.0 KB, free: 886.4 MB)
19/08/28 14:35:25 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[84] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:25 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 14:35:25 WARN TaskSetManager: Stage 20 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:35:25 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:35:25 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 14:35:25 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:35:25 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 1921 bytes result sent to driver
19/08/28 14:35:25 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 479 ms on localhost (executor driver) (1/1)
19/08/28 14:35:25 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 14:35:25 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0,480 s
19/08/28 14:35:25 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:25 INFO DAGScheduler: running: Set()
19/08/28 14:35:25 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 14:35:25 INFO DAGScheduler: failed: Set()
19/08/28 14:35:25 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 27.2 KB, free 886.2 MB)
19/08/28 14:35:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.2 MB)
19/08/28 14:35:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:57696 (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:35:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:35:25 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/08/28 14:35:25 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:25 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 25, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 14:35:25 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 26, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 14:35:25 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 27, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 14:35:25 INFO Executor: Running task 2.0 in stage 21.0 (TID 26)
19/08/28 14:35:25 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 14:35:25 INFO Executor: Running task 1.0 in stage 21.0 (TID 25)
19/08/28 14:35:25 INFO Executor: Running task 3.0 in stage 21.0 (TID 27)
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:25 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 21599 bytes result sent to driver
19/08/28 14:35:25 INFO Executor: Finished task 3.0 in stage 21.0 (TID 27). 20885 bytes result sent to driver
19/08/28 14:35:25 INFO Executor: Finished task 2.0 in stage 21.0 (TID 26). 22659 bytes result sent to driver
19/08/28 14:35:25 INFO Executor: Finished task 1.0 in stage 21.0 (TID 25). 21818 bytes result sent to driver
19/08/28 14:35:25 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 42 ms on localhost (executor driver) (1/4)
19/08/28 14:35:25 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 27) in 42 ms on localhost (executor driver) (2/4)
19/08/28 14:35:25 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 25) in 43 ms on localhost (executor driver) (3/4)
19/08/28 14:35:25 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 26) in 42 ms on localhost (executor driver) (4/4)
19/08/28 14:35:25 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 14:35:25 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0,044 s
19/08/28 14:35:25 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0,541561 s
19/08/28 14:35:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:35:31 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:31 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:31 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:31 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:35:31 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:35:31 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:35:31 INFO DAGScheduler: Got job 14 (collect at utils.scala:44) with 3 output partitions
19/08/28 14:35:31 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:44)
19/08/28 14:35:31 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:31 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:31 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[92] at map at utils.scala:41), which has no missing parents
19/08/28 14:35:31 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 6.4 KB, free 886.2 MB)
19/08/28 14:35:31 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.2 MB)
19/08/28 14:35:31 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:57696 (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:35:31 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:31 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 22 (MapPartitionsRDD[92] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 14:35:31 INFO TaskSchedulerImpl: Adding task set 22.0 with 3 tasks
19/08/28 14:35:31 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:31 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:31 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:35:31 INFO Executor: Running task 1.0 in stage 22.0 (TID 29)
19/08/28 14:35:31 INFO Executor: Running task 2.0 in stage 22.0 (TID 30)
19/08/28 14:35:31 INFO Executor: Finished task 1.0 in stage 22.0 (TID 29). 937 bytes result sent to driver
19/08/28 14:35:31 INFO Executor: Running task 0.0 in stage 22.0 (TID 28)
19/08/28 14:35:31 INFO Executor: Finished task 0.0 in stage 22.0 (TID 28). 894 bytes result sent to driver
19/08/28 14:35:31 INFO Executor: Finished task 2.0 in stage 22.0 (TID 30). 891 bytes result sent to driver
19/08/28 14:35:31 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 29) in 66 ms on localhost (executor driver) (1/3)
19/08/28 14:35:31 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 28) in 68 ms on localhost (executor driver) (2/3)
19/08/28 14:35:31 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 30) in 68 ms on localhost (executor driver) (3/3)
19/08/28 14:35:31 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:44) finished in 0,070 s
19/08/28 14:35:31 INFO DAGScheduler: Job 14 finished: collect at utils.scala:44, took 0,089033 s
19/08/28 14:35:31 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 14:35:31 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 14:35:32 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:35:32 INFO DAGScheduler: Registering RDD 100 (sql at <unknown>:0)
19/08/28 14:35:32 INFO DAGScheduler: Got job 15 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:35:32 INFO DAGScheduler: Final stage: ResultStage 24 (sql at <unknown>:0)
19/08/28 14:35:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/08/28 14:35:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/08/28 14:35:32 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[100] at sql at <unknown>:0), which has no missing parents
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 22.4 KB, free 886.2 MB)
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.4 KB, free 886.1 MB)
19/08/28 14:35:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:57696 (size: 9.4 KB, free: 886.3 MB)
19/08/28 14:35:32 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[100] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:32 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 14:35:32 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:35:32 INFO Executor: Running task 0.0 in stage 23.0 (TID 31)
19/08/28 14:35:32 INFO CodeGenerator: Code generated in 20.285224 ms
19/08/28 14:35:32 INFO CodeGenerator: Code generated in 75.88703 ms
19/08/28 14:35:32 INFO MemoryStore: Block rdd_97_0 stored as values in memory (estimated size 4.2 KB, free 886.1 MB)
19/08/28 14:35:32 INFO BlockManagerInfo: Added rdd_97_0 in memory on 127.0.0.1:57696 (size: 4.2 KB, free: 886.3 MB)
19/08/28 14:35:32 INFO Executor: Finished task 0.0 in stage 23.0 (TID 31). 2328 bytes result sent to driver
19/08/28 14:35:32 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 31) in 167 ms on localhost (executor driver) (1/1)
19/08/28 14:35:32 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 14:35:32 INFO DAGScheduler: ShuffleMapStage 23 (sql at <unknown>:0) finished in 0,169 s
19/08/28 14:35:32 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:32 INFO DAGScheduler: running: Set()
19/08/28 14:35:32 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/08/28 14:35:32 INFO DAGScheduler: failed: Set()
19/08/28 14:35:32 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at sql at <unknown>:0), which has no missing parents
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 886.1 MB)
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.1 MB)
19/08/28 14:35:32 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:32 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:32 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/08/28 14:35:32 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 32, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:32 INFO Executor: Running task 0.0 in stage 24.0 (TID 32)
19/08/28 14:35:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:32 INFO Executor: Finished task 0.0 in stage 24.0 (TID 32). 1538 bytes result sent to driver
19/08/28 14:35:32 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 32) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:35:32 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 14:35:32 INFO DAGScheduler: ResultStage 24 (sql at <unknown>:0) finished in 0,018 s
19/08/28 14:35:32 INFO DAGScheduler: Job 15 finished: sql at <unknown>:0, took 0,243706 s
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 14:35:32 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:35:32 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:35:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:35:32 INFO DAGScheduler: Registering RDD 106 (collect at utils.scala:204)
19/08/28 14:35:32 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:35:32 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:204)
19/08/28 14:35:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
19/08/28 14:35:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
19/08/28 14:35:32 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 22.4 KB, free 886.1 MB)
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.4 KB, free 886.1 MB)
19/08/28 14:35:32 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:57696 (size: 9.4 KB, free: 886.3 MB)
19/08/28 14:35:32 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:32 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 14:35:32 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:35:32 INFO Executor: Running task 0.0 in stage 25.0 (TID 33)
19/08/28 14:35:32 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:32 INFO Executor: Finished task 0.0 in stage 25.0 (TID 33). 1647 bytes result sent to driver
19/08/28 14:35:32 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 33) in 22 ms on localhost (executor driver) (1/1)
19/08/28 14:35:32 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 14:35:32 INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:204) finished in 0,024 s
19/08/28 14:35:32 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:32 INFO DAGScheduler: running: Set()
19/08/28 14:35:32 INFO DAGScheduler: waiting: Set(ResultStage 26)
19/08/28 14:35:32 INFO DAGScheduler: failed: Set()
19/08/28 14:35:32 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 886.1 MB)
19/08/28 14:35:32 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.1 MB)
19/08/28 14:35:32 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:32 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:32 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 14:35:32 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:32 INFO Executor: Running task 0.0 in stage 26.0 (TID 34)
19/08/28 14:35:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:35:32 INFO Executor: Finished task 0.0 in stage 26.0 (TID 34). 1495 bytes result sent to driver
19/08/28 14:35:32 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 34) in 8 ms on localhost (executor driver) (1/1)
19/08/28 14:35:32 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 14:35:32 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:204) finished in 0,009 s
19/08/28 14:35:32 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0,060947 s
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz4`
WHERE (0 = 1)
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: sparklyr_tmp_750263145f4
19/08/28 14:35:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_750263145f4` AS `zzz5`
WHERE (0 = 1)
19/08/28 14:35:33 INFO SparkSqlParser: Parsing command: sparklyr_tmp_750328d4f88
19/08/28 14:35:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_750328d4f88` AS `zzz6`
WHERE (0 = 1)
19/08/28 14:35:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_750263145f4`
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 702
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 703
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 709
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:57696 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 708
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 711
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 610
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 701
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:57696 in memory (size: 9.4 KB, free: 886.3 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 705
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:57696 in memory (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 760
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 699
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:57696 in memory (size: 20.0 KB, free: 886.4 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 706
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:57696 in memory (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 707
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:57696 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 700
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 14:35:34 INFO ContextCleaner: Cleaned shuffle 7
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 710
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 704
19/08/28 14:35:34 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 14:35:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:57696 in memory (size: 9.4 KB, free: 886.4 MB)
19/08/28 14:35:34 INFO ContextCleaner: Cleaned shuffle 8
19/08/28 14:35:34 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2085 - hp.nullCount#2084) > 0)
19/08/28 14:35:34 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2082)
19/08/28 14:35:34 INFO CodeGenerator: Code generated in 65.013985 ms
19/08/28 14:35:35 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 14:35:35 INFO DAGScheduler: Got job 17 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 14:35:35 INFO DAGScheduler: Final stage: ResultStage 27 (first at LinearRegression.scala:198)
19/08/28 14:35:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:35 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 41.3 KB, free 886.3 MB)
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 16.4 KB, free 886.3 MB)
19/08/28 14:35:35 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:57696 (size: 16.4 KB, free: 886.4 MB)
19/08/28 14:35:35 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:35 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 14:35:35 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:35:35 INFO Executor: Running task 0.0 in stage 27.0 (TID 35)
19/08/28 14:35:35 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 16.455729 ms
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 21.699332 ms
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 39.303833 ms
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 12.994966 ms
19/08/28 14:35:35 INFO Executor: Finished task 0.0 in stage 27.0 (TID 35). 1743 bytes result sent to driver
19/08/28 14:35:35 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 35) in 225 ms on localhost (executor driver) (1/1)
19/08/28 14:35:35 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 14:35:35 INFO DAGScheduler: ResultStage 27 (first at LinearRegression.scala:198) finished in 0,225 s
19/08/28 14:35:35 INFO DAGScheduler: Job 17 finished: first at LinearRegression.scala:198, took 0,238614 s
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 9.16167 ms
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2146 - hp.nullCount#2145) > 0)
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2143)
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 32.728992 ms
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2202 - hp.nullCount#2201) > 0)
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2199)
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 35.752978 ms
19/08/28 14:35:35 INFO Instrumentation: LinearRegression-linear_regression_750129b74d7-898865567-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 14:35:35 INFO Instrumentation: LinearRegression-linear_regression_750129b74d7-898865567-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 14:35:35 INFO Instrumentation: LinearRegression-linear_regression_750129b74d7-898865567-1: {"numFeatures":2}
19/08/28 14:35:35 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 14:35:35 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 14:35:35 INFO DAGScheduler: Got job 18 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 14:35:35 INFO DAGScheduler: Final stage: ResultStage 28 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 14:35:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:35 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[122] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 44.1 KB, free 886.2 MB)
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 17.6 KB, free 886.2 MB)
19/08/28 14:35:35 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:57696 (size: 17.6 KB, free: 886.3 MB)
19/08/28 14:35:35 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[122] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:35 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 14:35:35 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:35:35 INFO Executor: Running task 0.0 in stage 28.0 (TID 36)
19/08/28 14:35:35 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 5.76553 ms
19/08/28 14:35:35 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 14:35:35 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 14:35:35 INFO Executor: Finished task 0.0 in stage 28.0 (TID 36). 2141 bytes result sent to driver
19/08/28 14:35:35 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 36) in 36 ms on localhost (executor driver) (1/1)
19/08/28 14:35:35 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 14:35:35 INFO DAGScheduler: ResultStage 28 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,037 s
19/08/28 14:35:35 INFO DAGScheduler: Job 18 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,044155 s
19/08/28 14:35:35 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 14:35:35 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 14:35:35 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2279 - hp.nullCount#2278) > 0)
19/08/28 14:35:35 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2276)
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 23.229001 ms
19/08/28 14:35:35 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 14:35:35 INFO DAGScheduler: Got job 19 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 14:35:35 INFO DAGScheduler: Final stage: ResultStage 29 (aggregate at RegressionMetrics.scala:57)
19/08/28 14:35:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:35 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[128] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 44.2 KB, free 886.2 MB)
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 17.9 KB, free 886.2 MB)
19/08/28 14:35:35 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:57696 (size: 17.9 KB, free: 886.3 MB)
19/08/28 14:35:35 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[128] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:35 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/08/28 14:35:35 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:35:35 INFO Executor: Running task 0.0 in stage 29.0 (TID 37)
19/08/28 14:35:35 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:35 INFO CodeGenerator: Code generated in 5.085467 ms
19/08/28 14:35:35 INFO Executor: Finished task 0.0 in stage 29.0 (TID 37). 2266 bytes result sent to driver
19/08/28 14:35:35 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 37) in 37 ms on localhost (executor driver) (1/1)
19/08/28 14:35:35 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 14:35:35 INFO DAGScheduler: ResultStage 29 (aggregate at RegressionMetrics.scala:57) finished in 0,037 s
19/08/28 14:35:35 INFO DAGScheduler: Job 19 finished: aggregate at RegressionMetrics.scala:57, took 0,044953 s
19/08/28 14:35:35 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 14:35:35 INFO DAGScheduler: Got job 20 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 14:35:35 INFO DAGScheduler: Final stage: ResultStage 30 (sum at RegressionMetrics.scala:71)
19/08/28 14:35:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:35 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[129] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 43.8 KB, free 886.1 MB)
19/08/28 14:35:35 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 17.8 KB, free 886.1 MB)
19/08/28 14:35:35 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:57696 (size: 17.8 KB, free: 886.3 MB)
19/08/28 14:35:35 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[129] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:35 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/08/28 14:35:35 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:35:35 INFO Executor: Running task 0.0 in stage 30.0 (TID 38)
19/08/28 14:35:35 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:35 INFO Executor: Finished task 0.0 in stage 30.0 (TID 38). 1654 bytes result sent to driver
19/08/28 14:35:35 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 38) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:35:35 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 14:35:35 INFO DAGScheduler: ResultStage 30 (sum at RegressionMetrics.scala:71) finished in 0,012 s
19/08/28 14:35:35 INFO DAGScheduler: Job 20 finished: sum at RegressionMetrics.scala:71, took 0,020706 s
19/08/28 14:35:36 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2354 - hp.nullCount#2353) > 0)
19/08/28 14:35:36 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2351)
19/08/28 14:35:36 INFO CodeGenerator: Code generated in 20.027491 ms
19/08/28 14:35:36 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 14:35:36 INFO DAGScheduler: Registering RDD 132 (count at LinearRegression.scala:696)
19/08/28 14:35:36 INFO DAGScheduler: Got job 21 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 14:35:36 INFO DAGScheduler: Final stage: ResultStage 32 (count at LinearRegression.scala:696)
19/08/28 14:35:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 14:35:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 14:35:36 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[132] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:35:36 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 36.6 KB, free 886.1 MB)
19/08/28 14:35:36 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.8 KB, free 886.0 MB)
19/08/28 14:35:36 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:57696 (size: 14.8 KB, free: 886.3 MB)
19/08/28 14:35:36 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[132] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:36 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 14:35:36 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:35:36 INFO Executor: Running task 0.0 in stage 31.0 (TID 39)
19/08/28 14:35:36 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:36 INFO Executor: Finished task 0.0 in stage 31.0 (TID 39). 2275 bytes result sent to driver
19/08/28 14:35:36 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 39) in 19 ms on localhost (executor driver) (1/1)
19/08/28 14:35:36 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 14:35:36 INFO DAGScheduler: ShuffleMapStage 31 (count at LinearRegression.scala:696) finished in 0,021 s
19/08/28 14:35:36 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:36 INFO DAGScheduler: running: Set()
19/08/28 14:35:36 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 14:35:36 INFO DAGScheduler: failed: Set()
19/08/28 14:35:36 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[135] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:35:36 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.0 KB, free 886.0 MB)
19/08/28 14:35:36 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.0 MB)
19/08/28 14:35:36 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:36 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[135] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:36 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 14:35:36 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 40, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:36 INFO Executor: Running task 0.0 in stage 32.0 (TID 40)
19/08/28 14:35:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:35:36 INFO Executor: Finished task 0.0 in stage 32.0 (TID 40). 1495 bytes result sent to driver
19/08/28 14:35:36 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
19/08/28 14:35:36 INFO DAGScheduler: ResultStage 32 (count at LinearRegression.scala:696) finished in 0,006 s
19/08/28 14:35:36 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 14:35:36 INFO DAGScheduler: Job 21 finished: count at LinearRegression.scala:696, took 0,046965 s
19/08/28 14:35:36 INFO Instrumentation: LinearRegression-linear_regression_750129b74d7-898865567-1: training finished
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_750a1a4ebe
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_750a1a4ebe` AS `zzz7`
WHERE (0 = 1)
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_750263145f4`
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_7503774171f
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_7503774171f` AS `zzz8`
WHERE (0 = 1)
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_7503774171f`
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: sparklyr_tmp_75058cf3238
19/08/28 14:35:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_75058cf3238` AS `zzz9`
WHERE (0 = 1)
19/08/28 14:35:37 INFO SparkSqlParser: Parsing command: sparklyr_tmp_7504c0e61d6
19/08/28 14:35:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_7504c0e61d6` AS `zzz10`
WHERE (0 = 1)
19/08/28 14:35:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_7504c0e61d6`
19/08/28 14:35:37 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2576 - hp.nullCount#2575) > 0)
19/08/28 14:35:37 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2573)
19/08/28 14:35:37 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 14:35:37 INFO DAGScheduler: Registering RDD 138 (count at <unknown>:0)
19/08/28 14:35:37 INFO DAGScheduler: Got job 22 (count at <unknown>:0) with 1 output partitions
19/08/28 14:35:37 INFO DAGScheduler: Final stage: ResultStage 34 (count at <unknown>:0)
19/08/28 14:35:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 14:35:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 14:35:37 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[138] at count at <unknown>:0), which has no missing parents
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 36.6 KB, free 886.0 MB)
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 14.8 KB, free 886.0 MB)
19/08/28 14:35:37 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:57696 (size: 14.8 KB, free: 886.3 MB)
19/08/28 14:35:37 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[138] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:37 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 14:35:37 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:35:37 INFO Executor: Running task 0.0 in stage 33.0 (TID 41)
19/08/28 14:35:37 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:37 INFO Executor: Finished task 0.0 in stage 33.0 (TID 41). 2275 bytes result sent to driver
19/08/28 14:35:37 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 41) in 68 ms on localhost (executor driver) (1/1)
19/08/28 14:35:37 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 14:35:37 INFO DAGScheduler: ShuffleMapStage 33 (count at <unknown>:0) finished in 0,073 s
19/08/28 14:35:37 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:35:37 INFO DAGScheduler: running: Set()
19/08/28 14:35:37 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 14:35:37 INFO DAGScheduler: failed: Set()
19/08/28 14:35:37 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[141] at count at <unknown>:0), which has no missing parents
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 7.0 KB, free 886.0 MB)
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.0 MB)
19/08/28 14:35:37 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:57696 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:35:37 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[141] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:37 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 14:35:37 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 42, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:35:37 INFO Executor: Running task 0.0 in stage 34.0 (TID 42)
19/08/28 14:35:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:35:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:35:37 INFO Executor: Finished task 0.0 in stage 34.0 (TID 42). 1538 bytes result sent to driver
19/08/28 14:35:37 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 42) in 32 ms on localhost (executor driver) (1/1)
19/08/28 14:35:37 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 14:35:37 INFO DAGScheduler: ResultStage 34 (count at <unknown>:0) finished in 0,033 s
19/08/28 14:35:37 INFO DAGScheduler: Job 22 finished: count at <unknown>:0, took 0,146944 s
19/08/28 14:35:37 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1670) generates partition filter: ((hp.count#2636 - hp.nullCount#2635) > 0)
19/08/28 14:35:37 INFO InMemoryTableScanExec: Predicate (hp#1670 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2633)
19/08/28 14:35:37 INFO CodeGenerator: Code generated in 70.070181 ms
19/08/28 14:35:37 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 14:35:37 INFO DAGScheduler: Got job 23 (collect at utils.scala:37) with 1 output partitions
19/08/28 14:35:37 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:37)
19/08/28 14:35:37 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:35:37 INFO DAGScheduler: Missing parents: List()
19/08/28 14:35:37 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[146] at map at utils.scala:34), which has no missing parents
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 50.2 KB, free 885.9 MB)
19/08/28 14:35:37 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.9 MB)
19/08/28 14:35:37 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:57696 (size: 19.3 KB, free: 886.3 MB)
19/08/28 14:35:37 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 14:35:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[146] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 14:35:37 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 14:35:37 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:35:37 INFO Executor: Running task 0.0 in stage 35.0 (TID 43)
19/08/28 14:35:37 INFO BlockManager: Found block rdd_97_0 locally
19/08/28 14:35:37 INFO CodeGenerator: Code generated in 13.261442 ms
19/08/28 14:35:37 INFO Executor: Finished task 0.0 in stage 35.0 (TID 43). 1747 bytes result sent to driver
19/08/28 14:35:37 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 43) in 55 ms on localhost (executor driver) (1/1)
19/08/28 14:35:37 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 14:35:37 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:37) finished in 0,056 s
19/08/28 14:35:37 INFO DAGScheduler: Job 23 finished: collect at utils.scala:37, took 0,076521 s
19/08/28 14:35:42 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 14:35:42 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 14:35:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 14:35:42 INFO MemoryStore: MemoryStore cleared
19/08/28 14:35:42 INFO BlockManager: BlockManager stopped
19/08/28 14:35:42 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 14:35:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 14:35:42 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:35:42 INFO SparkContext: Successfully stopped SparkContext
19/08/28 14:35:42 INFO ShutdownHookManager: Shutdown hook called
19/08/28 14:35:42 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7
19/08/28 14:35:42 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:35:42 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e
19/08/28 14:35:42 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d763ca2c-b953-4b74-af6b-9b39c9b7e7a7\userFiles-50be0c25-29ec-4d04-ac3c-dd36f2464d7e
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:44:24 INFO SparkContext: Running Spark version 2.2.0
19/08/28 14:44:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 14:44:24 INFO SparkContext: Submitted application: sparklyr
19/08/28 14:44:25 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 14:44:25 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 14:44:25 INFO SecurityManager: Changing view acls groups to: 
19/08/28 14:44:25 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 14:44:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 14:44:25 INFO Utils: Successfully started service 'sparkDriver' on port 57583.
19/08/28 14:44:25 INFO SparkEnv: Registering MapOutputTracker
19/08/28 14:44:25 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 14:44:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 14:44:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 14:44:25 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-bae5c056-ddb7-4863-962f-78197a1d84a5
19/08/28 14:44:25 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 14:44:25 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 14:44:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 14:44:25 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 14:44:25 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 14:44:25 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:57583/jars/sparklyr-2.0-2.11.jar with timestamp 1566996265930
19/08/28 14:44:26 INFO Executor: Starting executor ID driver on host localhost
19/08/28 14:44:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57605.
19/08/28 14:44:26 INFO NettyBlockTransferService: Server created on 127.0.0.1:57605
19/08/28 14:44:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 14:44:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57605, None)
19/08/28 14:44:26 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57605 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 57605, None)
19/08/28 14:44:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57605, None)
19/08/28 14:44:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57605, None)
19/08/28 14:44:26 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 14:44:26 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 14:44:26 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 14:44:27 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 14:44:28 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 14:44:28 INFO ObjectStore: ObjectStore, initialize called
19/08/28 14:44:28 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 14:44:28 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 14:44:30 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 14:44:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:44:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:44:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:44:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:44:32 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 14:44:32 INFO ObjectStore: Initialized ObjectStore
19/08/28 14:44:32 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 14:44:32 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 14:44:33 INFO HiveMetaStore: Added admin role in metastore
19/08/28 14:44:33 INFO HiveMetaStore: Added public role in metastore
19/08/28 14:44:33 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 14:44:33 INFO HiveMetaStore: 0: get_all_databases
19/08/28 14:44:33 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 14:44:33 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 14:44:33 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 14:44:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:44:33 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/d5ae3151-190e-4c61-960d-5083ce651292_resources
19/08/28 14:44:33 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/d5ae3151-190e-4c61-960d-5083ce651292
19/08/28 14:44:33 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/d5ae3151-190e-4c61-960d-5083ce651292
19/08/28 14:44:33 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/d5ae3151-190e-4c61-960d-5083ce651292/_tmp_space.db
19/08/28 14:44:33 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:44:33 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:33 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:33 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 14:44:33 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 14:44:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 14:44:33 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/a78b7a0c-7bb7-4962-bee2-dc821cea0a2b_resources
19/08/28 14:44:34 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/a78b7a0c-7bb7-4962-bee2-dc821cea0a2b
19/08/28 14:44:34 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/a78b7a0c-7bb7-4962-bee2-dc821cea0a2b
19/08/28 14:44:34 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/a78b7a0c-7bb7-4962-bee2-dc821cea0a2b/_tmp_space.db
19/08/28 14:44:34 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:44:34 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 14:44:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:44:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:44:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:44:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:44:36 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:44:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 14:44:36 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:44:36 INFO DAGScheduler: Missing parents: List()
19/08/28 14:44:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 14:44:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 14:44:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 14:44:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57605 (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:44:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 14:44:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 14:44:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 14:44:37 INFO Executor: Fetching spark://127.0.0.1:57583/jars/sparklyr-2.0-2.11.jar with timestamp 1566996265930
19/08/28 14:44:37 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57583 after 25 ms (0 ms spent in bootstraps)
19/08/28 14:44:37 INFO Utils: Fetching spark://127.0.0.1:57583/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9\fetchFileTemp5080017347301984230.tmp
19/08/28 14:44:37 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-d72e1574-9c58-48b9-9a58-33e8749df617/userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9/sparklyr-2.0-2.11.jar to class loader
19/08/28 14:44:37 INFO CodeGenerator: Code generated in 301.752734 ms
19/08/28 14:44:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/08/28 14:44:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 783 ms on localhost (executor driver) (1/1)
19/08/28 14:44:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 14:44:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,808 s
19/08/28 14:44:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1,012767 s
19/08/28 14:44:38 INFO SparkSqlParser: Parsing command: iris
19/08/28 14:44:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 14:44:38 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 19.730225 ms
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 12.009272 ms
19/08/28 14:44:38 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:44:38 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 14:44:38 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:44:38 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 14:44:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 14:44:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 14:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 14:44:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:44:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 14:44:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57605 (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:44:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 14:44:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:44:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 13.571253 ms
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 55.074176 ms
19/08/28 14:44:38 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 14:44:38 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:57605 (size: 5.6 KB, free: 912.3 MB)
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 5.575462 ms
19/08/28 14:44:38 INFO CodeGenerator: Code generated in 19.480095 ms
19/08/28 14:44:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/08/28 14:44:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 271 ms on localhost (executor driver) (1/1)
19/08/28 14:44:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 14:44:38 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,272 s
19/08/28 14:44:38 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:44:38 INFO DAGScheduler: running: Set()
19/08/28 14:44:38 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 14:44:38 INFO DAGScheduler: failed: Set()
19/08/28 14:44:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 14:44:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:44:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:44:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:44:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 14:44:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:44:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 14:44:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:44:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
19/08/28 14:44:39 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 14:44:39 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 14:44:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/08/28 14:44:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 195 ms on localhost (executor driver) (1/1)
19/08/28 14:44:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 14:44:39 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,196 s
19/08/28 14:44:39 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,533823 s
19/08/28 14:44:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:57605 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:44:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57605 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 14:44:39 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:39 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:44:39 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 14:44:39 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:44:39 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 14:44:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 14:44:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 14:44:39 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 14:44:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57605 (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:44:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 14:44:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:44:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 14:44:39 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:44:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1690 bytes result sent to driver
19/08/28 14:44:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 26 ms on localhost (executor driver) (1/1)
19/08/28 14:44:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 14:44:39 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,058 s
19/08/28 14:44:39 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:44:39 INFO DAGScheduler: running: Set()
19/08/28 14:44:39 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 14:44:39 INFO DAGScheduler: failed: Set()
19/08/28 14:44:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:44:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:44:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 14:44:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:44:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 14:44:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:44:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:44:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/08/28 14:44:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
19/08/28 14:44:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 14:44:39 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,008 s
19/08/28 14:44:39 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,094967 s
19/08/28 14:44:39 INFO CodeGenerator: Code generated in 9.173834 ms
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:44:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:44:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:44:39 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:44:39 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 14:44:39 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:44:39 INFO DAGScheduler: Missing parents: List()
19/08/28 14:44:39 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 14:44:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 14:44:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57605 (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:44:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 14:44:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:44:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 14:44:39 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:44:39 INFO CodeGenerator: Code generated in 40.221482 ms
19/08/28 14:44:39 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 14:44:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1398 bytes result sent to driver
19/08/28 14:44:39 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 84 ms on localhost (executor driver) (1/1)
19/08/28 14:44:39 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 14:44:39 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,085 s
19/08/28 14:44:39 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,102404 s
19/08/28 14:44:39 INFO CodeGenerator: Code generated in 18.023412 ms
19/08/28 14:44:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:44:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:44:40 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:40 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:40 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:44:40 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:44:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:44:40 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:44:40 INFO CodeGenerator: Code generated in 15.071272 ms
19/08/28 14:44:40 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:44:40 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:44:40 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 14:44:40 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:44:40 INFO DAGScheduler: Missing parents: List()
19/08/28 14:44:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 14:44:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 14:44:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 14:44:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57605 (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:44:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 14:44:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:44:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 14:44:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 891 bytes result sent to driver
19/08/28 14:44:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 14 ms on localhost (executor driver) (1/1)
19/08/28 14:44:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 14:44:40 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,016 s
19/08/28 14:44:40 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,026129 s
19/08/28 14:44:54 INFO SparkSqlParser: Parsing command: flights
19/08/28 14:44:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 14:44:54 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 14:44:54 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:44:54 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 14:44:54 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:44:54 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 14:44:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 14:44:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 14:44:54 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 14:44:54 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 14:44:54 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 14:44:54 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57605 (size: 11.7 KB, free: 912.3 MB)
19/08/28 14:44:54 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 14:44:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:44:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 14:44:54 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:44:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:44:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 14:44:55 INFO CodeGenerator: Code generated in 31.936408 ms
19/08/28 14:44:55 INFO CodeGenerator: Code generated in 230.132736 ms
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 14:44:58 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 14:44:58 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57605 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:44:58 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57605 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:44:58 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57605 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:44:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 14:44:58 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 14:44:58 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 14:44:58 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 14:45:04 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 14:45:04 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:57605 (size: 22.5 MB, free: 889.8 MB)
19/08/28 14:45:04 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 14:45:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10368 ms on localhost (executor driver) (1/1)
19/08/28 14:45:04 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 10,375 s
19/08/28 14:45:04 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:04 INFO DAGScheduler: running: Set()
19/08/28 14:45:04 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 14:45:04 INFO DAGScheduler: failed: Set()
19/08/28 14:45:04 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 14:45:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:45:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:45:04 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 14:45:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:45:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:04 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 14:45:04 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:04 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 14:45:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:45:04 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1538 bytes result sent to driver
19/08/28 14:45:04 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 35 ms on localhost (executor driver) (1/1)
19/08/28 14:45:04 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 14:45:04 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,039 s
19/08/28 14:45:04 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 10,438343 s
19/08/28 14:45:04 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 14:45:04 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:04 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:04 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:45:04 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 14:45:04 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:45:04 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 14:45:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 14:45:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 14:45:04 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 14:45:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 14:45:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57605 (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:45:04 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:04 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 14:45:05 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:45:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:45:05 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 14:45:05 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 14:45:05 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:45:05 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:45:05 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 14:45:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 924 ms on localhost (executor driver) (1/1)
19/08/28 14:45:05 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 14:45:05 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,938 s
19/08/28 14:45:05 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:05 INFO DAGScheduler: running: Set()
19/08/28 14:45:05 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 14:45:05 INFO DAGScheduler: failed: Set()
19/08/28 14:45:05 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:45:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:45:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:45:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:05 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 14:45:05 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:05 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 14:45:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:45:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1495 bytes result sent to driver
19/08/28 14:45:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
19/08/28 14:45:05 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 14:45:05 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,008 s
19/08/28 14:45:05 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,983016 s
19/08/28 14:45:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 14:45:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:45:06 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:06 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:06 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:06 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:45:06 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:45:07 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:45:07 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 14:45:07 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 14:45:07 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:07 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:07 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 14:45:07 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 14:45:07 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 14:45:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57605 (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:45:07 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 14:45:07 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 14:45:07 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:07 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:07 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 14:45:07 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 14:45:07 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 937 bytes result sent to driver
19/08/28 14:45:07 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 891 bytes result sent to driver
19/08/28 14:45:07 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 50 ms on localhost (executor driver) (1/2)
19/08/28 14:45:07 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 50 ms on localhost (executor driver) (2/2)
19/08/28 14:45:07 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 14:45:07 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,056 s
19/08/28 14:45:07 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,073229 s
19/08/28 14:45:11 INFO SparkSqlParser: Parsing command: batting
19/08/28 14:45:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 14:45:11 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 14:45:11 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:45:11 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 14:45:11 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:45:11 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 14:45:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 14:45:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 14:45:11 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 14:45:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.7 MB)
19/08/28 14:45:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 14:45:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57605 (size: 11.6 KB, free: 889.8 MB)
19/08/28 14:45:11 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:11 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 14:45:11 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:45:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:45:11 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 14:45:11 INFO CodeGenerator: Code generated in 41.864813 ms
19/08/28 14:45:11 INFO CodeGenerator: Code generated in 109.858688 ms
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 288
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 294
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 292
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 14:45:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57605 in memory (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:45:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 298
19/08/28 14:45:14 INFO ContextCleaner: Cleaned shuffle 3
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 290
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 296
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 289
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 287
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 293
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 297
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 291
19/08/28 14:45:14 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57605 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:45:14 INFO ContextCleaner: Cleaned accumulator 295
19/08/28 14:45:15 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 14:45:15 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:57605 (size: 3.4 MB, free: 886.4 MB)
19/08/28 14:45:15 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 14:45:15 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 3953 ms on localhost (executor driver) (1/1)
19/08/28 14:45:15 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 3,954 s
19/08/28 14:45:15 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:15 INFO DAGScheduler: running: Set()
19/08/28 14:45:15 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 14:45:15 INFO DAGScheduler: failed: Set()
19/08/28 14:45:15 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 14:45:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:45:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:45:15 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 14:45:15 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:45:15 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:15 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 14:45:15 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:15 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 14:45:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/08/28 14:45:15 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1581 bytes result sent to driver
19/08/28 14:45:15 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 29 ms on localhost (executor driver) (1/1)
19/08/28 14:45:15 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,032 s
19/08/28 14:45:15 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 4,138564 s
19/08/28 14:45:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 14:45:15 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:15 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:15 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 14:45:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:45:15 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 14:45:15 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:45:15 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 14:45:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 14:45:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 14:45:15 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.3 MB)
19/08/28 14:45:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.3 MB)
19/08/28 14:45:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57605 (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:45:15 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:15 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 14:45:15 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:45:15 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:45:15 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 14:45:16 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 14:45:16 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1733 bytes result sent to driver
19/08/28 14:45:16 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 310 ms on localhost (executor driver) (1/1)
19/08/28 14:45:16 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,313 s
19/08/28 14:45:16 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:16 INFO DAGScheduler: running: Set()
19/08/28 14:45:16 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 14:45:16 INFO DAGScheduler: failed: Set()
19/08/28 14:45:16 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:16 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 14:45:16 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:45:16 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:45:16 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:45:16 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:16 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 14:45:16 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:16 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 14:45:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:45:16 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1495 bytes result sent to driver
19/08/28 14:45:16 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 10 ms on localhost (executor driver) (1/1)
19/08/28 14:45:16 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 14:45:16 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,012 s
19/08/28 14:45:16 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,366221 s
19/08/28 14:45:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 14:45:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:45:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:45:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:45:17 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:45:17 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:45:17 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 14:45:17 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:17 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:17 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 14:45:17 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.2 MB)
19/08/28 14:45:17 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.1 MB)
19/08/28 14:45:17 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57605 (size: 34.7 KB, free: 886.3 MB)
19/08/28 14:45:17 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:17 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 14:45:17 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:45:17 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 14:45:17 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:45:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:45:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:45:17 INFO FileOutputCommitter: Saved output of task 'attempt_20190828144517_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/RtmpmoRkUZ/file3b0c37a44d1f.csv/_temporary/0/task_20190828144517_0016_m_000000
19/08/28 14:45:17 INFO SparkHadoopMapRedUtil: attempt_20190828144517_0016_m_000000_0: Committed
19/08/28 14:45:17 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 14:45:17 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 417 ms on localhost (executor driver) (1/1)
19/08/28 14:45:17 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 14:45:17 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,419 s
19/08/28 14:45:17 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,455858 s
19/08/28 14:45:17 INFO FileFormatWriter: Job null committed.
19/08/28 14:45:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:45:17 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:17 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:45:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:45:18 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:45:18 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 14:45:18 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 14:45:18 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:18 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:18 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 14:45:18 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.1 MB)
19/08/28 14:45:18 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.1 MB)
19/08/28 14:45:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57605 (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:45:18 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:18 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 14:45:18 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 14:45:18 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:18 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:18 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:18 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 14:45:18 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 937 bytes result sent to driver
19/08/28 14:45:18 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 14:45:18 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 894 bytes result sent to driver
19/08/28 14:45:18 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 14:45:18 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 28 ms on localhost (executor driver) (1/3)
19/08/28 14:45:18 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 31 ms on localhost (executor driver) (2/3)
19/08/28 14:45:18 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 891 bytes result sent to driver
19/08/28 14:45:18 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 35 ms on localhost (executor driver) (3/3)
19/08/28 14:45:18 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 14:45:18 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,042 s
19/08/28 14:45:18 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,060277 s
19/08/28 14:45:19 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:45:19 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 14:45:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:45:19 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:45:19 INFO CodeGenerator: Code generated in 12.841011 ms
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 885.8 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.8 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:57605 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 14:45:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:45:19 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:45:19 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:45:19 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 14:45:19 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:19 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:19 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 885.8 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 885.8 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:57605 (size: 4.3 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:19 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 14:45:19 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:45:19 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 14:45:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpmoRkUZ/file3b0c37a44d1f.csv/part-00000-e9df8844-35fd-4ec8-9e1b-5ff943466889-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:45:19 INFO CodeGenerator: Code generated in 8.844255 ms
19/08/28 14:45:19 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1265 bytes result sent to driver
19/08/28 14:45:19 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 66 ms on localhost (executor driver) (1/1)
19/08/28 14:45:19 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 14:45:19 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,066 s
19/08/28 14:45:19 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,088874 s
19/08/28 14:45:19 INFO CodeGenerator: Code generated in 7.765428 ms
19/08/28 14:45:19 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:45:19 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:45:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:45:19 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:45:19 INFO CodeGenerator: Code generated in 7.263648 ms
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.5 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.5 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:57605 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 14:45:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:45:19 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:45:19 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:45:19 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 14:45:19 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:19 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:19 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.5 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.5 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:57605 (size: 8.2 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:19 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 14:45:19 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:45:19 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 14:45:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpmoRkUZ/file3b0c37a44d1f.csv/part-00000-e9df8844-35fd-4ec8-9e1b-5ff943466889-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:45:19 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1495 bytes result sent to driver
19/08/28 14:45:19 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 52 ms on localhost (executor driver) (1/1)
19/08/28 14:45:19 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 14:45:19 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,052 s
19/08/28 14:45:19 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,064769 s
19/08/28 14:45:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:45:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:45:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:45:19 INFO CodeGenerator: Code generated in 10.372785 ms
19/08/28 14:45:19 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 14:45:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 14:45:19 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 14:45:19 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:45:19 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:45:19 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 14:45:19 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.2 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.2 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:57605 (size: 24.1 KB, free: 886.2 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 14:45:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:57605 in memory (size: 4.3 KB, free: 886.2 MB)
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:57605 in memory (size: 8.2 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 14:45:19 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:45:19 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 14:45:19 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:45:19 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 14:45:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 14:45:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 14:45:19 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.2 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.2 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:57605 in memory (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:57605 (size: 9.9 KB, free: 886.2 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:19 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 14:45:19 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:45:19 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57605 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpmoRkUZ/file3b0c37a44d1f.csv/part-00000-e9df8844-35fd-4ec8-9e1b-5ff943466889-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57605 in memory (size: 34.7 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:57605 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:57605 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 521
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 14:45:19 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 14:45:19 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57605 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 886.0 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:57605 (size: 5.6 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2418 bytes result sent to driver
19/08/28 14:45:19 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 78 ms on localhost (executor driver) (1/1)
19/08/28 14:45:19 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 14:45:19 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,079 s
19/08/28 14:45:19 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:19 INFO DAGScheduler: running: Set()
19/08/28 14:45:19 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 14:45:19 INFO DAGScheduler: failed: Set()
19/08/28 14:45:19 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 886.0 MB)
19/08/28 14:45:19 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.0 MB)
19/08/28 14:45:19 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:45:19 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:19 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 14:45:19 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:19 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 14:45:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:45:20 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1495 bytes result sent to driver
19/08/28 14:45:20 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
19/08/28 14:45:20 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 14:45:20 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,006 s
19/08/28 14:45:20 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,120640 s
19/08/28 14:45:20 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 14:45:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:45:20 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 14:45:20 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:45:20 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 14:45:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 14:45:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 14:45:20 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 886.0 MB)
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.9 MB)
19/08/28 14:45:20 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:57605 (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:45:20 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:20 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 14:45:20 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:45:20 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 14:45:20 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 14:45:20 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1737 bytes result sent to driver
19/08/28 14:45:20 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:45:20 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 14:45:20 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,018 s
19/08/28 14:45:20 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:45:20 INFO DAGScheduler: running: Set()
19/08/28 14:45:20 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 14:45:20 INFO DAGScheduler: failed: Set()
19/08/28 14:45:20 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 14:45:20 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:57605 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:45:20 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:45:20 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 14:45:20 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:45:20 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 14:45:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:45:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:45:20 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1495 bytes result sent to driver
19/08/28 14:45:20 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:45:20 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 14:45:20 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,007 s
19/08/28 14:45:20 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,049767 s
19/08/28 14:45:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 14:45:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:45:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:45:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:45:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:45:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:45:20 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:45:20 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 14:45:20 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 14:45:20 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:45:20 INFO DAGScheduler: Missing parents: List()
19/08/28 14:45:20 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.9 MB)
19/08/28 14:45:20 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.9 MB)
19/08/28 14:45:20 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:57605 (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:45:20 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 14:45:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:45:20 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 14:45:20 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:20 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:20 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:20 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:45:20 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 14:45:20 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 14:45:20 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 14:45:20 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 14:45:20 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 14:45:20 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 934 bytes result sent to driver
19/08/28 14:45:20 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 14:45:20 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 14 ms on localhost (executor driver) (1/4)
19/08/28 14:45:20 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 15 ms on localhost (executor driver) (2/4)
19/08/28 14:45:20 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 16 ms on localhost (executor driver) (3/4)
19/08/28 14:45:20 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 895 bytes result sent to driver
19/08/28 14:45:20 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 15 ms on localhost (executor driver) (4/4)
19/08/28 14:45:20 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 14:45:20 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,018 s
19/08/28 14:45:20 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,026423 s
19/08/28 14:45:22 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 14:45:22 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 14:45:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 14:45:22 INFO MemoryStore: MemoryStore cleared
19/08/28 14:45:22 INFO BlockManager: BlockManager stopped
19/08/28 14:45:22 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 14:45:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 14:45:22 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:45:22 INFO SparkContext: Successfully stopped SparkContext
19/08/28 14:45:22 INFO ShutdownHookManager: Shutdown hook called
19/08/28 14:45:22 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9
19/08/28 14:45:22 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617\userFiles-3a1445f4-a94d-462f-afc6-31b339adb6e9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:45:22 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617
19/08/28 14:45:22 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d72e1574-9c58-48b9-9a58-33e8749df617
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:49:32 INFO SparkContext: Running Spark version 2.2.0
19/08/28 14:49:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 14:49:33 INFO SparkContext: Submitted application: sparklyr
19/08/28 14:49:33 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 14:49:33 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 14:49:33 INFO SecurityManager: Changing view acls groups to: 
19/08/28 14:49:33 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 14:49:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 14:49:33 INFO Utils: Successfully started service 'sparkDriver' on port 57739.
19/08/28 14:49:33 INFO SparkEnv: Registering MapOutputTracker
19/08/28 14:49:33 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 14:49:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 14:49:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 14:49:33 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-87148c9e-47e7-40b2-98d2-c6684618d4f1
19/08/28 14:49:33 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 14:49:33 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 14:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 14:49:34 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 14:49:34 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 14:49:34 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:57739/jars/sparklyr-2.0-2.11.jar with timestamp 1566996574256
19/08/28 14:49:34 INFO Executor: Starting executor ID driver on host localhost
19/08/28 14:49:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57760.
19/08/28 14:49:34 INFO NettyBlockTransferService: Server created on 127.0.0.1:57760
19/08/28 14:49:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 14:49:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57760, None)
19/08/28 14:49:34 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57760 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 57760, None)
19/08/28 14:49:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57760, None)
19/08/28 14:49:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57760, None)
19/08/28 14:49:34 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 14:49:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 14:49:34 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 14:49:36 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 14:49:36 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 14:49:36 INFO ObjectStore: ObjectStore, initialize called
19/08/28 14:49:37 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 14:49:37 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 14:49:39 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 14:49:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:49:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:49:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:49:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:49:41 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 14:49:41 INFO ObjectStore: Initialized ObjectStore
19/08/28 14:49:41 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 14:49:41 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 14:49:41 INFO HiveMetaStore: Added admin role in metastore
19/08/28 14:49:41 INFO HiveMetaStore: Added public role in metastore
19/08/28 14:49:41 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 14:49:41 INFO HiveMetaStore: 0: get_all_databases
19/08/28 14:49:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 14:49:41 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 14:49:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 14:49:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:49:42 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/e5eab278-2dba-4157-a78a-d3af155c92a4_resources
19/08/28 14:49:42 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/e5eab278-2dba-4157-a78a-d3af155c92a4
19/08/28 14:49:42 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/e5eab278-2dba-4157-a78a-d3af155c92a4
19/08/28 14:49:42 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/e5eab278-2dba-4157-a78a-d3af155c92a4/_tmp_space.db
19/08/28 14:49:42 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:49:42 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:42 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:42 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 14:49:42 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 14:49:42 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 14:49:42 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/539a06b0-ff89-4530-b998-acdfd270ca4a_resources
19/08/28 14:49:42 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/539a06b0-ff89-4530-b998-acdfd270ca4a
19/08/28 14:49:42 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/539a06b0-ff89-4530-b998-acdfd270ca4a
19/08/28 14:49:42 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/539a06b0-ff89-4530-b998-acdfd270ca4a/_tmp_space.db
19/08/28 14:49:42 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:49:42 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 14:49:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:49:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:49:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:49:46 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:49:46 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:49:46 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 14:49:46 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:49:46 INFO DAGScheduler: Missing parents: List()
19/08/28 14:49:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 14:49:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 14:49:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 14:49:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57760 (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:49:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 14:49:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 14:49:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 14:49:46 INFO Executor: Fetching spark://127.0.0.1:57739/jars/sparklyr-2.0-2.11.jar with timestamp 1566996574256
19/08/28 14:49:46 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57739 after 27 ms (0 ms spent in bootstraps)
19/08/28 14:49:46 INFO Utils: Fetching spark://127.0.0.1:57739/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f\fetchFileTemp3374325725764349666.tmp
19/08/28 14:49:46 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-9332325b-a3d9-4b03-8b19-097374f09183/userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f/sparklyr-2.0-2.11.jar to class loader
19/08/28 14:49:47 INFO CodeGenerator: Code generated in 316.4184 ms
19/08/28 14:49:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/08/28 14:49:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 912 ms on localhost (executor driver) (1/1)
19/08/28 14:49:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 14:49:47 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,937 s
19/08/28 14:49:47 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1,156320 s
19/08/28 14:49:47 INFO SparkSqlParser: Parsing command: iris
19/08/28 14:49:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 14:49:47 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 14:49:47 INFO CodeGenerator: Code generated in 22.441738 ms
19/08/28 14:49:47 INFO CodeGenerator: Code generated in 12.607608 ms
19/08/28 14:49:47 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:49:47 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 14:49:47 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:49:47 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 14:49:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 14:49:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 14:49:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 14:49:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:49:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 14:49:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57760 (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:49:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 14:49:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:49:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 14:49:47 INFO CodeGenerator: Code generated in 15.434682 ms
19/08/28 14:49:47 INFO CodeGenerator: Code generated in 70.464762 ms
19/08/28 14:49:48 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 14:49:48 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:57760 (size: 5.6 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO CodeGenerator: Code generated in 6.338016 ms
19/08/28 14:49:48 INFO CodeGenerator: Code generated in 53.370404 ms
19/08/28 14:49:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2285 bytes result sent to driver
19/08/28 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 358 ms on localhost (executor driver) (1/1)
19/08/28 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 14:49:48 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,359 s
19/08/28 14:49:48 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:49:48 INFO DAGScheduler: running: Set()
19/08/28 14:49:48 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 14:49:48 INFO DAGScheduler: failed: Set()
19/08/28 14:49:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:49:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:49:48 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 14:49:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:49:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
19/08/28 14:49:48 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 14:49:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1624 bytes result sent to driver
19/08/28 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 189 ms on localhost (executor driver) (1/1)
19/08/28 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 14:49:48 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,189 s
19/08/28 14:49:48 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,622804 s
19/08/28 14:49:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:57760 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 14:49:48 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57760 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 14:49:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:49:48 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 14:49:48 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:49:48 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 14:49:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 14:49:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 14:49:48 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 14:49:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57760 (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:49:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 14:49:48 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:49:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1604 bytes result sent to driver
19/08/28 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 14:49:48 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,018 s
19/08/28 14:49:48 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:49:48 INFO DAGScheduler: running: Set()
19/08/28 14:49:48 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 14:49:48 INFO DAGScheduler: failed: Set()
19/08/28 14:49:48 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:49:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:49:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:49:48 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:48 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 14:49:48 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:49:48 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 14:49:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:49:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:49:48 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/08/28 14:49:48 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:49:48 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 14:49:48 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,008 s
19/08/28 14:49:48 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,057730 s
19/08/28 14:49:48 INFO CodeGenerator: Code generated in 8.564475 ms
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:49:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:49:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:49:49 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:49:49 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 14:49:49 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:49:49 INFO DAGScheduler: Missing parents: List()
19/08/28 14:49:49 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 14:49:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 14:49:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 14:49:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57760 (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:49:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:49 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 14:49:49 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:49:49 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 14:49:49 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:49:49 INFO CodeGenerator: Code generated in 59.065229 ms
19/08/28 14:49:49 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 14:49:49 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1355 bytes result sent to driver
19/08/28 14:49:49 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 104 ms on localhost (executor driver) (1/1)
19/08/28 14:49:49 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 14:49:49 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,104 s
19/08/28 14:49:49 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,139844 s
19/08/28 14:49:49 INFO CodeGenerator: Code generated in 10.593264 ms
19/08/28 14:49:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:49:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:49:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:49:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:49:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:49:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:49:50 INFO CodeGenerator: Code generated in 6.179119 ms
19/08/28 14:49:50 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:49:50 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:49:50 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 14:49:50 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:49:50 INFO DAGScheduler: Missing parents: List()
19/08/28 14:49:50 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 14:49:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 14:49:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 14:49:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57760 (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:49:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 14:49:50 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:49:50 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 14:49:50 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 891 bytes result sent to driver
19/08/28 14:49:50 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 10 ms on localhost (executor driver) (1/1)
19/08/28 14:49:50 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,010 s
19/08/28 14:49:50 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 14:49:50 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,018228 s
19/08/28 14:49:58 INFO SparkSqlParser: Parsing command: flights
19/08/28 14:49:58 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 14:49:58 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 14:49:58 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:49:58 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 14:49:58 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:49:58 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 14:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 14:49:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 14:49:58 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 14:49:58 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 14:49:58 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 14:49:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57760 (size: 11.7 KB, free: 912.3 MB)
19/08/28 14:49:58 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 14:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:49:58 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 14:49:58 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:49:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:49:58 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 14:49:59 INFO CodeGenerator: Code generated in 23.257511 ms
19/08/28 14:49:59 INFO CodeGenerator: Code generated in 164.439828 ms
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 14:50:01 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57760 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 14:50:01 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 14:50:01 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57760 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 14:50:01 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57760 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 14:50:01 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 14:50:01 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 14:50:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 14:50:01 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 14:50:07 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 14:50:07 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:57760 (size: 22.5 MB, free: 889.8 MB)
19/08/28 14:50:07 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 14:50:07 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9350 ms on localhost (executor driver) (1/1)
19/08/28 14:50:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 14:50:07 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 9,372 s
19/08/28 14:50:07 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:07 INFO DAGScheduler: running: Set()
19/08/28 14:50:07 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 14:50:07 INFO DAGScheduler: failed: Set()
19/08/28 14:50:07 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:07 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:50:07 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:50:07 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:50:07 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 14:50:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 14:50:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1495 bytes result sent to driver
19/08/28 14:50:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 18 ms on localhost (executor driver) (1/1)
19/08/28 14:50:07 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 14:50:07 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,035 s
19/08/28 14:50:07 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 9,468703 s
19/08/28 14:50:07 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 14:50:07 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:07 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:08 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:08 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 14:50:08 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:08 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 14:50:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 14:50:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 14:50:08 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:08 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 14:50:08 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 14:50:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57760 (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:50:08 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:08 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 14:50:08 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:50:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 14:50:08 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:50:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 14:50:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 816 ms on localhost (executor driver) (1/1)
19/08/28 14:50:08 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 14:50:08 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,817 s
19/08/28 14:50:08 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:08 INFO DAGScheduler: running: Set()
19/08/28 14:50:08 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 14:50:08 INFO DAGScheduler: failed: Set()
19/08/28 14:50:08 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:08 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:50:08 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:50:08 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:50:08 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:08 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 14:50:08 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:08 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 14:50:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:08 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1495 bytes result sent to driver
19/08/28 14:50:08 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
19/08/28 14:50:08 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 14:50:08 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,011 s
19/08/28 14:50:08 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,866610 s
19/08/28 14:50:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 14:50:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:50:09 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:09 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:50:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:50:09 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:50:09 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 14:50:09 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 14:50:09 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:09 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:09 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 14:50:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 14:50:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 14:50:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57760 (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:50:09 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 14:50:09 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 14:50:09 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:09 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:09 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 14:50:09 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 14:50:09 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 891 bytes result sent to driver
19/08/28 14:50:09 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 894 bytes result sent to driver
19/08/28 14:50:09 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 16 ms on localhost (executor driver) (1/2)
19/08/28 14:50:09 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 16 ms on localhost (executor driver) (2/2)
19/08/28 14:50:09 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 14:50:09 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,019 s
19/08/28 14:50:09 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,031919 s
19/08/28 14:50:15 INFO SparkSqlParser: Parsing command: batting
19/08/28 14:50:15 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 14:50:15 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 14:50:15 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:50:15 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 14:50:15 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:50:15 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 14:50:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 14:50:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 14:50:15 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:15 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.6 MB)
19/08/28 14:50:15 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 14:50:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57760 (size: 11.6 KB, free: 889.7 MB)
19/08/28 14:50:15 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:15 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 14:50:15 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:15 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:50:15 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 14:50:15 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:50:15 INFO ContextCleaner: Cleaned accumulator 297
19/08/28 14:50:15 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57760 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:50:15 INFO ContextCleaner: Cleaned accumulator 290
19/08/28 14:50:15 INFO ContextCleaner: Cleaned accumulator 291
19/08/28 14:50:16 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:57760 in memory (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 294
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 287
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 298
19/08/28 14:50:16 INFO ContextCleaner: Cleaned shuffle 3
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 288
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 296
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 292
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 14:50:16 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 295
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 293
19/08/28 14:50:16 INFO ContextCleaner: Cleaned accumulator 289
19/08/28 14:50:16 INFO CodeGenerator: Code generated in 40.913331 ms
19/08/28 14:50:16 INFO CodeGenerator: Code generated in 341.418077 ms
19/08/28 14:50:18 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 14:50:18 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:57760 (size: 3.4 MB, free: 886.4 MB)
19/08/28 14:50:18 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 14:50:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 2935 ms on localhost (executor driver) (1/1)
19/08/28 14:50:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 14:50:18 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 2,953 s
19/08/28 14:50:18 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:18 INFO DAGScheduler: running: Set()
19/08/28 14:50:18 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 14:50:18 INFO DAGScheduler: failed: Set()
19/08/28 14:50:18 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:50:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:50:18 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:18 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 14:50:18 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:18 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 14:50:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:18 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1452 bytes result sent to driver
19/08/28 14:50:18 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:50:18 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 14:50:18 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,011 s
19/08/28 14:50:18 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 3,008260 s
19/08/28 14:50:18 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 14:50:18 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:18 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:18 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 14:50:18 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:18 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 14:50:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 14:50:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 14:50:18 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.3 MB)
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.3 MB)
19/08/28 14:50:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57760 (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:50:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:18 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 14:50:18 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:18 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:50:18 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 14:50:18 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 14:50:18 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1690 bytes result sent to driver
19/08/28 14:50:18 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 136 ms on localhost (executor driver) (1/1)
19/08/28 14:50:18 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 14:50:18 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,137 s
19/08/28 14:50:18 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:18 INFO DAGScheduler: running: Set()
19/08/28 14:50:18 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 14:50:18 INFO DAGScheduler: failed: Set()
19/08/28 14:50:18 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:50:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:50:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:50:18 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:18 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 14:50:18 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:18 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 14:50:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:50:18 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1495 bytes result sent to driver
19/08/28 14:50:18 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:50:18 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 14:50:18 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,013 s
19/08/28 14:50:18 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,182473 s
19/08/28 14:50:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 14:50:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:50:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:50:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:50:19 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:50:19 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:50:19 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 14:50:19 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:19 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:19 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 14:50:19 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.2 MB)
19/08/28 14:50:19 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.1 MB)
19/08/28 14:50:19 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57760 (size: 34.7 KB, free: 886.3 MB)
19/08/28 14:50:19 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:19 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 14:50:19 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:50:19 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 14:50:19 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:50:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:50:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:50:19 INFO FileOutputCommitter: Saved output of task 'attempt_20190828145019_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/RtmpghPFau/file2aa4518e176f.csv/_temporary/0/task_20190828145019_0016_m_000000
19/08/28 14:50:19 INFO SparkHadoopMapRedUtil: attempt_20190828145019_0016_m_000000_0: Committed
19/08/28 14:50:19 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 14:50:19 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 215 ms on localhost (executor driver) (1/1)
19/08/28 14:50:19 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 14:50:19 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,216 s
19/08/28 14:50:19 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,244362 s
19/08/28 14:50:19 INFO FileFormatWriter: Job null committed.
19/08/28 14:50:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:50:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:50:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:50:19 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:50:19 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 14:50:19 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 14:50:19 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:19 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:19 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 14:50:19 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.1 MB)
19/08/28 14:50:19 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.6 KB, free 886.1 MB)
19/08/28 14:50:19 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57760 (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:50:19 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:19 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 14:50:19 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 14:50:19 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:19 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:19 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:19 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 14:50:19 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 14:50:19 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 14:50:19 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 891 bytes result sent to driver
19/08/28 14:50:19 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 894 bytes result sent to driver
19/08/28 14:50:19 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 894 bytes result sent to driver
19/08/28 14:50:19 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 5 ms on localhost (executor driver) (1/3)
19/08/28 14:50:19 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 7 ms on localhost (executor driver) (2/3)
19/08/28 14:50:19 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 8 ms on localhost (executor driver) (3/3)
19/08/28 14:50:19 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 14:50:19 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,008 s
19/08/28 14:50:19 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,014817 s
19/08/28 14:50:20 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:50:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 14:50:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:50:20 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:50:20 INFO CodeGenerator: Code generated in 10.631277 ms
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 885.8 MB)
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.8 MB)
19/08/28 14:50:20 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:57760 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:50:20 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 14:50:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:50:20 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:50:20 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:50:20 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 14:50:20 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:20 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:20 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 885.8 MB)
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 885.8 MB)
19/08/28 14:50:20 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:57760 (size: 4.3 KB, free: 886.3 MB)
19/08/28 14:50:20 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:20 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 14:50:20 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:50:20 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 14:50:20 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpghPFau/file2aa4518e176f.csv/part-00000-d23e810c-96c9-41d8-b001-d56df8e07cca-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:50:20 INFO CodeGenerator: Code generated in 7.285316 ms
19/08/28 14:50:20 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1265 bytes result sent to driver
19/08/28 14:50:20 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 88 ms on localhost (executor driver) (1/1)
19/08/28 14:50:20 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 14:50:20 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,090 s
19/08/28 14:50:20 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,109390 s
19/08/28 14:50:20 INFO CodeGenerator: Code generated in 5.797082 ms
19/08/28 14:50:20 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:50:20 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:50:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:50:20 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:50:20 INFO CodeGenerator: Code generated in 5.074062 ms
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.5 MB)
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.5 MB)
19/08/28 14:50:20 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:57760 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:50:20 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 14:50:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:50:20 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:50:20 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:50:20 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 14:50:20 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:20 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:20 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.5 MB)
19/08/28 14:50:20 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.5 MB)
19/08/28 14:50:20 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:57760 (size: 8.2 KB, free: 886.3 MB)
19/08/28 14:50:20 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:20 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 14:50:20 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:50:20 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 14:50:20 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpghPFau/file2aa4518e176f.csv/part-00000-d23e810c-96c9-41d8-b001-d56df8e07cca-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:50:20 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1495 bytes result sent to driver
19/08/28 14:50:20 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 56 ms on localhost (executor driver) (1/1)
19/08/28 14:50:20 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 14:50:20 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,065 s
19/08/28 14:50:20 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,080467 s
19/08/28 14:50:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:50:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:50:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:50:20 INFO CodeGenerator: Code generated in 9.445252 ms
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 14:50:21 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:50:21 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:50:21 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 14:50:21 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.2 MB)
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.2 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:57760 (size: 24.1 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 14:50:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:50:21 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:50:21 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 14:50:21 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:50:21 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 14:50:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 14:50:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 14:50:21 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.2 MB)
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.2 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:57760 (size: 9.9 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:21 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 14:50:21 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:50:21 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 14:50:21 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpghPFau/file2aa4518e176f.csv/part-00000-d23e810c-96c9-41d8-b001-d56df8e07cca-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:50:21 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 885.2 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:57760 (size: 5.6 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2461 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 64 ms on localhost (executor driver) (1/1)
19/08/28 14:50:21 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,065 s
19/08/28 14:50:21 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:21 INFO DAGScheduler: running: Set()
19/08/28 14:50:21 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 14:50:21 INFO DAGScheduler: failed: Set()
19/08/28 14:50:21 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 885.2 MB)
19/08/28 14:50:21 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.1 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:21 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 14:50:21 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:21 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 14:50:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:50:21 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1452 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
19/08/28 14:50:21 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 14:50:21 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,005 s
19/08/28 14:50:21 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,094299 s
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 14:50:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:21 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 14:50:21 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:21 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 14:50:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 14:50:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 14:50:21 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 885.1 MB)
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.1 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:57760 (size: 9.9 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:21 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 14:50:21 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:50:21 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 14:50:21 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 14:50:21 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1694 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:50:21 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 14:50:21 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,013 s
19/08/28 14:50:21 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:21 INFO DAGScheduler: running: Set()
19/08/28 14:50:21 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 14:50:21 INFO DAGScheduler: failed: Set()
19/08/28 14:50:21 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.1 MB)
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.1 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:21 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 14:50:21 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:21 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 14:50:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:21 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1495 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 8 ms on localhost (executor driver) (1/1)
19/08/28 14:50:21 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 14:50:21 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,009 s
19/08/28 14:50:21 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,037277 s
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:50:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:21 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:50:21 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:50:21 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:50:21 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 14:50:21 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 14:50:21 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:21 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:21 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.1 MB)
19/08/28 14:50:21 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.1 MB)
19/08/28 14:50:21 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:57760 (size: 3.6 KB, free: 886.2 MB)
19/08/28 14:50:21 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:50:21 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 14:50:21 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:21 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:21 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:21 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:21 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 14:50:21 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 14:50:21 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 14:50:21 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 14:50:21 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 891 bytes result sent to driver
19/08/28 14:50:21 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 14 ms on localhost (executor driver) (1/4)
19/08/28 14:50:21 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 14 ms on localhost (executor driver) (2/4)
19/08/28 14:50:21 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 14:50:21 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 16 ms on localhost (executor driver) (3/4)
19/08/28 14:50:21 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 938 bytes result sent to driver
19/08/28 14:50:21 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 21 ms on localhost (executor driver) (4/4)
19/08/28 14:50:21 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 14:50:21 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,030 s
19/08/28 14:50:21 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,053377 s
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:50:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:50:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:50:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:50:22 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1479 - dep_delay.nullCount#1478) > 0)
19/08/28 14:50:22 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1477 <= 2.0) && (2.0 <= dep_delay.upperBound#1476))
19/08/28 14:50:22 INFO CodeGenerator: Code generated in 26.349542 ms
19/08/28 14:50:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:22 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:22 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/08/28 14:50:22 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:22 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:22 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:22 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.7 KB, free 885.1 MB)
19/08/28 14:50:22 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 885.1 MB)
19/08/28 14:50:22 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:57760 (size: 12.5 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:22 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 14:50:22 WARN TaskSetManager: Stage 25 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:22 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 14:50:22 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 681
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:57760 in memory (size: 8.2 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 14:50:22 INFO ContextCleaner: Cleaned shuffle 6
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 673
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 680
19/08/28 14:50:22 INFO ContextCleaner: Cleaned shuffle 7
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57760 in memory (size: 11.6 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 521
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:57760 in memory (size: 24.0 KB, free: 886.2 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57760 in memory (size: 34.7 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:57760 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 679
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:57760 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 678
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 684
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:57760 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 682
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 676
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 674
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 683
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:57760 in memory (size: 4.3 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 733
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:57760 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 14:50:22 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:57760 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 677
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 675
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 14:50:22 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 14:50:22 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:50:22 INFO CodeGenerator: Code generated in 9.625816 ms
19/08/28 14:50:22 INFO CodeGenerator: Code generated in 22.245968 ms
19/08/28 14:50:23 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_33_0]
19/08/28 14:50:23 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2273 bytes result sent to driver
19/08/28 14:50:23 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 665 ms on localhost (executor driver) (1/1)
19/08/28 14:50:23 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 14:50:23 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0,668 s
19/08/28 14:50:23 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0,695639 s
19/08/28 14:50:23 INFO CodeGenerator: Code generated in 19.630629 ms
19/08/28 14:50:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:50:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `bwvdgbkkzs`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `tefbgtkusk`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `abllfulkln`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `mfjyxilera`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:24 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:24 INFO CodeGenerator: Code generated in 38.716902 ms
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 63.382439 ms
19/08/28 14:50:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:25 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:204)
19/08/28 14:50:25 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:25 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/08/28 14:50:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/08/28 14:50:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/08/28 14:50:25 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:25 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 14:50:25 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KB, free 885.9 MB)
19/08/28 14:50:25 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:57760 (size: 19.8 KB, free: 886.3 MB)
19/08/28 14:50:25 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:25 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 14:50:25 WARN TaskSetManager: Stage 26 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:25 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:50:25 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
19/08/28 14:50:25 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 14.967875 ms
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 5.924807 ms
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 26.125641 ms
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 8.182438 ms
19/08/28 14:50:25 INFO CodeGenerator: Code generated in 11.602907 ms
19/08/28 14:50:26 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1921 bytes result sent to driver
19/08/28 14:50:26 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 1015 ms on localhost (executor driver) (1/1)
19/08/28 14:50:26 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 14:50:26 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 1,016 s
19/08/28 14:50:26 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:26 INFO DAGScheduler: running: Set()
19/08/28 14:50:26 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/08/28 14:50:26 INFO DAGScheduler: failed: Set()
19/08/28 14:50:26 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:26 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 27.0 KB, free 885.9 MB)
19/08/28 14:50:26 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.9 MB)
19/08/28 14:50:26 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:57760 (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:50:26 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:26 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 14:50:26 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:26 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
19/08/28 14:50:26 INFO ContextCleaner: Cleaned accumulator 785
19/08/28 14:50:26 INFO ContextCleaner: Cleaned accumulator 759
19/08/28 14:50:26 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:57760 in memory (size: 19.8 KB, free: 886.3 MB)
19/08/28 14:50:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:26 INFO ContextCleaner: Cleaned accumulator 760
19/08/28 14:50:26 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:57760 in memory (size: 12.5 KB, free: 886.3 MB)
19/08/28 14:50:26 INFO ContextCleaner: Cleaned accumulator 758
19/08/28 14:50:26 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 33
19/08/28 14:50:26 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 2691 bytes result sent to driver
19/08/28 14:50:26 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 34 ms on localhost (executor driver) (1/1)
19/08/28 14:50:26 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 14:50:26 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0,034 s
19/08/28 14:50:26 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 1,078967 s
19/08/28 14:50:26 INFO CodeGenerator: Code generated in 6.694964 ms
19/08/28 14:50:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `pkolzirgrr`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `pctyyyecas`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `eqizhddgzt`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:26 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:26 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/08/28 14:50:26 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 4 output partitions
19/08/28 14:50:26 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/08/28 14:50:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/08/28 14:50:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/08/28 14:50:26 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:26 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 14:50:26 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.0 KB, free 885.9 MB)
19/08/28 14:50:26 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:57760 (size: 20.0 KB, free: 886.3 MB)
19/08/28 14:50:26 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:26 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 14:50:27 WARN TaskSetManager: Stage 28 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:50:27 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:50:27 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
19/08/28 14:50:27 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:50:27 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 1921 bytes result sent to driver
19/08/28 14:50:27 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 803 ms on localhost (executor driver) (1/1)
19/08/28 14:50:27 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 14:50:27 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0,803 s
19/08/28 14:50:27 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:27 INFO DAGScheduler: running: Set()
19/08/28 14:50:27 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/08/28 14:50:27 INFO DAGScheduler: failed: Set()
19/08/28 14:50:27 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:27 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 27.2 KB, free 885.9 MB)
19/08/28 14:50:27 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.9 MB)
19/08/28 14:50:27 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:57760 (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:50:27 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:50:27 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
19/08/28 14:50:27 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:27 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 36, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 14:50:27 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 37, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 14:50:27 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 38, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 14:50:27 INFO Executor: Running task 2.0 in stage 29.0 (TID 37)
19/08/28 14:50:27 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:27 INFO Executor: Running task 3.0 in stage 29.0 (TID 38)
19/08/28 14:50:27 INFO Executor: Running task 1.0 in stage 29.0 (TID 36)
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:50:27 INFO Executor: Finished task 2.0 in stage 29.0 (TID 37). 22702 bytes result sent to driver
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:27 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 21556 bytes result sent to driver
19/08/28 14:50:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 28 ms on localhost (executor driver) (1/4)
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/08/28 14:50:27 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 37) in 30 ms on localhost (executor driver) (2/4)
19/08/28 14:50:27 INFO Executor: Finished task 3.0 in stage 29.0 (TID 38). 20842 bytes result sent to driver
19/08/28 14:50:27 INFO Executor: Finished task 1.0 in stage 29.0 (TID 36). 21732 bytes result sent to driver
19/08/28 14:50:27 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 38) in 45 ms on localhost (executor driver) (3/4)
19/08/28 14:50:27 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 36) in 47 ms on localhost (executor driver) (4/4)
19/08/28 14:50:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 14:50:27 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0,048 s
19/08/28 14:50:27 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0,870134 s
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:50:30 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:30 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:30 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:30 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:50:30 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:50:30 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:50:30 INFO DAGScheduler: Got job 20 (collect at utils.scala:44) with 4 output partitions
19/08/28 14:50:30 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
19/08/28 14:50:30 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:30 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:30 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41), which has no missing parents
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.5 KB, free 885.9 MB)
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.9 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:57760 (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:50:30 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/08/28 14:50:30 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:30 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:30 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:30 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:50:30 INFO Executor: Running task 2.0 in stage 30.0 (TID 41)
19/08/28 14:50:30 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
19/08/28 14:50:30 INFO Executor: Running task 3.0 in stage 30.0 (TID 42)
19/08/28 14:50:30 INFO Executor: Running task 1.0 in stage 30.0 (TID 40)
19/08/28 14:50:30 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 894 bytes result sent to driver
19/08/28 14:50:30 INFO Executor: Finished task 2.0 in stage 30.0 (TID 41). 891 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 41) in 12 ms on localhost (executor driver) (1/4)
19/08/28 14:50:30 INFO Executor: Finished task 3.0 in stage 30.0 (TID 42). 895 bytes result sent to driver
19/08/28 14:50:30 INFO Executor: Finished task 1.0 in stage 30.0 (TID 40). 894 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 16 ms on localhost (executor driver) (2/4)
19/08/28 14:50:30 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 42) in 16 ms on localhost (executor driver) (3/4)
19/08/28 14:50:30 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 40) in 16 ms on localhost (executor driver) (4/4)
19/08/28 14:50:30 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 14:50:30 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0,018 s
19/08/28 14:50:30 INFO DAGScheduler: Job 20 finished: collect at utils.scala:44, took 0,027852 s
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 14:50:30 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:50:30 INFO DAGScheduler: Registering RDD 131 (sql at <unknown>:0)
19/08/28 14:50:30 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:50:30 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
19/08/28 14:50:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 14:50:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 14:50:30 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 22.4 KB, free 885.8 MB)
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.8 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:57760 (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:30 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 14:50:30 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:50:30 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
19/08/28 14:50:30 INFO CodeGenerator: Code generated in 10.557151 ms
19/08/28 14:50:30 INFO CodeGenerator: Code generated in 34.374603 ms
19/08/28 14:50:30 INFO MemoryStore: Block rdd_128_0 stored as values in memory (estimated size 4.2 KB, free 885.8 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added rdd_128_0 in memory on 127.0.0.1:57760 (size: 4.2 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2285 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 70 ms on localhost (executor driver) (1/1)
19/08/28 14:50:30 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0,072 s
19/08/28 14:50:30 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:30 INFO DAGScheduler: running: Set()
19/08/28 14:50:30 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 14:50:30 INFO DAGScheduler: failed: Set()
19/08/28 14:50:30 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 885.8 MB)
19/08/28 14:50:30 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.8 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:30 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 14:50:30 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:30 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
19/08/28 14:50:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:50:30 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 1538 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 5 ms on localhost (executor driver) (1/1)
19/08/28 14:50:30 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 14:50:30 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0,005 s
19/08/28 14:50:30 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0,090423 s
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 14:50:30 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:50:30 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:50:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:50:30 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:204)
19/08/28 14:50:30 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:50:30 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/08/28 14:50:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 14:50:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 14:50:30 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 22.4 KB, free 885.8 MB)
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.8 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:57760 (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:30 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 14:50:30 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:50:30 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
19/08/28 14:50:30 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:30 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 1647 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 10 ms on localhost (executor driver) (1/1)
19/08/28 14:50:30 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 14:50:30 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0,011 s
19/08/28 14:50:30 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:30 INFO DAGScheduler: running: Set()
19/08/28 14:50:30 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 14:50:30 INFO DAGScheduler: failed: Set()
19/08/28 14:50:30 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 885.8 MB)
19/08/28 14:50:30 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.8 MB)
19/08/28 14:50:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:30 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:30 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 14:50:30 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:30 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
19/08/28 14:50:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:30 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 1495 bytes result sent to driver
19/08/28 14:50:30 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
19/08/28 14:50:30 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 14:50:30 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0,004 s
19/08/28 14:50:30 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0,029010 s
19/08/28 14:50:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa4286e7369
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa4286e7369` AS `zzz6`
WHERE (0 = 1)
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa45e5f42b2
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa45e5f42b2` AS `zzz7`
WHERE (0 = 1)
19/08/28 14:50:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa4286e7369`
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2292 - hp.nullCount#2291) > 0)
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2289)
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 38.039499 ms
19/08/28 14:50:32 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 14:50:32 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 14:50:32 INFO DAGScheduler: Final stage: ResultStage 35 (first at LinearRegression.scala:198)
19/08/28 14:50:32 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:32 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:32 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 14:50:32 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 41.3 KB, free 885.7 MB)
19/08/28 14:50:32 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.3 KB, free 885.7 MB)
19/08/28 14:50:32 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:57760 (size: 16.3 KB, free: 886.3 MB)
19/08/28 14:50:32 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:32 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 14:50:32 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:50:32 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
19/08/28 14:50:32 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 23.667679 ms
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 13.67351 ms
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 26.433932 ms
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 14.905912 ms
19/08/28 14:50:32 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 1743 bytes result sent to driver
19/08/28 14:50:32 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 276 ms on localhost (executor driver) (1/1)
19/08/28 14:50:32 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 14:50:32 INFO DAGScheduler: ResultStage 35 (first at LinearRegression.scala:198) finished in 0,276 s
19/08/28 14:50:32 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0,289998 s
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 10.19374 ms
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2353 - hp.nullCount#2352) > 0)
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2350)
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 31.592004 ms
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2409 - hp.nullCount#2408) > 0)
19/08/28 14:50:32 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2406)
19/08/28 14:50:32 INFO CodeGenerator: Code generated in 28.37643 ms
19/08/28 14:50:32 INFO Instrumentation: LinearRegression-linear_regression_2aa41beb48a1-80316759-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 14:50:32 INFO Instrumentation: LinearRegression-linear_regression_2aa41beb48a1-80316759-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 14:50:32 INFO Instrumentation: LinearRegression-linear_regression_2aa41beb48a1-80316759-1: {"numFeatures":2}
19/08/28 14:50:32 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 14:50:32 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:57760 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 790
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 860
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 794
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1059
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 851
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 856
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 948
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 796
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 941
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 939
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1063
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 947
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 792
19/08/28 14:50:33 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 14:50:33 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 14:50:33 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 14:50:33 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:57760 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:33 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 885.7 MB)
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.6 KB, free 885.7 MB)
19/08/28 14:50:33 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:57760 (size: 17.6 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:33 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 944
19/08/28 14:50:33 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:50:33 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
19/08/28 14:50:33 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:57760 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 909
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 849
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 855
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 943
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 788
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 791
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 847
19/08/28 14:50:33 INFO ContextCleaner: Cleaned shuffle 10
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 848
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 789
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 857
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 946
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1060
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 793
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 940
19/08/28 14:50:33 INFO CodeGenerator: Code generated in 7.207388 ms
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:57760 in memory (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 786
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 854
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 787
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:57760 in memory (size: 20.0 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 859
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 795
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 858
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:57760 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 14:50:33 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 945
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 797
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 997
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 937
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 852
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 938
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 798
19/08/28 14:50:33 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 2184 bytes result sent to driver
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:57760 in memory (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 112 ms on localhost (executor driver) (1/1)
19/08/28 14:50:33 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/08/28 14:50:33 INFO DAGScheduler: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,141 s
19/08/28 14:50:33 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,157895 s
19/08/28 14:50:33 INFO ContextCleaner: Cleaned shuffle 8
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 942
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1061
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1062
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 850
19/08/28 14:50:33 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 14:50:33 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:57760 in memory (size: 16.3 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1064
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 853
19/08/28 14:50:33 INFO ContextCleaner: Cleaned shuffle 9
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 1058
19/08/28 14:50:33 INFO ContextCleaner: Cleaned accumulator 936
19/08/28 14:50:33 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 14:50:33 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 14:50:33 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2486 - hp.nullCount#2485) > 0)
19/08/28 14:50:33 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2483)
19/08/28 14:50:33 INFO CodeGenerator: Code generated in 32.199082 ms
19/08/28 14:50:33 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 14:50:33 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 14:50:33 INFO DAGScheduler: Final stage: ResultStage 37 (aggregate at RegressionMetrics.scala:57)
19/08/28 14:50:33 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:33 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:33 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.2 KB, free 885.9 MB)
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.9 KB, free 885.9 MB)
19/08/28 14:50:33 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:57760 (size: 17.9 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:33 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/08/28 14:50:33 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:50:33 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
19/08/28 14:50:33 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:33 INFO CodeGenerator: Code generated in 10.236696 ms
19/08/28 14:50:33 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2180 bytes result sent to driver
19/08/28 14:50:33 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 143 ms on localhost (executor driver) (1/1)
19/08/28 14:50:33 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/08/28 14:50:33 INFO DAGScheduler: ResultStage 37 (aggregate at RegressionMetrics.scala:57) finished in 0,150 s
19/08/28 14:50:33 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0,164071 s
19/08/28 14:50:33 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 14:50:33 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 14:50:33 INFO DAGScheduler: Final stage: ResultStage 38 (sum at RegressionMetrics.scala:71)
19/08/28 14:50:33 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:33 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:33 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 43.8 KB, free 885.8 MB)
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.8 MB)
19/08/28 14:50:33 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:57760 (size: 17.8 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:33 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/08/28 14:50:33 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:50:33 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
19/08/28 14:50:33 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:33 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 1697 bytes result sent to driver
19/08/28 14:50:33 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 13 ms on localhost (executor driver) (1/1)
19/08/28 14:50:33 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/08/28 14:50:33 INFO DAGScheduler: ResultStage 38 (sum at RegressionMetrics.scala:71) finished in 0,013 s
19/08/28 14:50:33 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0,020330 s
19/08/28 14:50:33 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2561 - hp.nullCount#2560) > 0)
19/08/28 14:50:33 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2558)
19/08/28 14:50:33 INFO CodeGenerator: Code generated in 27.236781 ms
19/08/28 14:50:33 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 14:50:33 INFO DAGScheduler: Registering RDD 163 (count at LinearRegression.scala:696)
19/08/28 14:50:33 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 14:50:33 INFO DAGScheduler: Final stage: ResultStage 40 (count at LinearRegression.scala:696)
19/08/28 14:50:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/08/28 14:50:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/08/28 14:50:33 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 36.6 KB, free 885.8 MB)
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.8 MB)
19/08/28 14:50:33 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:57760 (size: 14.8 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:33 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/08/28 14:50:33 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:50:33 INFO Executor: Running task 0.0 in stage 39.0 (TID 51)
19/08/28 14:50:33 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:33 INFO Executor: Finished task 0.0 in stage 39.0 (TID 51). 2275 bytes result sent to driver
19/08/28 14:50:33 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 51) in 62 ms on localhost (executor driver) (1/1)
19/08/28 14:50:33 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/08/28 14:50:33 INFO DAGScheduler: ShuffleMapStage 39 (count at LinearRegression.scala:696) finished in 0,065 s
19/08/28 14:50:33 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:33 INFO DAGScheduler: running: Set()
19/08/28 14:50:33 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/08/28 14:50:33 INFO DAGScheduler: failed: Set()
19/08/28 14:50:33 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 885.8 MB)
19/08/28 14:50:33 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.8 MB)
19/08/28 14:50:33 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:33 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/08/28 14:50:33 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 52, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:34 INFO Executor: Running task 0.0 in stage 40.0 (TID 52)
19/08/28 14:50:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:34 INFO Executor: Finished task 0.0 in stage 40.0 (TID 52). 1495 bytes result sent to driver
19/08/28 14:50:34 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 52) in 13 ms on localhost (executor driver) (1/1)
19/08/28 14:50:34 INFO DAGScheduler: ResultStage 40 (count at LinearRegression.scala:696) finished in 0,021 s
19/08/28 14:50:34 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:696, took 0,108491 s
19/08/28 14:50:34 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/08/28 14:50:34 INFO Instrumentation: LinearRegression-linear_regression_2aa41beb48a1-80316759-1: training finished
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa459a75990
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa459a75990` AS `zzz8`
WHERE (0 = 1)
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa4286e7369`
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa464f96d9d
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa464f96d9d` AS `zzz9`
WHERE (0 = 1)
19/08/28 14:50:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa464f96d9d`
19/08/28 14:50:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa47044555b
19/08/28 14:50:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa47044555b` AS `zzz10`
WHERE (0 = 1)
19/08/28 14:50:35 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2aa419344d07
19/08/28 14:50:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa419344d07` AS `zzz11`
WHERE (0 = 1)
19/08/28 14:50:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2aa419344d07`
19/08/28 14:50:35 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2783 - hp.nullCount#2782) > 0)
19/08/28 14:50:35 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2780)
19/08/28 14:50:35 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 14:50:35 INFO DAGScheduler: Registering RDD 169 (count at <unknown>:0)
19/08/28 14:50:35 INFO DAGScheduler: Got job 28 (count at <unknown>:0) with 1 output partitions
19/08/28 14:50:35 INFO DAGScheduler: Final stage: ResultStage 42 (count at <unknown>:0)
19/08/28 14:50:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/08/28 14:50:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/08/28 14:50:35 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 36.6 KB, free 885.7 MB)
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.7 MB)
19/08/28 14:50:35 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:57760 (size: 14.8 KB, free: 886.3 MB)
19/08/28 14:50:35 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:35 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/08/28 14:50:35 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:50:35 INFO Executor: Running task 0.0 in stage 41.0 (TID 53)
19/08/28 14:50:35 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:35 INFO Executor: Finished task 0.0 in stage 41.0 (TID 53). 2275 bytes result sent to driver
19/08/28 14:50:35 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 53) in 19 ms on localhost (executor driver) (1/1)
19/08/28 14:50:35 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/08/28 14:50:35 INFO DAGScheduler: ShuffleMapStage 41 (count at <unknown>:0) finished in 0,027 s
19/08/28 14:50:35 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:50:35 INFO DAGScheduler: running: Set()
19/08/28 14:50:35 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/08/28 14:50:35 INFO DAGScheduler: failed: Set()
19/08/28 14:50:35 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0), which has no missing parents
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 885.7 MB)
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.7 MB)
19/08/28 14:50:35 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:57760 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:50:35 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:35 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/08/28 14:50:35 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:50:35 INFO Executor: Running task 0.0 in stage 42.0 (TID 54)
19/08/28 14:50:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:50:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:50:35 INFO Executor: Finished task 0.0 in stage 42.0 (TID 54). 1452 bytes result sent to driver
19/08/28 14:50:35 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 54) in 5 ms on localhost (executor driver) (1/1)
19/08/28 14:50:35 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/08/28 14:50:35 INFO DAGScheduler: ResultStage 42 (count at <unknown>:0) finished in 0,007 s
19/08/28 14:50:35 INFO DAGScheduler: Job 28 finished: count at <unknown>:0, took 0,062757 s
19/08/28 14:50:35 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2843 - hp.nullCount#2842) > 0)
19/08/28 14:50:35 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2840)
19/08/28 14:50:35 INFO CodeGenerator: Code generated in 32.230633 ms
19/08/28 14:50:35 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 14:50:35 INFO DAGScheduler: Got job 29 (collect at utils.scala:37) with 1 output partitions
19/08/28 14:50:35 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:37)
19/08/28 14:50:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:50:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:50:35 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34), which has no missing parents
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 885.7 MB)
19/08/28 14:50:35 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.6 MB)
19/08/28 14:50:35 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:57760 (size: 19.3 KB, free: 886.2 MB)
19/08/28 14:50:35 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/08/28 14:50:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 14:50:35 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/08/28 14:50:35 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:50:35 INFO Executor: Running task 0.0 in stage 43.0 (TID 55)
19/08/28 14:50:35 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:50:35 INFO CodeGenerator: Code generated in 13.236733 ms
19/08/28 14:50:35 INFO Executor: Finished task 0.0 in stage 43.0 (TID 55). 1747 bytes result sent to driver
19/08/28 14:50:35 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 55) in 47 ms on localhost (executor driver) (1/1)
19/08/28 14:50:35 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/08/28 14:50:35 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:37) finished in 0,047 s
19/08/28 14:50:35 INFO DAGScheduler: Job 29 finished: collect at utils.scala:37, took 0,056736 s
19/08/28 14:50:38 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 14:50:38 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 14:50:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 14:50:38 INFO MemoryStore: MemoryStore cleared
19/08/28 14:50:38 INFO BlockManager: BlockManager stopped
19/08/28 14:50:38 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 14:50:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 14:50:38 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:50:38 INFO SparkContext: Successfully stopped SparkContext
19/08/28 14:50:38 INFO ShutdownHookManager: Shutdown hook called
19/08/28 14:50:38 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f
19/08/28 14:50:38 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183\userFiles-aedb9956-c7a5-46a4-99bd-8aad16fde26f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:50:38 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183
19/08/28 14:50:38 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-9332325b-a3d9-4b03-8b19-097374f09183
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:57:42 INFO SparkContext: Running Spark version 2.2.0
19/08/28 14:57:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 14:57:44 INFO SparkContext: Submitted application: sparklyr
19/08/28 14:57:44 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 14:57:44 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 14:57:44 INFO SecurityManager: Changing view acls groups to: 
19/08/28 14:57:44 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 14:57:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 14:57:44 INFO Utils: Successfully started service 'sparkDriver' on port 57969.
19/08/28 14:57:44 INFO SparkEnv: Registering MapOutputTracker
19/08/28 14:57:44 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 14:57:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 14:57:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 14:57:44 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-acecc521-03d8-4b19-ad15-8b65538ee242
19/08/28 14:57:44 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 14:57:44 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 14:57:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 14:57:45 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 14:57:45 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 14:57:45 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:57969/jars/sparklyr-2.0-2.11.jar with timestamp 1566997065497
19/08/28 14:57:45 INFO Executor: Starting executor ID driver on host localhost
19/08/28 14:57:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57990.
19/08/28 14:57:45 INFO NettyBlockTransferService: Server created on 127.0.0.1:57990
19/08/28 14:57:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 14:57:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57990, None)
19/08/28 14:57:45 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57990 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 57990, None)
19/08/28 14:57:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57990, None)
19/08/28 14:57:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57990, None)
19/08/28 14:57:46 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 14:57:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 14:57:46 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 14:57:47 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 14:57:48 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 14:57:48 INFO ObjectStore: ObjectStore, initialize called
19/08/28 14:57:48 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 14:57:48 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 14:57:50 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 14:57:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:57:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:57:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:57:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:57:52 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 14:57:52 INFO ObjectStore: Initialized ObjectStore
19/08/28 14:57:52 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 14:57:52 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 14:57:52 INFO HiveMetaStore: Added admin role in metastore
19/08/28 14:57:52 INFO HiveMetaStore: Added public role in metastore
19/08/28 14:57:52 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 14:57:52 INFO HiveMetaStore: 0: get_all_databases
19/08/28 14:57:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 14:57:52 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 14:57:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 14:57:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 14:57:52 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/053a7725-d8dd-4e8c-afda-6fcb2bda825b_resources
19/08/28 14:57:52 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/053a7725-d8dd-4e8c-afda-6fcb2bda825b
19/08/28 14:57:52 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/053a7725-d8dd-4e8c-afda-6fcb2bda825b
19/08/28 14:57:52 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/053a7725-d8dd-4e8c-afda-6fcb2bda825b/_tmp_space.db
19/08/28 14:57:52 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:57:52 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:57:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:57:52 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 14:57:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 14:57:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 14:57:53 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/7dd66172-eb0e-4a19-86e8-93c9abf16246_resources
19/08/28 14:57:53 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/7dd66172-eb0e-4a19-86e8-93c9abf16246
19/08/28 14:57:53 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/7dd66172-eb0e-4a19-86e8-93c9abf16246
19/08/28 14:57:53 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/7dd66172-eb0e-4a19-86e8-93c9abf16246/_tmp_space.db
19/08/28 14:57:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 14:57:53 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 14:57:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:57:55 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:57:55 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:57:55 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:57:55 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:57:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:57:55 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:57:56 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:57:56 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:57:56 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 14:57:56 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:57:56 INFO DAGScheduler: Missing parents: List()
19/08/28 14:57:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 14:57:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 14:57:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 14:57:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57990 (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:57:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 14:57:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 14:57:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 14:57:56 INFO Executor: Fetching spark://127.0.0.1:57969/jars/sparklyr-2.0-2.11.jar with timestamp 1566997065497
19/08/28 14:57:56 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57969 after 19 ms (0 ms spent in bootstraps)
19/08/28 14:57:56 INFO Utils: Fetching spark://127.0.0.1:57969/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0\fetchFileTemp743089944326235614.tmp
19/08/28 14:57:57 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-309a971d-2136-4e80-9090-8100d24b8478/userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0/sparklyr-2.0-2.11.jar to class loader
19/08/28 14:57:57 INFO CodeGenerator: Code generated in 379.177795 ms
19/08/28 14:57:57 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
19/08/28 14:57:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 877 ms on localhost (executor driver) (1/1)
19/08/28 14:57:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 14:57:57 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,900 s
19/08/28 14:57:57 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1,183717 s
19/08/28 14:57:57 INFO SparkSqlParser: Parsing command: iris
19/08/28 14:57:57 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 14:57:57 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 17.051023 ms
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 12.803377 ms
19/08/28 14:57:58 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:57:58 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 14:57:58 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:57:58 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 14:57:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 14:57:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 14:57:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 14:57:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:57:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 14:57:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57990 (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:57:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 14:57:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:57:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 12.667668 ms
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 51.747982 ms
19/08/28 14:57:58 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 14:57:58 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:57990 (size: 5.6 KB, free: 912.3 MB)
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 5.918345 ms
19/08/28 14:57:58 INFO CodeGenerator: Code generated in 35.946088 ms
19/08/28 14:57:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/08/28 14:57:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 304 ms on localhost (executor driver) (1/1)
19/08/28 14:57:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 14:57:58 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,307 s
19/08/28 14:57:58 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:57:58 INFO DAGScheduler: running: Set()
19/08/28 14:57:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 14:57:58 INFO DAGScheduler: failed: Set()
19/08/28 14:57:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 14:57:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:57:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:57:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:57:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 14:57:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:57:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 14:57:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:57:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
19/08/28 14:57:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:57990 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 14:57:58 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 14:57:58 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 14:57:58 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57990 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 14:57:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/08/28 14:57:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 304 ms on localhost (executor driver) (1/1)
19/08/28 14:57:58 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,305 s
19/08/28 14:57:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 14:57:58 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,682239 s
19/08/28 14:57:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 14:57:59 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:57:59 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:57:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:57:59 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 14:57:59 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:57:59 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 14:57:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 14:57:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 14:57:59 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 14:57:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57990 (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:57:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:59 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 14:57:59 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 14:57:59 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 14:57:59 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:57:59 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/08/28 14:57:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (executor driver) (1/1)
19/08/28 14:57:59 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,030 s
19/08/28 14:57:59 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:57:59 INFO DAGScheduler: running: Set()
19/08/28 14:57:59 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 14:57:59 INFO DAGScheduler: failed: Set()
19/08/28 14:57:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 14:57:59 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 14:57:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:57:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:59 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 14:57:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:57:59 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 14:57:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:57:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:57:59 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/08/28 14:57:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:57:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 14:57:59 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,008 s
19/08/28 14:57:59 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,073165 s
19/08/28 14:57:59 INFO CodeGenerator: Code generated in 9.863022 ms
19/08/28 14:57:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 14:57:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:57:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:57:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:57:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 14:57:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:57:59 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:57:59 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 14:57:59 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:57:59 INFO DAGScheduler: Missing parents: List()
19/08/28 14:57:59 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 14:57:59 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 14:57:59 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57990 (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:57:59 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 14:57:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:57:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 14:57:59 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:57:59 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 14:57:59 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:57:59 INFO CodeGenerator: Code generated in 61.01647 ms
19/08/28 14:58:00 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 14:58:00 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1355 bytes result sent to driver
19/08/28 14:58:00 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 139 ms on localhost (executor driver) (1/1)
19/08/28 14:58:00 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 14:58:00 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,144 s
19/08/28 14:58:00 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,160075 s
19/08/28 14:58:00 INFO CodeGenerator: Code generated in 9.601868 ms
19/08/28 14:58:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:58:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:01 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:01 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:01 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:01 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:01 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:01 INFO CodeGenerator: Code generated in 8.987567 ms
19/08/28 14:58:01 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:58:01 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 14:58:01 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 14:58:01 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:01 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:01 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 14:58:01 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 14:58:01 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 14:58:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57990 (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:58:01 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:01 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 14:58:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:01 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 14:58:01 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 934 bytes result sent to driver
19/08/28 14:58:01 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
19/08/28 14:58:01 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 14:58:01 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,008 s
19/08/28 14:58:01 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,025404 s
19/08/28 14:58:10 INFO SparkSqlParser: Parsing command: flights
19/08/28 14:58:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 14:58:10 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 14:58:10 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:58:10 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 14:58:10 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:58:10 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 14:58:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 14:58:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 14:58:10 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 14:58:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 14:58:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57990 (size: 11.7 KB, free: 912.3 MB)
19/08/28 14:58:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:10 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 14:58:11 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:58:11 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 14:58:12 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 14:58:12 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:57990 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 14:58:12 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 14:58:12 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:57990 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 14:58:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:57990 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 14:58:12 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 14:58:12 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 14:58:12 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 14:58:12 INFO CodeGenerator: Code generated in 18.862373 ms
19/08/28 14:58:12 INFO CodeGenerator: Code generated in 102.683232 ms
19/08/28 14:58:18 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 14:58:18 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:57990 (size: 22.5 MB, free: 889.8 MB)
19/08/28 14:58:18 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2371 bytes result sent to driver
19/08/28 14:58:18 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 7980 ms on localhost (executor driver) (1/1)
19/08/28 14:58:18 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 14:58:18 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 7,992 s
19/08/28 14:58:18 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:18 INFO DAGScheduler: running: Set()
19/08/28 14:58:18 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 14:58:18 INFO DAGScheduler: failed: Set()
19/08/28 14:58:18 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:18 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:58:18 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:58:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:58:18 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:18 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 14:58:18 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:18 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 14:58:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:58:18 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1495 bytes result sent to driver
19/08/28 14:58:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (executor driver) (1/1)
19/08/28 14:58:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 14:58:18 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,018 s
19/08/28 14:58:18 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 8,076185 s
19/08/28 14:58:18 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 14:58:18 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:18 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:19 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 14:58:19 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:19 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 14:58:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 14:58:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 14:58:19 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 14:58:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 14:58:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57990 (size: 11.8 KB, free: 889.8 MB)
19/08/28 14:58:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 14:58:19 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:58:19 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 14:58:19 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:58:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 14:58:19 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:58:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 14:58:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 684 ms on localhost (executor driver) (1/1)
19/08/28 14:58:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 14:58:19 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,696 s
19/08/28 14:58:19 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:19 INFO DAGScheduler: running: Set()
19/08/28 14:58:19 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 14:58:19 INFO DAGScheduler: failed: Set()
19/08/28 14:58:19 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 14:58:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 14:58:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:58:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 14:58:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 14:58:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1495 bytes result sent to driver
19/08/28 14:58:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:58:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 14:58:19 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,026 s
19/08/28 14:58:19 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,763108 s
19/08/28 14:58:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 14:58:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:20 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:58:20 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 14:58:20 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 14:58:20 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:20 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:20 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 14:58:20 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 14:58:20 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 14:58:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:57990 (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:58:20 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 14:58:20 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 14:58:20 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:20 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:20 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 14:58:20 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 14:58:20 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 934 bytes result sent to driver
19/08/28 14:58:20 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 980 bytes result sent to driver
19/08/28 14:58:20 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 42 ms on localhost (executor driver) (1/2)
19/08/28 14:58:20 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 44 ms on localhost (executor driver) (2/2)
19/08/28 14:58:20 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 14:58:20 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,046 s
19/08/28 14:58:20 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,079561 s
19/08/28 14:58:26 INFO SparkSqlParser: Parsing command: batting
19/08/28 14:58:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 14:58:26 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 14:58:26 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:58:26 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 14:58:26 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:58:26 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 14:58:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 14:58:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 14:58:26 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.7 MB)
19/08/28 14:58:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 14:58:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:57990 (size: 11.6 KB, free: 889.8 MB)
19/08/28 14:58:26 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:26 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 14:58:26 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:26 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:58:26 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 14:58:26 INFO CodeGenerator: Code generated in 33.857998 ms
19/08/28 14:58:26 INFO CodeGenerator: Code generated in 182.389112 ms
19/08/28 14:58:28 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 14:58:28 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 14:58:28 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 14:58:28 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:57990 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 14:58:30 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 14:58:30 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:57990 (size: 3.4 MB, free: 886.4 MB)
19/08/28 14:58:30 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 14:58:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 4459 ms on localhost (executor driver) (1/1)
19/08/28 14:58:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 14:58:30 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 4,462 s
19/08/28 14:58:30 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:30 INFO DAGScheduler: running: Set()
19/08/28 14:58:30 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 14:58:30 INFO DAGScheduler: failed: Set()
19/08/28 14:58:30 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:30 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 14:58:30 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 14:58:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.4 MB)
19/08/28 14:58:31 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:31 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 14:58:31 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:31 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 14:58:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:31 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1538 bytes result sent to driver
19/08/28 14:58:31 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:58:31 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 14:58:31 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,018 s
19/08/28 14:58:31 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 4,587766 s
19/08/28 14:58:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 14:58:31 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:31 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:31 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 14:58:31 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:31 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 14:58:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 14:58:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 14:58:31 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.2 MB)
19/08/28 14:58:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.2 MB)
19/08/28 14:58:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:57990 (size: 11.6 KB, free: 886.4 MB)
19/08/28 14:58:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:31 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 14:58:31 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:31 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 14:58:31 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 14:58:31 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 14:58:31 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1690 bytes result sent to driver
19/08/28 14:58:31 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 205 ms on localhost (executor driver) (1/1)
19/08/28 14:58:31 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 14:58:31 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,208 s
19/08/28 14:58:31 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:31 INFO DAGScheduler: running: Set()
19/08/28 14:58:31 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 14:58:31 INFO DAGScheduler: failed: Set()
19/08/28 14:58:31 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:31 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.2 MB)
19/08/28 14:58:31 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.2 MB)
19/08/28 14:58:31 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:31 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:31 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 14:58:31 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:31 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 14:58:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:31 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1495 bytes result sent to driver
19/08/28 14:58:31 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 13 ms on localhost (executor driver) (1/1)
19/08/28 14:58:31 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 14:58:31 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,018 s
19/08/28 14:58:31 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,256179 s
19/08/28 14:58:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 14:58:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 14:58:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:58:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:58:32 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:58:32 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:58:32 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 14:58:32 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:32 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:32 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 14:58:32 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.1 MB)
19/08/28 14:58:32 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.1 MB)
19/08/28 14:58:32 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:57990 (size: 34.7 KB, free: 886.3 MB)
19/08/28 14:58:32 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:32 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 14:58:32 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 14:58:32 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 14:58:32 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 14:58:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 14:58:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 14:58:32 INFO FileOutputCommitter: Saved output of task 'attempt_20190828145832_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/Rtmp6Z5GME/file2ad82f273bef.csv/_temporary/0/task_20190828145832_0016_m_000000
19/08/28 14:58:32 INFO SparkHadoopMapRedUtil: attempt_20190828145832_0016_m_000000_0: Committed
19/08/28 14:58:32 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 14:58:32 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 330 ms on localhost (executor driver) (1/1)
19/08/28 14:58:32 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 14:58:32 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,331 s
19/08/28 14:58:32 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,370197 s
19/08/28 14:58:32 INFO FileFormatWriter: Job null committed.
19/08/28 14:58:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:32 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:32 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:32 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:32 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:32 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:32 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:58:32 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 14:58:32 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 14:58:32 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:32 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:32 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 14:58:32 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.1 MB)
19/08/28 14:58:32 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.1 MB)
19/08/28 14:58:32 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:57990 (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:58:32 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 14:58:32 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 14:58:32 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:32 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:32 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:32 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 14:58:32 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 14:58:32 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 14:58:32 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 894 bytes result sent to driver
19/08/28 14:58:32 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 894 bytes result sent to driver
19/08/28 14:58:32 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 8 ms on localhost (executor driver) (1/3)
19/08/28 14:58:32 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 891 bytes result sent to driver
19/08/28 14:58:32 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 8 ms on localhost (executor driver) (2/3)
19/08/28 14:58:32 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 8 ms on localhost (executor driver) (3/3)
19/08/28 14:58:32 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 14:58:32 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,010 s
19/08/28 14:58:32 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,017675 s
19/08/28 14:58:33 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:58:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 14:58:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:58:33 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:58:33 INFO CodeGenerator: Code generated in 12.879025 ms
19/08/28 14:58:33 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 885.8 MB)
19/08/28 14:58:33 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.8 MB)
19/08/28 14:58:33 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:57990 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 14:58:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:58:33 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:58:33 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:58:33 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 14:58:33 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:33 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:33 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 14:58:33 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 885.8 MB)
19/08/28 14:58:33 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 885.8 MB)
19/08/28 14:58:33 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:57990 (size: 4.3 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:33 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 14:58:33 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:58:33 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned shuffle 4
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 521
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 386
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 385
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 384
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 375
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 377
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:57990 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 376
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:57990 in memory (size: 3.5 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/Rtmp6Z5GME/file2ad82f273bef.csv/part-00000-dabc8502-9488-4729-b974-86cc0bf64814-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 378
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 380
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 381
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 383
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:57990 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 382
19/08/28 14:58:33 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:57990 in memory (size: 34.7 KB, free: 886.4 MB)
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 14:58:33 INFO ContextCleaner: Cleaned accumulator 379
19/08/28 14:58:33 INFO CodeGenerator: Code generated in 13.353435 ms
19/08/28 14:58:33 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1308 bytes result sent to driver
19/08/28 14:58:33 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 117 ms on localhost (executor driver) (1/1)
19/08/28 14:58:33 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 14:58:33 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,119 s
19/08/28 14:58:33 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,136264 s
19/08/28 14:58:33 INFO CodeGenerator: Code generated in 6.191663 ms
19/08/28 14:58:33 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:58:33 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:58:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 14:58:33 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:58:33 INFO CodeGenerator: Code generated in 5.979927 ms
19/08/28 14:58:33 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.7 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.7 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:57990 (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 14:58:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:58:34 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 14:58:34 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 14:58:34 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 14:58:34 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:34 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:34 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.7 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.7 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:57990 (size: 8.2 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 14:58:34 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/Rtmp6Z5GME/file2ad82f273bef.csv/part-00000-dabc8502-9488-4729-b974-86cc0bf64814-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1538 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 46 ms on localhost (executor driver) (1/1)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,046 s
19/08/28 14:58:34 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,059324 s
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:34 INFO CodeGenerator: Code generated in 10.639261 ms
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 14:58:34 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 14:58:34 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 14:58:34 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 14:58:34 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.4 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.4 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:57990 (size: 24.1 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 14:58:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 14:58:34 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:58:34 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 14:58:34 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:58:34 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 14:58:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 14:58:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 14:58:34 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.4 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.4 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:57990 (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 14:58:34 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/Rtmp6Z5GME/file2ad82f273bef.csv/part-00000-dabc8502-9488-4729-b974-86cc0bf64814-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 14:58:34 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 885.4 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:57990 (size: 5.6 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2418 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 78 ms on localhost (executor driver) (1/1)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,079 s
19/08/28 14:58:34 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:34 INFO DAGScheduler: running: Set()
19/08/28 14:58:34 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 14:58:34 INFO DAGScheduler: failed: Set()
19/08/28 14:58:34 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 885.3 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.3 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 14:58:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1495 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 7 ms on localhost (executor driver) (1/1)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,008 s
19/08/28 14:58:34 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,106827 s
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:34 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 14:58:34 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:34 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 14:58:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 14:58:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 14:58:34 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 885.3 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.3 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:57990 (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 14:58:34 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1737 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 14 ms on localhost (executor driver) (1/1)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,015 s
19/08/28 14:58:34 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:34 INFO DAGScheduler: running: Set()
19/08/28 14:58:34 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 14:58:34 INFO DAGScheduler: failed: Set()
19/08/28 14:58:34 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.3 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.3 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 14:58:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1495 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 5 ms on localhost (executor driver) (1/1)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,007 s
19/08/28 14:58:34 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,041301 s
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 14:58:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:34 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:34 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:58:34 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 14:58:34 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 14:58:34 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:34 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:34 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.3 MB)
19/08/28 14:58:34 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.3 MB)
19/08/28 14:58:34 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:57990 (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:58:34 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:58:34 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 14:58:34 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:34 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:34 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:34 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:34 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 14:58:34 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 14:58:34 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 14:58:34 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 14:58:34 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 14:58:34 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 891 bytes result sent to driver
19/08/28 14:58:34 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 895 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 11 ms on localhost (executor driver) (1/4)
19/08/28 14:58:34 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 11 ms on localhost (executor driver) (2/4)
19/08/28 14:58:34 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 13 ms on localhost (executor driver) (3/4)
19/08/28 14:58:34 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 14:58:34 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 13 ms on localhost (executor driver) (4/4)
19/08/28 14:58:34 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 14:58:34 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,015 s
19/08/28 14:58:34 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,025282 s
19/08/28 14:58:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:58:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:58:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:58:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 14:58:35 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1479 - dep_delay.nullCount#1478) > 0)
19/08/28 14:58:35 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1477 <= 2.0) && (2.0 <= dep_delay.upperBound#1476))
19/08/28 14:58:35 INFO CodeGenerator: Code generated in 11.875845 ms
19/08/28 14:58:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:35 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:35 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/08/28 14:58:35 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:35 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:35 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:35 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.7 KB, free 885.3 MB)
19/08/28 14:58:35 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 885.2 MB)
19/08/28 14:58:35 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:57990 (size: 12.5 KB, free: 886.2 MB)
19/08/28 14:58:35 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:35 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 14:58:35 WARN TaskSetManager: Stage 25 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:35 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 14:58:35 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
19/08/28 14:58:35 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:58:35 INFO CodeGenerator: Code generated in 12.805278 ms
19/08/28 14:58:35 INFO CodeGenerator: Code generated in 26.463963 ms
19/08/28 14:58:35 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_33_0]
19/08/28 14:58:35 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2273 bytes result sent to driver
19/08/28 14:58:35 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 417 ms on localhost (executor driver) (1/1)
19/08/28 14:58:35 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 14:58:35 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0,418 s
19/08/28 14:58:35 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0,436219 s
19/08/28 14:58:35 INFO CodeGenerator: Code generated in 13.829746 ms
19/08/28 14:58:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 14:58:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `qmxejwzntg`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `sjhnhrgidu`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `yimygusmkl`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `fsfzxrptdu`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:36 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:36 INFO CodeGenerator: Code generated in 31.984305 ms
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 46.133745 ms
19/08/28 14:58:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:37 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:204)
19/08/28 14:58:37 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:37 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/08/28 14:58:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/08/28 14:58:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/08/28 14:58:37 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:37 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 50.3 KB, free 885.2 MB)
19/08/28 14:58:37 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KB, free 885.2 MB)
19/08/28 14:58:37 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:57990 (size: 19.8 KB, free: 886.2 MB)
19/08/28 14:58:37 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:37 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 14:58:37 WARN TaskSetManager: Stage 26 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:37 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:58:37 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 758
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 678
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 684
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 679
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 674
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:57990 in memory (size: 8.2 KB, free: 886.2 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned shuffle 6
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:57990 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:57990 in memory (size: 4.3 KB, free: 886.2 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 680
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:57990 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:57990 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 759
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 673
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 683
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:57990 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 760
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:57990 in memory (size: 12.5 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 677
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 733
19/08/28 14:58:37 INFO ContextCleaner: Cleaned shuffle 7
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 681
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:57990 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 682
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 676
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 785
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 14:58:37 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:57990 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 675
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 14:58:37 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 14:58:37 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 17.078393 ms
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 7.207008 ms
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 8.462219 ms
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 7.65823 ms
19/08/28 14:58:37 INFO CodeGenerator: Code generated in 11.467578 ms
19/08/28 14:58:38 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1964 bytes result sent to driver
19/08/28 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 942 ms on localhost (executor driver) (1/1)
19/08/28 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 14:58:38 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0,942 s
19/08/28 14:58:38 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:38 INFO DAGScheduler: running: Set()
19/08/28 14:58:38 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/08/28 14:58:38 INFO DAGScheduler: failed: Set()
19/08/28 14:58:38 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:38 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 27.0 KB, free 885.9 MB)
19/08/28 14:58:38 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.9 MB)
19/08/28 14:58:38 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:57990 (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:38 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:38 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:38 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
19/08/28 14:58:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:38 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 33
19/08/28 14:58:38 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 2648 bytes result sent to driver
19/08/28 14:58:38 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 26 ms on localhost (executor driver) (1/1)
19/08/28 14:58:38 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 14:58:38 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0,026 s
19/08/28 14:58:38 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0,987959 s
19/08/28 14:58:38 INFO CodeGenerator: Code generated in 7.450675 ms
19/08/28 14:58:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `aadoecfhik`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `gsevcgelkz`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `gsylykufmm`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:38 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/08/28 14:58:38 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 4 output partitions
19/08/28 14:58:38 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/08/28 14:58:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/08/28 14:58:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/08/28 14:58:38 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:38 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 14:58:38 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.0 KB, free 885.8 MB)
19/08/28 14:58:38 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:57990 (size: 20.0 KB, free: 886.3 MB)
19/08/28 14:58:38 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:38 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 14:58:38 WARN TaskSetManager: Stage 28 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 14:58:38 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 14:58:38 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
19/08/28 14:58:38 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 14:58:39 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 1921 bytes result sent to driver
19/08/28 14:58:39 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 480 ms on localhost (executor driver) (1/1)
19/08/28 14:58:39 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 14:58:39 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0,481 s
19/08/28 14:58:39 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:39 INFO DAGScheduler: running: Set()
19/08/28 14:58:39 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/08/28 14:58:39 INFO DAGScheduler: failed: Set()
19/08/28 14:58:39 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:39 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 27.2 KB, free 885.8 MB)
19/08/28 14:58:39 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.8 MB)
19/08/28 14:58:39 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:57990 (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:39 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:58:39 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
19/08/28 14:58:39 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:39 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 36, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 14:58:39 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 37, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 14:58:39 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 38, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 14:58:39 INFO Executor: Running task 3.0 in stage 29.0 (TID 38)
19/08/28 14:58:39 INFO Executor: Running task 2.0 in stage 29.0 (TID 37)
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:39 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:39 INFO Executor: Finished task 3.0 in stage 29.0 (TID 38). 20799 bytes result sent to driver
19/08/28 14:58:39 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 38) in 33 ms on localhost (executor driver) (1/4)
19/08/28 14:58:39 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 21599 bytes result sent to driver
19/08/28 14:58:39 INFO Executor: Running task 1.0 in stage 29.0 (TID 36)
19/08/28 14:58:39 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 34 ms on localhost (executor driver) (2/4)
19/08/28 14:58:39 INFO Executor: Finished task 2.0 in stage 29.0 (TID 37). 22745 bytes result sent to driver
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:39 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 37) in 38 ms on localhost (executor driver) (3/4)
19/08/28 14:58:39 INFO Executor: Finished task 1.0 in stage 29.0 (TID 36). 21775 bytes result sent to driver
19/08/28 14:58:39 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 36) in 46 ms on localhost (executor driver) (4/4)
19/08/28 14:58:39 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 14:58:39 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0,049 s
19/08/28 14:58:39 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0,544166 s
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 14:58:41 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:41 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 14:58:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 14:58:41 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 14:58:41 INFO DAGScheduler: Got job 20 (collect at utils.scala:44) with 4 output partitions
19/08/28 14:58:41 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
19/08/28 14:58:41 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:41 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:41 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41), which has no missing parents
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.5 KB, free 885.8 MB)
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.8 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:57990 (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 14:58:41 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/08/28 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:41 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:41 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:41 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 14:58:41 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
19/08/28 14:58:41 INFO Executor: Running task 1.0 in stage 30.0 (TID 40)
19/08/28 14:58:41 INFO Executor: Running task 2.0 in stage 30.0 (TID 41)
19/08/28 14:58:41 INFO Executor: Running task 3.0 in stage 30.0 (TID 42)
19/08/28 14:58:41 INFO Executor: Finished task 1.0 in stage 30.0 (TID 40). 851 bytes result sent to driver
19/08/28 14:58:41 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 894 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 40) in 8 ms on localhost (executor driver) (1/4)
19/08/28 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 8 ms on localhost (executor driver) (2/4)
19/08/28 14:58:41 INFO Executor: Finished task 2.0 in stage 30.0 (TID 41). 891 bytes result sent to driver
19/08/28 14:58:41 INFO Executor: Finished task 3.0 in stage 30.0 (TID 42). 895 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 42) in 16 ms on localhost (executor driver) (3/4)
19/08/28 14:58:41 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 41) in 19 ms on localhost (executor driver) (4/4)
19/08/28 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 14:58:41 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0,022 s
19/08/28 14:58:41 INFO DAGScheduler: Job 20 finished: collect at utils.scala:44, took 0,032701 s
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 14:58:41 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 14:58:41 INFO DAGScheduler: Registering RDD 131 (sql at <unknown>:0)
19/08/28 14:58:41 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/08/28 14:58:41 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
19/08/28 14:58:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 14:58:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 14:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 22.4 KB, free 885.8 MB)
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.8 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:57990 (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:41 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:58:41 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
19/08/28 14:58:41 INFO CodeGenerator: Code generated in 10.77687 ms
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 790
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 852
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 860
19/08/28 14:58:41 INFO ContextCleaner: Cleaned shuffle 9
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 787
19/08/28 14:58:41 INFO CodeGenerator: Code generated in 61.560445 ms
19/08/28 14:58:41 INFO MemoryStore: Block rdd_128_0 stored as values in memory (estimated size 4.2 KB, free 885.8 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:57990 in memory (size: 20.0 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 798
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 794
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 855
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 853
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 859
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 793
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 851
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 791
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 795
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 792
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 848
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 788
19/08/28 14:58:41 INFO BlockManagerInfo: Added rdd_128_0 in memory on 127.0.0.1:57990 (size: 4.2 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:57990 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2285 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 109 ms on localhost (executor driver) (1/1)
19/08/28 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 14:58:41 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0,110 s
19/08/28 14:58:41 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:41 INFO DAGScheduler: running: Set()
19/08/28 14:58:41 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 14:58:41 INFO DAGScheduler: failed: Set()
19/08/28 14:58:41 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 858
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 789
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 797
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 849
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:41 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:41 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
19/08/28 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:41 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 1452 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
19/08/28 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 14:58:41 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0,005 s
19/08/28 14:58:41 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0,128657 s
19/08/28 14:58:41 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:57990 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 14:58:41 INFO HiveMetaStore: 0: get_database: default
19/08/28 14:58:41 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 14:58:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:57990 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO ContextCleaner: Cleaned shuffle 8
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 856
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 936
19/08/28 14:58:41 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:57990 in memory (size: 19.8 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 786
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 796
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 847
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 854
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 850
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 909
19/08/28 14:58:41 INFO ContextCleaner: Cleaned accumulator 857
19/08/28 14:58:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 14:58:41 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:204)
19/08/28 14:58:41 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/08/28 14:58:41 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/08/28 14:58:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 14:58:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 14:58:41 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 22.4 KB, free 885.9 MB)
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.9 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:57990 (size: 9.3 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:41 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:58:41 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
19/08/28 14:58:41 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:41 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 1647 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 14 ms on localhost (executor driver) (1/1)
19/08/28 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 14:58:41 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0,014 s
19/08/28 14:58:41 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:41 INFO DAGScheduler: running: Set()
19/08/28 14:58:41 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 14:58:41 INFO DAGScheduler: failed: Set()
19/08/28 14:58:41 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 14:58:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 14:58:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.3 MB)
19/08/28 14:58:41 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:41 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 14:58:41 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:41 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
19/08/28 14:58:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:41 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 1495 bytes result sent to driver
19/08/28 14:58:41 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 11 ms on localhost (executor driver) (1/1)
19/08/28 14:58:41 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 14:58:41 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0,011 s
19/08/28 14:58:41 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0,039037 s
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad82a71664
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad82a71664` AS `zzz6`
WHERE (0 = 1)
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad8552d7da3
19/08/28 14:58:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad8552d7da3` AS `zzz7`
WHERE (0 = 1)
19/08/28 14:58:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad82a71664`
19/08/28 14:58:42 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2292 - hp.nullCount#2291) > 0)
19/08/28 14:58:42 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2289)
19/08/28 14:58:42 INFO CodeGenerator: Code generated in 36.893768 ms
19/08/28 14:58:42 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 14:58:42 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 14:58:42 INFO DAGScheduler: Final stage: ResultStage 35 (first at LinearRegression.scala:198)
19/08/28 14:58:42 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:42 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:42 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 14:58:42 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 41.3 KB, free 885.9 MB)
19/08/28 14:58:42 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.4 KB, free 885.9 MB)
19/08/28 14:58:42 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:57990 (size: 16.4 KB, free: 886.3 MB)
19/08/28 14:58:42 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:42 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 14:58:42 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:58:42 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
19/08/28 14:58:42 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:42 INFO CodeGenerator: Code generated in 8.66141 ms
19/08/28 14:58:42 INFO CodeGenerator: Code generated in 14.963693 ms
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 20.888881 ms
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 11.486585 ms
19/08/28 14:58:43 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 1743 bytes result sent to driver
19/08/28 14:58:43 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 148 ms on localhost (executor driver) (1/1)
19/08/28 14:58:43 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 14:58:43 INFO DAGScheduler: ResultStage 35 (first at LinearRegression.scala:198) finished in 0,148 s
19/08/28 14:58:43 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0,155561 s
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 9.179156 ms
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2353 - hp.nullCount#2352) > 0)
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2350)
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 26.861966 ms
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2409 - hp.nullCount#2408) > 0)
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2406)
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 30.389252 ms
19/08/28 14:58:43 INFO Instrumentation: LinearRegression-linear_regression_2ad83b884c4a-1264412340-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 14:58:43 INFO Instrumentation: LinearRegression-linear_regression_2ad83b884c4a-1264412340-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 14:58:43 INFO Instrumentation: LinearRegression-linear_regression_2ad83b884c4a-1264412340-1: {"numFeatures":2}
19/08/28 14:58:43 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 14:58:43 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 14:58:43 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 14:58:43 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 14:58:43 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:43 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:43 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 14:58:43 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 885.8 MB)
19/08/28 14:58:43 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.6 KB, free 885.8 MB)
19/08/28 14:58:43 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:57990 (size: 17.6 KB, free: 886.3 MB)
19/08/28 14:58:43 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:43 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/08/28 14:58:43 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:58:43 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
19/08/28 14:58:43 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 5.630962 ms
19/08/28 14:58:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 14:58:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 14:58:43 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 2184 bytes result sent to driver
19/08/28 14:58:43 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 138 ms on localhost (executor driver) (1/1)
19/08/28 14:58:43 INFO DAGScheduler: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,140 s
19/08/28 14:58:43 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,286957 s
19/08/28 14:58:43 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/08/28 14:58:43 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 14:58:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 14:58:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2486 - hp.nullCount#2485) > 0)
19/08/28 14:58:43 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2483)
19/08/28 14:58:43 INFO CodeGenerator: Code generated in 22.470248 ms
19/08/28 14:58:43 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 14:58:44 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 14:58:44 INFO DAGScheduler: Final stage: ResultStage 37 (aggregate at RegressionMetrics.scala:57)
19/08/28 14:58:44 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:44 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:44 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.2 KB, free 885.8 MB)
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.9 KB, free 885.7 MB)
19/08/28 14:58:44 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:57990 (size: 17.9 KB, free: 886.3 MB)
19/08/28 14:58:44 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:44 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/08/28 14:58:44 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:58:44 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
19/08/28 14:58:44 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:44 INFO CodeGenerator: Code generated in 5.172898 ms
19/08/28 14:58:44 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2180 bytes result sent to driver
19/08/28 14:58:44 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 35 ms on localhost (executor driver) (1/1)
19/08/28 14:58:44 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/08/28 14:58:44 INFO DAGScheduler: ResultStage 37 (aggregate at RegressionMetrics.scala:57) finished in 0,037 s
19/08/28 14:58:44 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0,062754 s
19/08/28 14:58:44 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 14:58:44 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 14:58:44 INFO DAGScheduler: Final stage: ResultStage 38 (sum at RegressionMetrics.scala:71)
19/08/28 14:58:44 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:44 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:44 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 43.8 KB, free 885.7 MB)
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.7 MB)
19/08/28 14:58:44 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:57990 (size: 17.8 KB, free: 886.3 MB)
19/08/28 14:58:44 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:44 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/08/28 14:58:44 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:58:44 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
19/08/28 14:58:44 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:44 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 1654 bytes result sent to driver
19/08/28 14:58:44 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 12 ms on localhost (executor driver) (1/1)
19/08/28 14:58:44 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/08/28 14:58:44 INFO DAGScheduler: ResultStage 38 (sum at RegressionMetrics.scala:71) finished in 0,013 s
19/08/28 14:58:44 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0,036096 s
19/08/28 14:58:44 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2561 - hp.nullCount#2560) > 0)
19/08/28 14:58:44 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2558)
19/08/28 14:58:44 INFO CodeGenerator: Code generated in 18.521391 ms
19/08/28 14:58:44 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 14:58:44 INFO DAGScheduler: Registering RDD 163 (count at LinearRegression.scala:696)
19/08/28 14:58:44 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 14:58:44 INFO DAGScheduler: Final stage: ResultStage 40 (count at LinearRegression.scala:696)
19/08/28 14:58:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/08/28 14:58:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/08/28 14:58:44 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 36.6 KB, free 885.7 MB)
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.6 MB)
19/08/28 14:58:44 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:57990 (size: 14.8 KB, free: 886.2 MB)
19/08/28 14:58:44 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:44 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/08/28 14:58:44 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:58:44 INFO Executor: Running task 0.0 in stage 39.0 (TID 51)
19/08/28 14:58:44 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:44 INFO Executor: Finished task 0.0 in stage 39.0 (TID 51). 2275 bytes result sent to driver
19/08/28 14:58:44 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 51) in 17 ms on localhost (executor driver) (1/1)
19/08/28 14:58:44 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/08/28 14:58:44 INFO DAGScheduler: ShuffleMapStage 39 (count at LinearRegression.scala:696) finished in 0,018 s
19/08/28 14:58:44 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:44 INFO DAGScheduler: running: Set()
19/08/28 14:58:44 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/08/28 14:58:44 INFO DAGScheduler: failed: Set()
19/08/28 14:58:44 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 885.6 MB)
19/08/28 14:58:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.6 MB)
19/08/28 14:58:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:58:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:44 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/08/28 14:58:44 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 52, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:44 INFO Executor: Running task 0.0 in stage 40.0 (TID 52)
19/08/28 14:58:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 14:58:44 INFO Executor: Finished task 0.0 in stage 40.0 (TID 52). 1495 bytes result sent to driver
19/08/28 14:58:44 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
19/08/28 14:58:44 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/08/28 14:58:44 INFO DAGScheduler: ResultStage 40 (count at LinearRegression.scala:696) finished in 0,005 s
19/08/28 14:58:44 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:696, took 0,039235 s
19/08/28 14:58:44 INFO Instrumentation: LinearRegression-linear_regression_2ad83b884c4a-1264412340-1: training finished
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad81ab3231f
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad81ab3231f` AS `zzz8`
WHERE (0 = 1)
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad82a71664`
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad868f0463f
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad868f0463f` AS `zzz9`
WHERE (0 = 1)
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad868f0463f`
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad84d843c50
19/08/28 14:58:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad84d843c50` AS `zzz10`
WHERE (0 = 1)
19/08/28 14:58:45 INFO SparkSqlParser: Parsing command: sparklyr_tmp_2ad86f407780
19/08/28 14:58:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad86f407780` AS `zzz11`
WHERE (0 = 1)
19/08/28 14:58:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_2ad86f407780`
19/08/28 14:58:45 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2783 - hp.nullCount#2782) > 0)
19/08/28 14:58:45 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2780)
19/08/28 14:58:45 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 14:58:45 INFO DAGScheduler: Registering RDD 169 (count at <unknown>:0)
19/08/28 14:58:45 INFO DAGScheduler: Got job 28 (count at <unknown>:0) with 1 output partitions
19/08/28 14:58:45 INFO DAGScheduler: Final stage: ResultStage 42 (count at <unknown>:0)
19/08/28 14:58:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/08/28 14:58:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/08/28 14:58:45 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 36.6 KB, free 885.6 MB)
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.6 MB)
19/08/28 14:58:45 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:57990 (size: 14.8 KB, free: 886.2 MB)
19/08/28 14:58:45 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:45 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/08/28 14:58:45 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 14:58:45 INFO Executor: Running task 0.0 in stage 41.0 (TID 53)
19/08/28 14:58:45 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:45 INFO Executor: Finished task 0.0 in stage 41.0 (TID 53). 2275 bytes result sent to driver
19/08/28 14:58:45 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 53) in 83 ms on localhost (executor driver) (1/1)
19/08/28 14:58:45 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/08/28 14:58:45 INFO DAGScheduler: ShuffleMapStage 41 (count at <unknown>:0) finished in 0,089 s
19/08/28 14:58:45 INFO DAGScheduler: looking for newly runnable stages
19/08/28 14:58:45 INFO DAGScheduler: running: Set()
19/08/28 14:58:45 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/08/28 14:58:45 INFO DAGScheduler: failed: Set()
19/08/28 14:58:45 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0), which has no missing parents
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 885.6 MB)
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.6 MB)
19/08/28 14:58:45 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:57990 (size: 3.7 KB, free: 886.2 MB)
19/08/28 14:58:45 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:45 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/08/28 14:58:45 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 14:58:45 INFO Executor: Running task 0.0 in stage 42.0 (TID 54)
19/08/28 14:58:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 14:58:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 14:58:45 INFO Executor: Finished task 0.0 in stage 42.0 (TID 54). 1538 bytes result sent to driver
19/08/28 14:58:45 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 54) in 16 ms on localhost (executor driver) (1/1)
19/08/28 14:58:45 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/08/28 14:58:45 INFO DAGScheduler: ResultStage 42 (count at <unknown>:0) finished in 0,016 s
19/08/28 14:58:45 INFO DAGScheduler: Job 28 finished: count at <unknown>:0, took 0,125086 s
19/08/28 14:58:45 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2843 - hp.nullCount#2842) > 0)
19/08/28 14:58:45 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2840)
19/08/28 14:58:45 INFO CodeGenerator: Code generated in 27.513139 ms
19/08/28 14:58:45 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 14:58:45 INFO DAGScheduler: Got job 29 (collect at utils.scala:37) with 1 output partitions
19/08/28 14:58:45 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:37)
19/08/28 14:58:45 INFO DAGScheduler: Parents of final stage: List()
19/08/28 14:58:45 INFO DAGScheduler: Missing parents: List()
19/08/28 14:58:45 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34), which has no missing parents
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 885.5 MB)
19/08/28 14:58:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.5 MB)
19/08/28 14:58:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:57990 (size: 19.3 KB, free: 886.2 MB)
19/08/28 14:58:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/08/28 14:58:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 14:58:45 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/08/28 14:58:45 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 14:58:45 INFO Executor: Running task 0.0 in stage 43.0 (TID 55)
19/08/28 14:58:45 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 14:58:45 INFO CodeGenerator: Code generated in 5.73588 ms
19/08/28 14:58:45 INFO Executor: Finished task 0.0 in stage 43.0 (TID 55). 1747 bytes result sent to driver
19/08/28 14:58:45 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 55) in 29 ms on localhost (executor driver) (1/1)
19/08/28 14:58:45 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/08/28 14:58:45 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:37) finished in 0,029 s
19/08/28 14:58:45 INFO DAGScheduler: Job 29 finished: collect at utils.scala:37, took 0,103047 s
19/08/28 14:58:48 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 14:58:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 14:58:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 14:58:48 INFO MemoryStore: MemoryStore cleared
19/08/28 14:58:48 INFO BlockManager: BlockManager stopped
19/08/28 14:58:48 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 14:58:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 14:58:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:58:48 INFO SparkContext: Successfully stopped SparkContext
19/08/28 14:58:48 INFO ShutdownHookManager: Shutdown hook called
19/08/28 14:58:48 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0
19/08/28 14:58:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478\userFiles-3be89fe7-7804-43f8-8834-ae6e7d4306d0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 14:58:48 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478
19/08/28 14:58:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-309a971d-2136-4e80-9090-8100d24b8478
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:02:09 INFO SparkContext: Running Spark version 2.2.0
19/08/28 15:02:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 15:02:09 INFO SparkContext: Submitted application: sparklyr
19/08/28 15:02:09 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 15:02:09 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 15:02:09 INFO SecurityManager: Changing view acls groups to: 
19/08/28 15:02:09 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 15:02:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 15:02:09 INFO Utils: Successfully started service 'sparkDriver' on port 58076.
19/08/28 15:02:09 INFO SparkEnv: Registering MapOutputTracker
19/08/28 15:02:09 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 15:02:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 15:02:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 15:02:10 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-cc12f4eb-d752-4304-886e-deb2af6310f7
19/08/28 15:02:10 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 15:02:10 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 15:02:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 15:02:10 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 15:02:10 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 15:02:10 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:58076/jars/sparklyr-2.0-2.11.jar with timestamp 1566997330574
19/08/28 15:02:10 INFO Executor: Starting executor ID driver on host localhost
19/08/28 15:02:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58097.
19/08/28 15:02:10 INFO NettyBlockTransferService: Server created on 127.0.0.1:58097
19/08/28 15:02:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 15:02:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58097, None)
19/08/28 15:02:10 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58097 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 58097, None)
19/08/28 15:02:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58097, None)
19/08/28 15:02:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58097, None)
19/08/28 15:02:11 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 15:02:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 15:02:11 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 15:02:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 15:02:13 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 15:02:13 INFO ObjectStore: ObjectStore, initialize called
19/08/28 15:02:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 15:02:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 15:02:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 15:02:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:02:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:02:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:02:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:02:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 15:02:17 INFO ObjectStore: Initialized ObjectStore
19/08/28 15:02:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 15:02:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 15:02:17 INFO HiveMetaStore: Added admin role in metastore
19/08/28 15:02:17 INFO HiveMetaStore: Added public role in metastore
19/08/28 15:02:17 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 15:02:17 INFO HiveMetaStore: 0: get_all_databases
19/08/28 15:02:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 15:02:17 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 15:02:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 15:02:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:02:17 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/8199b705-e40d-460c-9ff5-5629b4e91a81_resources
19/08/28 15:02:17 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/8199b705-e40d-460c-9ff5-5629b4e91a81
19/08/28 15:02:17 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/8199b705-e40d-460c-9ff5-5629b4e91a81
19/08/28 15:02:17 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/8199b705-e40d-460c-9ff5-5629b4e91a81/_tmp_space.db
19/08/28 15:02:17 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:02:17 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:17 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 15:02:17 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 15:02:17 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 15:02:18 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/ed20687f-3df9-4db5-9d4e-349be219f0c2_resources
19/08/28 15:02:18 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/ed20687f-3df9-4db5-9d4e-349be219f0c2
19/08/28 15:02:18 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/ed20687f-3df9-4db5-9d4e-349be219f0c2
19/08/28 15:02:18 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/ed20687f-3df9-4db5-9d4e-349be219f0c2/_tmp_space.db
19/08/28 15:02:18 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:02:18 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 15:02:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:20 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:20 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:21 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:21 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:02:21 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 15:02:21 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:21 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 15:02:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 15:02:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:58097 (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:02:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 15:02:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 15:02:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 15:02:21 INFO Executor: Fetching spark://127.0.0.1:58076/jars/sparklyr-2.0-2.11.jar with timestamp 1566997330574
19/08/28 15:02:21 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:58076 after 21 ms (0 ms spent in bootstraps)
19/08/28 15:02:21 INFO Utils: Fetching spark://127.0.0.1:58076/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f\fetchFileTemp2013902383712028448.tmp
19/08/28 15:02:21 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-433d21eb-a49a-4d41-adae-2e8038e25651/userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f/sparklyr-2.0-2.11.jar to class loader
19/08/28 15:02:22 INFO CodeGenerator: Code generated in 238.629927 ms
19/08/28 15:02:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/08/28 15:02:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 716 ms on localhost (executor driver) (1/1)
19/08/28 15:02:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 15:02:22 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,740 s
19/08/28 15:02:22 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,962661 s
19/08/28 15:02:22 INFO SparkSqlParser: Parsing command: iris
19/08/28 15:02:22 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 15:02:22 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 15:02:22 INFO CodeGenerator: Code generated in 16.795951 ms
19/08/28 15:02:22 INFO CodeGenerator: Code generated in 10.590603 ms
19/08/28 15:02:22 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:02:22 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 15:02:22 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:02:22 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 15:02:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 15:02:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 15:02:22 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:02:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 15:02:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:58097 (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:02:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 15:02:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:02:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 15:02:22 INFO CodeGenerator: Code generated in 12.563892 ms
19/08/28 15:02:22 INFO CodeGenerator: Code generated in 63.538296 ms
19/08/28 15:02:23 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 15:02:23 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:58097 (size: 5.6 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO CodeGenerator: Code generated in 5.436332 ms
19/08/28 15:02:23 INFO CodeGenerator: Code generated in 24.483071 ms
19/08/28 15:02:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2285 bytes result sent to driver
19/08/28 15:02:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 281 ms on localhost (executor driver) (1/1)
19/08/28 15:02:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 15:02:23 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,283 s
19/08/28 15:02:23 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:23 INFO DAGScheduler: running: Set()
19/08/28 15:02:23 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 15:02:23 INFO DAGScheduler: failed: Set()
19/08/28 15:02:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 15:02:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 15:02:23 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 15:02:23 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 15:02:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 15:02:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:58097 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:58097 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
19/08/28 15:02:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/08/28 15:02:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 257 ms on localhost (executor driver) (1/1)
19/08/28 15:02:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 15:02:23 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,259 s
19/08/28 15:02:23 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,618439 s
19/08/28 15:02:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 15:02:23 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:23 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:23 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 15:02:23 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:23 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 15:02:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 15:02:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 15:02:23 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 15:02:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:58097 (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 15:02:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:02:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 15:02:23 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:02:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1604 bytes result sent to driver
19/08/28 15:02:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (executor driver) (1/1)
19/08/28 15:02:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 15:02:23 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,020 s
19/08/28 15:02:23 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:23 INFO DAGScheduler: running: Set()
19/08/28 15:02:23 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 15:02:23 INFO DAGScheduler: failed: Set()
19/08/28 15:02:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:02:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 15:02:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:02:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 15:02:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 15:02:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/08/28 15:02:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/08/28 15:02:23 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,010 s
19/08/28 15:02:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 15:02:23 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,058200 s
19/08/28 15:02:23 INFO CodeGenerator: Code generated in 8.90964 ms
19/08/28 15:02:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 15:02:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:02:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:02:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:02:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:02:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:24 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:24 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 15:02:24 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:24 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:24 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 15:02:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 15:02:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:58097 (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:02:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 15:02:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:02:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 15:02:24 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:02:24 INFO CodeGenerator: Code generated in 51.589465 ms
19/08/28 15:02:24 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 15:02:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1398 bytes result sent to driver
19/08/28 15:02:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 101 ms on localhost (executor driver) (1/1)
19/08/28 15:02:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 15:02:24 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,104 s
19/08/28 15:02:24 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,117215 s
19/08/28 15:02:24 INFO CodeGenerator: Code generated in 10.329829 ms
19/08/28 15:02:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:02:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:25 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:25 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:25 INFO CodeGenerator: Code generated in 8.691441 ms
19/08/28 15:02:25 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:25 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:02:25 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 15:02:25 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:25 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:25 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 15:02:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 15:02:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:58097 (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:02:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 15:02:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:25 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 15:02:25 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 891 bytes result sent to driver
19/08/28 15:02:25 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:02:25 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 15:02:25 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,006 s
19/08/28 15:02:25 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,019644 s
19/08/28 15:02:33 INFO SparkSqlParser: Parsing command: flights
19/08/28 15:02:33 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 15:02:33 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 15:02:33 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:02:33 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 15:02:33 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:02:33 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 15:02:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 15:02:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 15:02:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 15:02:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 15:02:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:58097 (size: 11.7 KB, free: 912.3 MB)
19/08/28 15:02:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 15:02:34 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:02:34 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 15:02:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:58097 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:02:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:58097 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:02:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:58097 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 15:02:34 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 15:02:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 15:02:34 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 15:02:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:02:34 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 15:02:34 INFO CodeGenerator: Code generated in 19.04826 ms
19/08/28 15:02:35 INFO CodeGenerator: Code generated in 96.739797 ms
19/08/28 15:02:38 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 15:02:38 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:58097 (size: 22.5 MB, free: 889.8 MB)
19/08/28 15:02:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 15:02:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4583 ms on localhost (executor driver) (1/1)
19/08/28 15:02:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 15:02:38 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 4,587 s
19/08/28 15:02:38 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:38 INFO DAGScheduler: running: Set()
19/08/28 15:02:38 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 15:02:38 INFO DAGScheduler: failed: Set()
19/08/28 15:02:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:02:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:02:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:02:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 15:02:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 15:02:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:38 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1495 bytes result sent to driver
19/08/28 15:02:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
19/08/28 15:02:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 15:02:38 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,016 s
19/08/28 15:02:38 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 4,629214 s
19/08/28 15:02:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 15:02:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:38 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 15:02:38 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:38 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 15:02:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 15:02:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 15:02:38 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 15:02:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 15:02:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:58097 (size: 11.8 KB, free: 889.8 MB)
19/08/28 15:02:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 15:02:38 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:02:38 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 15:02:38 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:02:38 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 15:02:39 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:02:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1733 bytes result sent to driver
19/08/28 15:02:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 622 ms on localhost (executor driver) (1/1)
19/08/28 15:02:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 15:02:39 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,623 s
19/08/28 15:02:39 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:39 INFO DAGScheduler: running: Set()
19/08/28 15:02:39 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 15:02:39 INFO DAGScheduler: failed: Set()
19/08/28 15:02:39 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:02:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:02:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:02:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 15:02:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 15:02:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:39 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1538 bytes result sent to driver
19/08/28 15:02:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
19/08/28 15:02:39 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 15:02:39 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,026 s
19/08/28 15:02:39 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,672524 s
19/08/28 15:02:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 15:02:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:39 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:39 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:39 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:39 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:39 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:39 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:39 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 15:02:39 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 15:02:39 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:39 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 15:02:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 15:02:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:58097 (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:02:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 15:02:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 15:02:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:39 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 15:02:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 894 bytes result sent to driver
19/08/28 15:02:39 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 15:02:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 6 ms on localhost (executor driver) (1/2)
19/08/28 15:02:39 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 934 bytes result sent to driver
19/08/28 15:02:39 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 10 ms on localhost (executor driver) (2/2)
19/08/28 15:02:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 15:02:39 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,011 s
19/08/28 15:02:39 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,021088 s
19/08/28 15:02:41 INFO SparkSqlParser: Parsing command: batting
19/08/28 15:02:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 15:02:41 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 15:02:41 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:02:41 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 15:02:41 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:02:41 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 15:02:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 15:02:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 15:02:41 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.7 MB)
19/08/28 15:02:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 15:02:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:58097 (size: 11.6 KB, free: 889.8 MB)
19/08/28 15:02:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 15:02:41 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:02:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 15:02:41 INFO CodeGenerator: Code generated in 25.548594 ms
19/08/28 15:02:41 INFO CodeGenerator: Code generated in 104.343667 ms
19/08/28 15:02:42 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 15:02:42 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 15:02:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:02:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:58097 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:02:43 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 15:02:43 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:58097 (size: 3.4 MB, free: 886.4 MB)
19/08/28 15:02:43 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 15:02:43 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 1704 ms on localhost (executor driver) (1/1)
19/08/28 15:02:43 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 15:02:43 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 1,705 s
19/08/28 15:02:43 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:43 INFO DAGScheduler: running: Set()
19/08/28 15:02:43 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 15:02:43 INFO DAGScheduler: failed: Set()
19/08/28 15:02:43 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 15:02:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:02:43 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:43 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 15:02:43 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:43 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 15:02:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:02:43 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1452 bytes result sent to driver
19/08/28 15:02:43 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 22 ms on localhost (executor driver) (1/1)
19/08/28 15:02:43 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 15:02:43 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,079 s
19/08/28 15:02:43 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 1,834090 s
19/08/28 15:02:43 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 15:02:43 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:43 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 15:02:43 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:43 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 15:02:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 15:02:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 15:02:43 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.2 MB)
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.2 MB)
19/08/28 15:02:43 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:58097 (size: 11.6 KB, free: 886.4 MB)
19/08/28 15:02:43 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:43 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 15:02:43 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:43 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:02:43 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 15:02:43 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 15:02:43 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1647 bytes result sent to driver
19/08/28 15:02:43 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 112 ms on localhost (executor driver) (1/1)
19/08/28 15:02:43 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 15:02:43 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,117 s
19/08/28 15:02:43 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:43 INFO DAGScheduler: running: Set()
19/08/28 15:02:43 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 15:02:43 INFO DAGScheduler: failed: Set()
19/08/28 15:02:43 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.2 MB)
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.2 MB)
19/08/28 15:02:43 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:43 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:43 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 15:02:43 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:43 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 15:02:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:02:43 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1495 bytes result sent to driver
19/08/28 15:02:43 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 4 ms on localhost (executor driver) (1/1)
19/08/28 15:02:43 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 15:02:43 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,011 s
19/08/28 15:02:43 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,152757 s
19/08/28 15:02:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 15:02:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:02:43 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:02:43 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:02:43 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 15:02:43 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:43 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:43 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.1 MB)
19/08/28 15:02:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.1 MB)
19/08/28 15:02:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:58097 (size: 34.7 KB, free: 886.3 MB)
19/08/28 15:02:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:43 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 15:02:43 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:02:43 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 15:02:43 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:02:44 INFO FileOutputCommitter: Saved output of task 'attempt_20190828150243_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/RtmpEjJ90M/file6b035871204.csv/_temporary/0/task_20190828150243_0016_m_000000
19/08/28 15:02:44 INFO SparkHadoopMapRedUtil: attempt_20190828150243_0016_m_000000_0: Committed
19/08/28 15:02:44 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 15:02:44 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 245 ms on localhost (executor driver) (1/1)
19/08/28 15:02:44 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 15:02:44 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,245 s
19/08/28 15:02:44 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,292365 s
19/08/28 15:02:44 INFO FileFormatWriter: Job null committed.
19/08/28 15:02:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:44 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:44 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:44 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:44 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:44 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:44 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:44 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 15:02:44 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 15:02:44 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:44 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:44 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:44 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.1 MB)
19/08/28 15:02:44 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.1 MB)
19/08/28 15:02:44 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:58097 (size: 3.5 KB, free: 886.3 MB)
19/08/28 15:02:44 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:44 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 15:02:44 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 15:02:44 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:44 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:44 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:44 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 15:02:44 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 15:02:44 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 15:02:44 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 894 bytes result sent to driver
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 382
19/08/28 15:02:44 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 977 bytes result sent to driver
19/08/28 15:02:44 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 937 bytes result sent to driver
19/08/28 15:02:44 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 210 ms on localhost (executor driver) (1/3)
19/08/28 15:02:44 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 211 ms on localhost (executor driver) (2/3)
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:58097 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:02:44 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 218 ms on localhost (executor driver) (3/3)
19/08/28 15:02:44 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 15:02:44 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,218 s
19/08/28 15:02:44 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,225545 s
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:58097 in memory (size: 34.7 KB, free: 886.4 MB)
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 383
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 380
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 237
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 227
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 376
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:58097 in memory (size: 11.8 KB, free: 886.4 MB)
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 228
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 377
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 384
19/08/28 15:02:44 INFO ContextCleaner: Cleaned shuffle 2
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 378
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 229
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:58097 in memory (size: 11.6 KB, free: 886.4 MB)
19/08/28 15:02:44 INFO ContextCleaner: Cleaned shuffle 4
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 234
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 233
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 385
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 230
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 235
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 375
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 386
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 379
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 226
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 236
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 231
19/08/28 15:02:44 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:58097 in memory (size: 11.7 KB, free: 886.4 MB)
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 232
19/08/28 15:02:44 INFO ContextCleaner: Cleaned accumulator 381
19/08/28 15:02:45 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:02:45 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 15:02:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:02:45 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:02:45 INFO CodeGenerator: Code generated in 10.72289 ms
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 886.1 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.0 KB, free 886.1 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:58097 (size: 24.0 KB, free: 886.4 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 15:02:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:02:45 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:02:45 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:02:45 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 15:02:45 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:45 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:45 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 886.1 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 886.1 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:58097 (size: 4.3 KB, free: 886.4 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5367 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 15:02:45 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpEjJ90M/file6b035871204.csv/part-00000-c3e89140-ee44-4495-b7c0-b8e8e2aee586-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:02:45 INFO CodeGenerator: Code generated in 4.92923 ms
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1308 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 37 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,037 s
19/08/28 15:02:45 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,050391 s
19/08/28 15:02:45 INFO CodeGenerator: Code generated in 4.773754 ms
19/08/28 15:02:45 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:02:45 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:02:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:02:45 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:02:45 INFO CodeGenerator: Code generated in 3.574043 ms
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.8 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.8 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:58097 (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 15:02:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:02:45 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:02:45 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:02:45 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 15:02:45 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:45 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:45 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.8 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.8 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:58097 (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5367 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 15:02:45 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpEjJ90M/file6b035871204.csv/part-00000-c3e89140-ee44-4495-b7c0-b8e8e2aee586-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1538 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 27 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,028 s
19/08/28 15:02:45 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,036509 s
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:45 INFO CodeGenerator: Code generated in 7.922805 ms
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 15:02:45 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:02:45 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:02:45 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 15:02:45 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.5 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.5 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:58097 (size: 24.1 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 15:02:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:02:45 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:02:45 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 15:02:45 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:02:45 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 15:02:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 15:02:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 15:02:45 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.4 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.4 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:58097 (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5356 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 15:02:45 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpEjJ90M/file6b035871204.csv/part-00000-c3e89140-ee44-4495-b7c0-b8e8e2aee586-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:02:45 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 885.4 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:58097 (size: 5.6 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2461 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 51 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,052 s
19/08/28 15:02:45 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:45 INFO DAGScheduler: running: Set()
19/08/28 15:02:45 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 15:02:45 INFO DAGScheduler: failed: Set()
19/08/28 15:02:45 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 885.4 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.4 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 15:02:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1581 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 10 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,010 s
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,076832 s
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:45 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 15:02:45 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:45 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 15:02:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 15:02:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 15:02:45 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 885.4 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.4 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:58097 (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5356 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 15:02:45 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1694 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 13 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,016 s
19/08/28 15:02:45 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:45 INFO DAGScheduler: running: Set()
19/08/28 15:02:45 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 15:02:45 INFO DAGScheduler: failed: Set()
19/08/28 15:02:45 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.4 MB)
19/08/28 15:02:45 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.4 MB)
19/08/28 15:02:45 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:45 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:45 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 15:02:45 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:45 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 15:02:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:45 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1495 bytes result sent to driver
19/08/28 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 15:02:45 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,009 s
19/08/28 15:02:45 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,039751 s
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 15:02:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:46 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:46 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:02:46 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 15:02:46 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:46 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:46 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:46 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.4 MB)
19/08/28 15:02:46 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.4 MB)
19/08/28 15:02:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:58097 (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:02:46 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:02:46 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 15:02:46 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:46 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:46 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:46 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:46 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 15:02:46 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 15:02:46 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 15:02:46 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 15:02:46 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 891 bytes result sent to driver
19/08/28 15:02:46 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 11 ms on localhost (executor driver) (1/4)
19/08/28 15:02:46 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 15:02:46 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 15:02:46 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 11 ms on localhost (executor driver) (2/4)
19/08/28 15:02:46 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 12 ms on localhost (executor driver) (3/4)
19/08/28 15:02:46 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 852 bytes result sent to driver
19/08/28 15:02:46 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 14 ms on localhost (executor driver) (4/4)
19/08/28 15:02:46 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 15:02:46 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,015 s
19/08/28 15:02:46 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,021909 s
19/08/28 15:02:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:02:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:02:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:02:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:02:46 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1479 - dep_delay.nullCount#1478) > 0)
19/08/28 15:02:46 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1477 <= 2.0) && (2.0 <= dep_delay.upperBound#1476))
19/08/28 15:02:46 INFO CodeGenerator: Code generated in 11.169931 ms
19/08/28 15:02:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:46 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:46 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/08/28 15:02:46 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:46 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:46 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:46 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.7 KB, free 885.3 MB)
19/08/28 15:02:46 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 885.3 MB)
19/08/28 15:02:46 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:58097 (size: 12.5 KB, free: 886.3 MB)
19/08/28 15:02:46 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:46 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 15:02:46 WARN TaskSetManager: Stage 25 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:46 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 15:02:46 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
19/08/28 15:02:47 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:02:47 INFO CodeGenerator: Code generated in 11.69756 ms
19/08/28 15:02:47 INFO CodeGenerator: Code generated in 17.167344 ms
19/08/28 15:02:47 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_33_0]
19/08/28 15:02:47 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2230 bytes result sent to driver
19/08/28 15:02:47 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 530 ms on localhost (executor driver) (1/1)
19/08/28 15:02:47 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 15:02:47 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0,532 s
19/08/28 15:02:47 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0,550296 s
19/08/28 15:02:47 INFO CodeGenerator: Code generated in 18.867315 ms
19/08/28 15:02:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:02:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `qysthqvrwa`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `kwgsemydks`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ytvukospzn`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ulkosutlha`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:48 INFO CodeGenerator: Code generated in 39.46235 ms
19/08/28 15:02:48 INFO CodeGenerator: Code generated in 67.553677 ms
19/08/28 15:02:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:48 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:204)
19/08/28 15:02:48 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:48 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/08/28 15:02:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/08/28 15:02:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/08/28 15:02:48 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:48 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 50.3 KB, free 885.3 MB)
19/08/28 15:02:48 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KB, free 885.3 MB)
19/08/28 15:02:48 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:58097 (size: 19.8 KB, free: 886.2 MB)
19/08/28 15:02:48 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:48 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 758
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:58097 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:58097 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 733
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 785
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 760
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:58097 in memory (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 15:02:48 INFO ContextCleaner: Cleaned shuffle 6
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:58097 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:58097 in memory (size: 4.3 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:58097 in memory (size: 12.5 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 759
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:58097 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:58097 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:02:48 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 15:02:48 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:58097 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:02:48 WARN TaskSetManager: Stage 26 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:48 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:02:48 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
19/08/28 15:02:48 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:02:48 INFO CodeGenerator: Code generated in 7.920524 ms
19/08/28 15:02:49 INFO CodeGenerator: Code generated in 6.165814 ms
19/08/28 15:02:49 INFO CodeGenerator: Code generated in 14.001187 ms
19/08/28 15:02:49 INFO CodeGenerator: Code generated in 7.025683 ms
19/08/28 15:02:49 INFO CodeGenerator: Code generated in 12.78323 ms
19/08/28 15:02:49 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1921 bytes result sent to driver
19/08/28 15:02:49 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 831 ms on localhost (executor driver) (1/1)
19/08/28 15:02:49 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 15:02:49 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0,833 s
19/08/28 15:02:49 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:49 INFO DAGScheduler: running: Set()
19/08/28 15:02:49 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/08/28 15:02:49 INFO DAGScheduler: failed: Set()
19/08/28 15:02:49 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:49 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 27.0 KB, free 886.0 MB)
19/08/28 15:02:49 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.0 MB)
19/08/28 15:02:49 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:58097 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:02:49 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:49 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 15:02:49 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:49 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
19/08/28 15:02:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:49 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 33
19/08/28 15:02:49 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 2648 bytes result sent to driver
19/08/28 15:02:49 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 18 ms on localhost (executor driver) (1/1)
19/08/28 15:02:49 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 15:02:49 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0,019 s
19/08/28 15:02:49 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0,876356 s
19/08/28 15:02:49 INFO CodeGenerator: Code generated in 5.185442 ms
19/08/28 15:02:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `zprbntnyam`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `hxwpfbmsmp`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `djbrqeckfz`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:49 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/08/28 15:02:49 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 4 output partitions
19/08/28 15:02:49 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/08/28 15:02:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/08/28 15:02:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/08/28 15:02:49 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:49 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 15:02:49 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.0 KB, free 885.9 MB)
19/08/28 15:02:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:58097 (size: 20.0 KB, free: 886.3 MB)
19/08/28 15:02:49 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:49 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 15:02:50 WARN TaskSetManager: Stage 28 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:02:50 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:02:50 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
19/08/28 15:02:50 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:58097 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:02:50 INFO ContextCleaner: Cleaned accumulator 847
19/08/28 15:02:50 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:58097 in memory (size: 19.8 KB, free: 886.3 MB)
19/08/28 15:02:50 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:02:50 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 1964 bytes result sent to driver
19/08/28 15:02:50 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 777 ms on localhost (executor driver) (1/1)
19/08/28 15:02:50 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 15:02:50 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0,777 s
19/08/28 15:02:50 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:50 INFO DAGScheduler: running: Set()
19/08/28 15:02:50 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/08/28 15:02:50 INFO DAGScheduler: failed: Set()
19/08/28 15:02:50 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:50 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 27.2 KB, free 886.0 MB)
19/08/28 15:02:50 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.0 MB)
19/08/28 15:02:50 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:58097 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:02:50 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:02:50 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
19/08/28 15:02:50 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:50 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 36, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 15:02:50 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 37, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 15:02:50 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 38, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 15:02:50 INFO Executor: Running task 1.0 in stage 29.0 (TID 36)
19/08/28 15:02:50 INFO Executor: Running task 2.0 in stage 29.0 (TID 37)
19/08/28 15:02:50 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
19/08/28 15:02:50 INFO Executor: Running task 3.0 in stage 29.0 (TID 38)
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:02:50 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 21599 bytes result sent to driver
19/08/28 15:02:50 INFO Executor: Finished task 3.0 in stage 29.0 (TID 38). 20799 bytes result sent to driver
19/08/28 15:02:50 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 28 ms on localhost (executor driver) (1/4)
19/08/28 15:02:50 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 38) in 28 ms on localhost (executor driver) (2/4)
19/08/28 15:02:50 INFO Executor: Finished task 2.0 in stage 29.0 (TID 37). 22702 bytes result sent to driver
19/08/28 15:02:50 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 37) in 30 ms on localhost (executor driver) (3/4)
19/08/28 15:02:50 INFO Executor: Finished task 1.0 in stage 29.0 (TID 36). 21732 bytes result sent to driver
19/08/28 15:02:50 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 36) in 41 ms on localhost (executor driver) (4/4)
19/08/28 15:02:50 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 15:02:50 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0,042 s
19/08/28 15:02:50 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0,835734 s
19/08/28 15:02:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:02:52 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:52 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:02:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:02:53 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:02:53 INFO DAGScheduler: Got job 20 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:02:53 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
19/08/28 15:02:53 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:53 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:53 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41), which has no missing parents
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.5 KB, free 886.0 MB)
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KB, free 886.0 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:58097 (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:02:53 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/08/28 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:53 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:53 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:53 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:02:53 INFO Executor: Running task 3.0 in stage 30.0 (TID 42)
19/08/28 15:02:53 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
19/08/28 15:02:53 INFO Executor: Running task 1.0 in stage 30.0 (TID 40)
19/08/28 15:02:53 INFO Executor: Running task 2.0 in stage 30.0 (TID 41)
19/08/28 15:02:53 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 894 bytes result sent to driver
19/08/28 15:02:53 INFO Executor: Finished task 3.0 in stage 30.0 (TID 42). 895 bytes result sent to driver
19/08/28 15:02:53 INFO Executor: Finished task 1.0 in stage 30.0 (TID 40). 894 bytes result sent to driver
19/08/28 15:02:53 INFO Executor: Finished task 2.0 in stage 30.0 (TID 41). 891 bytes result sent to driver
19/08/28 15:02:53 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 42) in 20 ms on localhost (executor driver) (1/4)
19/08/28 15:02:53 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 40) in 21 ms on localhost (executor driver) (2/4)
19/08/28 15:02:53 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 41) in 31 ms on localhost (executor driver) (3/4)
19/08/28 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 31 ms on localhost (executor driver) (4/4)
19/08/28 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 15:02:53 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0,045 s
19/08/28 15:02:53 INFO DAGScheduler: Job 20 finished: collect at utils.scala:44, took 0,051589 s
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 15:02:53 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:02:53 INFO DAGScheduler: Registering RDD 131 (sql at <unknown>:0)
19/08/28 15:02:53 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:02:53 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
19/08/28 15:02:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 15:02:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 15:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 22.4 KB, free 885.9 MB)
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.9 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:58097 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:53 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:02:53 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
19/08/28 15:02:53 INFO CodeGenerator: Code generated in 5.497534 ms
19/08/28 15:02:53 INFO CodeGenerator: Code generated in 29.001373 ms
19/08/28 15:02:53 INFO MemoryStore: Block rdd_128_0 stored as values in memory (estimated size 4.2 KB, free 885.9 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added rdd_128_0 in memory on 127.0.0.1:58097 (size: 4.2 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2242 bytes result sent to driver
19/08/28 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 63 ms on localhost (executor driver) (1/1)
19/08/28 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 15:02:53 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0,063 s
19/08/28 15:02:53 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:53 INFO DAGScheduler: running: Set()
19/08/28 15:02:53 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 15:02:53 INFO DAGScheduler: failed: Set()
19/08/28 15:02:53 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:53 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:53 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
19/08/28 15:02:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:53 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 1495 bytes result sent to driver
19/08/28 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:02:53 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0,005 s
19/08/28 15:02:53 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0,100108 s
19/08/28 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 15:02:53 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:02:53 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:02:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:02:53 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:204)
19/08/28 15:02:53 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:02:53 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/08/28 15:02:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 15:02:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 15:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 22.4 KB, free 885.9 MB)
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.9 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:58097 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:53 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:02:53 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
19/08/28 15:02:53 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:53 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 1647 bytes result sent to driver
19/08/28 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 7 ms on localhost (executor driver) (1/1)
19/08/28 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 15:02:53 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0,009 s
19/08/28 15:02:53 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:53 INFO DAGScheduler: running: Set()
19/08/28 15:02:53 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 15:02:53 INFO DAGScheduler: failed: Set()
19/08/28 15:02:53 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 15:02:53 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 15:02:53 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:02:53 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:53 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 15:02:53 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:53 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
19/08/28 15:02:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:53 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 1495 bytes result sent to driver
19/08/28 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 8 ms on localhost (executor driver) (1/1)
19/08/28 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 15:02:53 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0,008 s
19/08/28 15:02:53 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0,030023 s
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b0493460ab
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b0493460ab` AS `zzz6`
WHERE (0 = 1)
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b05e69517c
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b05e69517c` AS `zzz7`
WHERE (0 = 1)
19/08/28 15:02:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b0493460ab`
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2292 - hp.nullCount#2291) > 0)
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2289)
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 51.430187 ms
19/08/28 15:02:54 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 15:02:54 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 15:02:54 INFO DAGScheduler: Final stage: ResultStage 35 (first at LinearRegression.scala:198)
19/08/28 15:02:54 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:54 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:54 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 15:02:54 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 41.3 KB, free 885.8 MB)
19/08/28 15:02:54 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.4 KB, free 885.8 MB)
19/08/28 15:02:54 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:58097 (size: 16.4 KB, free: 886.3 MB)
19/08/28 15:02:54 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:54 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 15:02:54 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:02:54 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
19/08/28 15:02:54 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 11.164989 ms
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 14.56531 ms
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 28.7406 ms
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 16.303674 ms
19/08/28 15:02:54 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 1743 bytes result sent to driver
19/08/28 15:02:54 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 295 ms on localhost (executor driver) (1/1)
19/08/28 15:02:54 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 15:02:54 INFO DAGScheduler: ResultStage 35 (first at LinearRegression.scala:198) finished in 0,295 s
19/08/28 15:02:54 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0,304858 s
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 6.206869 ms
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2353 - hp.nullCount#2352) > 0)
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2350)
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 25.574443 ms
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2409 - hp.nullCount#2408) > 0)
19/08/28 15:02:54 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2406)
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 27.900499 ms
19/08/28 15:02:54 INFO Instrumentation: LinearRegression-linear_regression_6b03b46681c-2077764724-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 15:02:54 INFO Instrumentation: LinearRegression-linear_regression_6b03b46681c-2077764724-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 15:02:54 INFO Instrumentation: LinearRegression-linear_regression_6b03b46681c-2077764724-1: {"numFeatures":2}
19/08/28 15:02:54 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 15:02:54 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 15:02:54 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 15:02:54 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 15:02:54 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:54 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:54 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 15:02:54 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 885.8 MB)
19/08/28 15:02:54 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.6 KB, free 885.8 MB)
19/08/28 15:02:54 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:58097 (size: 17.6 KB, free: 886.3 MB)
19/08/28 15:02:54 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:54 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/08/28 15:02:54 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:02:54 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
19/08/28 15:02:54 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:54 INFO CodeGenerator: Code generated in 4.934932 ms
19/08/28 15:02:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 15:02:54 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 15:02:54 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 2184 bytes result sent to driver
19/08/28 15:02:54 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 35 ms on localhost (executor driver) (1/1)
19/08/28 15:02:54 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/08/28 15:02:54 INFO DAGScheduler: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,036 s
19/08/28 15:02:54 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,042810 s
19/08/28 15:02:54 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 15:02:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 15:02:54 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 15:02:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2486 - hp.nullCount#2485) > 0)
19/08/28 15:02:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2483)
19/08/28 15:02:55 INFO CodeGenerator: Code generated in 21.30513 ms
19/08/28 15:02:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 15:02:55 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 15:02:55 INFO DAGScheduler: Final stage: ResultStage 37 (aggregate at RegressionMetrics.scala:57)
19/08/28 15:02:55 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:55 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:55 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.2 KB, free 885.7 MB)
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.7 MB)
19/08/28 15:02:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:58097 (size: 17.8 KB, free: 886.3 MB)
19/08/28 15:02:55 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:55 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/08/28 15:02:55 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:02:55 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
19/08/28 15:02:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:55 INFO CodeGenerator: Code generated in 5.775794 ms
19/08/28 15:02:55 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2180 bytes result sent to driver
19/08/28 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 32 ms on localhost (executor driver) (1/1)
19/08/28 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/08/28 15:02:55 INFO DAGScheduler: ResultStage 37 (aggregate at RegressionMetrics.scala:57) finished in 0,033 s
19/08/28 15:02:55 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0,042813 s
19/08/28 15:02:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 15:02:55 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 15:02:55 INFO DAGScheduler: Final stage: ResultStage 38 (sum at RegressionMetrics.scala:71)
19/08/28 15:02:55 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:55 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:55 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 43.8 KB, free 885.7 MB)
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.6 MB)
19/08/28 15:02:55 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:58097 (size: 17.8 KB, free: 886.2 MB)
19/08/28 15:02:55 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:55 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/08/28 15:02:55 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:02:55 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
19/08/28 15:02:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:55 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 1697 bytes result sent to driver
19/08/28 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 12 ms on localhost (executor driver) (1/1)
19/08/28 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/08/28 15:02:55 INFO DAGScheduler: ResultStage 38 (sum at RegressionMetrics.scala:71) finished in 0,014 s
19/08/28 15:02:55 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0,023557 s
19/08/28 15:02:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2561 - hp.nullCount#2560) > 0)
19/08/28 15:02:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2558)
19/08/28 15:02:55 INFO CodeGenerator: Code generated in 20.182207 ms
19/08/28 15:02:55 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 15:02:55 INFO DAGScheduler: Registering RDD 163 (count at LinearRegression.scala:696)
19/08/28 15:02:55 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 15:02:55 INFO DAGScheduler: Final stage: ResultStage 40 (count at LinearRegression.scala:696)
19/08/28 15:02:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/08/28 15:02:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/08/28 15:02:55 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 36.6 KB, free 885.6 MB)
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.6 MB)
19/08/28 15:02:55 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:58097 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:02:55 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:55 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/08/28 15:02:55 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:02:55 INFO Executor: Running task 0.0 in stage 39.0 (TID 51)
19/08/28 15:02:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:55 INFO Executor: Finished task 0.0 in stage 39.0 (TID 51). 2275 bytes result sent to driver
19/08/28 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 51) in 17 ms on localhost (executor driver) (1/1)
19/08/28 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/08/28 15:02:55 INFO DAGScheduler: ShuffleMapStage 39 (count at LinearRegression.scala:696) finished in 0,018 s
19/08/28 15:02:55 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:55 INFO DAGScheduler: running: Set()
19/08/28 15:02:55 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/08/28 15:02:55 INFO DAGScheduler: failed: Set()
19/08/28 15:02:55 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 885.6 MB)
19/08/28 15:02:55 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.6 MB)
19/08/28 15:02:55 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:02:55 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:55 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/08/28 15:02:55 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 52, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:55 INFO Executor: Running task 0.0 in stage 40.0 (TID 52)
19/08/28 15:02:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:55 INFO Executor: Finished task 0.0 in stage 40.0 (TID 52). 1495 bytes result sent to driver
19/08/28 15:02:55 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 52) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:02:55 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/08/28 15:02:55 INFO DAGScheduler: ResultStage 40 (count at LinearRegression.scala:696) finished in 0,006 s
19/08/28 15:02:55 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:696, took 0,036360 s
19/08/28 15:02:55 INFO Instrumentation: LinearRegression-linear_regression_6b03b46681c-2077764724-1: training finished
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b031c93808
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b031c93808` AS `zzz8`
WHERE (0 = 1)
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b0493460ab`
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b04800697a
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b04800697a` AS `zzz9`
WHERE (0 = 1)
19/08/28 15:02:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b04800697a`
19/08/28 15:02:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b07d9c7e52
19/08/28 15:02:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b07d9c7e52` AS `zzz10`
WHERE (0 = 1)
19/08/28 15:02:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_6b06dbf1097
19/08/28 15:02:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b06dbf1097` AS `zzz11`
WHERE (0 = 1)
19/08/28 15:02:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_6b06dbf1097`
19/08/28 15:02:56 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2783 - hp.nullCount#2782) > 0)
19/08/28 15:02:56 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2780)
19/08/28 15:02:56 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 15:02:56 INFO DAGScheduler: Registering RDD 169 (count at <unknown>:0)
19/08/28 15:02:56 INFO DAGScheduler: Got job 28 (count at <unknown>:0) with 1 output partitions
19/08/28 15:02:56 INFO DAGScheduler: Final stage: ResultStage 42 (count at <unknown>:0)
19/08/28 15:02:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/08/28 15:02:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/08/28 15:02:56 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 36.6 KB, free 885.5 MB)
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.5 MB)
19/08/28 15:02:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:58097 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:02:56 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:56 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/08/28 15:02:56 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:02:56 INFO Executor: Running task 0.0 in stage 41.0 (TID 53)
19/08/28 15:02:56 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:56 INFO Executor: Finished task 0.0 in stage 41.0 (TID 53). 2275 bytes result sent to driver
19/08/28 15:02:56 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 53) in 45 ms on localhost (executor driver) (1/1)
19/08/28 15:02:56 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/08/28 15:02:56 INFO DAGScheduler: ShuffleMapStage 41 (count at <unknown>:0) finished in 0,045 s
19/08/28 15:02:56 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:02:56 INFO DAGScheduler: running: Set()
19/08/28 15:02:56 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/08/28 15:02:56 INFO DAGScheduler: failed: Set()
19/08/28 15:02:56 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0), which has no missing parents
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 885.5 MB)
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.5 MB)
19/08/28 15:02:56 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:58097 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:02:56 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:56 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/08/28 15:02:56 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:02:56 INFO Executor: Running task 0.0 in stage 42.0 (TID 54)
19/08/28 15:02:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:02:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:02:56 INFO Executor: Finished task 0.0 in stage 42.0 (TID 54). 1452 bytes result sent to driver
19/08/28 15:02:56 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 54) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:02:56 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/08/28 15:02:56 INFO DAGScheduler: ResultStage 42 (count at <unknown>:0) finished in 0,006 s
19/08/28 15:02:56 INFO DAGScheduler: Job 28 finished: count at <unknown>:0, took 0,074779 s
19/08/28 15:02:56 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2843 - hp.nullCount#2842) > 0)
19/08/28 15:02:56 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2840)
19/08/28 15:02:56 INFO CodeGenerator: Code generated in 38.141756 ms
19/08/28 15:02:56 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 15:02:56 INFO DAGScheduler: Got job 29 (collect at utils.scala:37) with 1 output partitions
19/08/28 15:02:56 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:37)
19/08/28 15:02:56 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:02:56 INFO DAGScheduler: Missing parents: List()
19/08/28 15:02:56 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34), which has no missing parents
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 885.5 MB)
19/08/28 15:02:56 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.5 MB)
19/08/28 15:02:56 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:58097 (size: 19.3 KB, free: 886.2 MB)
19/08/28 15:02:56 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/08/28 15:02:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 15:02:56 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/08/28 15:02:56 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:02:56 INFO Executor: Running task 0.0 in stage 43.0 (TID 55)
19/08/28 15:02:56 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:02:56 INFO CodeGenerator: Code generated in 5.878051 ms
19/08/28 15:02:56 INFO Executor: Finished task 0.0 in stage 43.0 (TID 55). 1704 bytes result sent to driver
19/08/28 15:02:56 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 55) in 26 ms on localhost (executor driver) (1/1)
19/08/28 15:02:56 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/08/28 15:02:56 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:37) finished in 0,027 s
19/08/28 15:02:56 INFO DAGScheduler: Job 29 finished: collect at utils.scala:37, took 0,039741 s
19/08/28 15:02:58 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 15:02:58 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 15:02:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 15:02:59 INFO MemoryStore: MemoryStore cleared
19/08/28 15:02:59 INFO BlockManager: BlockManager stopped
19/08/28 15:02:59 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 15:02:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 15:02:59 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:02:59 INFO SparkContext: Successfully stopped SparkContext
19/08/28 15:02:59 INFO ShutdownHookManager: Shutdown hook called
19/08/28 15:02:59 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651
19/08/28 15:02:59 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:02:59 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f
19/08/28 15:02:59 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-433d21eb-a49a-4d41-adae-2e8038e25651\userFiles-5d3ec4e0-ed79-410f-85c9-7446afb2fb2f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:04:35 INFO SparkContext: Running Spark version 2.2.0
19/08/28 15:04:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 15:04:37 INFO SparkContext: Submitted application: sparklyr
19/08/28 15:04:37 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 15:04:37 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 15:04:37 INFO SecurityManager: Changing view acls groups to: 
19/08/28 15:04:37 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 15:04:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 15:04:37 INFO Utils: Successfully started service 'sparkDriver' on port 58167.
19/08/28 15:04:37 INFO SparkEnv: Registering MapOutputTracker
19/08/28 15:04:37 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 15:04:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 15:04:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 15:04:37 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-9d13c146-b813-4b02-bba5-ab4a74a0c11a
19/08/28 15:04:37 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 15:04:37 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 15:04:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 15:04:38 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 15:04:38 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 15:04:38 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:58167/jars/sparklyr-2.0-2.11.jar with timestamp 1566997478256
19/08/28 15:04:38 INFO Executor: Starting executor ID driver on host localhost
19/08/28 15:04:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58188.
19/08/28 15:04:38 INFO NettyBlockTransferService: Server created on 127.0.0.1:58188
19/08/28 15:04:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 15:04:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58188, None)
19/08/28 15:04:38 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58188 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 58188, None)
19/08/28 15:04:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58188, None)
19/08/28 15:04:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58188, None)
19/08/28 15:04:38 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 15:04:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 15:04:38 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 15:04:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 15:04:40 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 15:04:40 INFO ObjectStore: ObjectStore, initialize called
19/08/28 15:04:40 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 15:04:40 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 15:04:42 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 15:04:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:04:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:04:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:04:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:04:44 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 15:04:44 INFO ObjectStore: Initialized ObjectStore
19/08/28 15:04:44 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 15:04:44 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 15:04:45 INFO HiveMetaStore: Added admin role in metastore
19/08/28 15:04:45 INFO HiveMetaStore: Added public role in metastore
19/08/28 15:04:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 15:04:45 INFO HiveMetaStore: 0: get_all_databases
19/08/28 15:04:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 15:04:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 15:04:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 15:04:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:04:45 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/d4b04604-47f2-43bd-9800-bde71ac5c7a2_resources
19/08/28 15:04:45 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/d4b04604-47f2-43bd-9800-bde71ac5c7a2
19/08/28 15:04:45 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/d4b04604-47f2-43bd-9800-bde71ac5c7a2
19/08/28 15:04:45 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/d4b04604-47f2-43bd-9800-bde71ac5c7a2/_tmp_space.db
19/08/28 15:04:45 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:04:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:45 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 15:04:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 15:04:45 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 15:04:45 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/086d460c-4845-468f-9f38-6dfd12daf613_resources
19/08/28 15:04:46 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/086d460c-4845-468f-9f38-6dfd12daf613
19/08/28 15:04:46 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/086d460c-4845-468f-9f38-6dfd12daf613
19/08/28 15:04:46 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/086d460c-4845-468f-9f38-6dfd12daf613/_tmp_space.db
19/08/28 15:04:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:04:46 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 15:04:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:04:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:47 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:04:47 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:04:48 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:04:48 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:04:48 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 15:04:48 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:04:48 INFO DAGScheduler: Missing parents: List()
19/08/28 15:04:48 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 15:04:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 15:04:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 15:04:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:58188 (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:04:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 15:04:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 15:04:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 15:04:48 INFO Executor: Fetching spark://127.0.0.1:58167/jars/sparklyr-2.0-2.11.jar with timestamp 1566997478256
19/08/28 15:04:48 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:58167 after 20 ms (0 ms spent in bootstraps)
19/08/28 15:04:48 INFO Utils: Fetching spark://127.0.0.1:58167/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f\fetchFileTemp9102589305607675055.tmp
19/08/28 15:04:48 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-d5cf553f-cab8-40c0-8773-14c8df94a996/userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f/sparklyr-2.0-2.11.jar to class loader
19/08/28 15:04:49 INFO CodeGenerator: Code generated in 269.783254 ms
19/08/28 15:04:49 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/08/28 15:04:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 704 ms on localhost (executor driver) (1/1)
19/08/28 15:04:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 15:04:49 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,722 s
19/08/28 15:04:49 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,881754 s
19/08/28 15:04:49 INFO SparkSqlParser: Parsing command: iris
19/08/28 15:04:49 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 15:04:49 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 15:04:49 INFO CodeGenerator: Code generated in 16.62527 ms
19/08/28 15:04:49 INFO CodeGenerator: Code generated in 10.942229 ms
19/08/28 15:04:49 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:04:49 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 15:04:49 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:04:49 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 15:04:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 15:04:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 15:04:49 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 15:04:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:04:49 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 15:04:49 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:58188 (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:04:49 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 15:04:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:04:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 15:04:49 INFO CodeGenerator: Code generated in 13.1455 ms
19/08/28 15:04:49 INFO CodeGenerator: Code generated in 46.914926 ms
19/08/28 15:04:49 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 15:04:49 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:58188 (size: 5.6 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO CodeGenerator: Code generated in 5.137544 ms
19/08/28 15:04:50 INFO CodeGenerator: Code generated in 30.262667 ms
19/08/28 15:04:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/08/28 15:04:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 265 ms on localhost (executor driver) (1/1)
19/08/28 15:04:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 15:04:50 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,268 s
19/08/28 15:04:50 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:04:50 INFO DAGScheduler: running: Set()
19/08/28 15:04:50 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 15:04:50 INFO DAGScheduler: failed: Set()
19/08/28 15:04:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 15:04:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 15:04:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:04:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 15:04:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:04:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/08/28 15:04:50 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/08/28 15:04:50 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 283 ms on localhost (executor driver) (1/1)
19/08/28 15:04:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 15:04:50 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,284 s
19/08/28 15:04:50 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,603987 s
19/08/28 15:04:50 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:58188 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 15:04:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:58188 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 15:04:50 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 15:04:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:04:50 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 15:04:50 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:04:50 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 15:04:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 15:04:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 15:04:50 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 15:04:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:58188 (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 15:04:50 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:04:50 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 15:04:50 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:04:50 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1604 bytes result sent to driver
19/08/28 15:04:50 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 18 ms on localhost (executor driver) (1/1)
19/08/28 15:04:50 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,018 s
19/08/28 15:04:50 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:04:50 INFO DAGScheduler: running: Set()
19/08/28 15:04:50 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 15:04:50 INFO DAGScheduler: failed: Set()
19/08/28 15:04:50 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:04:50 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 15:04:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 15:04:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:04:50 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:50 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 15:04:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:04:50 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 15:04:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:04:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:04:50 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/08/28 15:04:50 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
19/08/28 15:04:50 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 15:04:50 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,009 s
19/08/28 15:04:50 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,056372 s
19/08/28 15:04:50 INFO CodeGenerator: Code generated in 8.531784 ms
19/08/28 15:04:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 15:04:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:04:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:04:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:04:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:04:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:04:51 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:04:51 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 15:04:51 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:04:51 INFO DAGScheduler: Missing parents: List()
19/08/28 15:04:51 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 15:04:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 15:04:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 15:04:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:58188 (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:04:51 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:51 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 15:04:51 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:04:51 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 15:04:51 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:04:51 INFO CodeGenerator: Code generated in 37.303935 ms
19/08/28 15:04:51 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 15:04:51 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1398 bytes result sent to driver
19/08/28 15:04:51 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 87 ms on localhost (executor driver) (1/1)
19/08/28 15:04:51 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 15:04:51 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,088 s
19/08/28 15:04:51 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,101763 s
19/08/28 15:04:51 INFO CodeGenerator: Code generated in 11.363801 ms
19/08/28 15:04:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:04:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:04:52 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:52 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:04:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:04:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:04:52 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:04:52 INFO CodeGenerator: Code generated in 6.220553 ms
19/08/28 15:04:52 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:04:52 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:04:52 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 15:04:52 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:04:52 INFO DAGScheduler: Missing parents: List()
19/08/28 15:04:52 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 15:04:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 15:04:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 15:04:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:58188 (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:04:52 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 15:04:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:04:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 15:04:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:04:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 15:04:52 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 891 bytes result sent to driver
19/08/28 15:04:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 21 ms on localhost (executor driver) (1/1)
19/08/28 15:04:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 15:04:52 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,022 s
19/08/28 15:04:52 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,029490 s
19/08/28 15:05:00 INFO SparkSqlParser: Parsing command: flights
19/08/28 15:05:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 15:05:00 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 15:05:00 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:05:00 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 15:05:00 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:05:00 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 15:05:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 15:05:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 15:05:00 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 15:05:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 15:05:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:58188 (size: 11.7 KB, free: 912.3 MB)
19/08/28 15:05:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 15:05:00 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:05:00 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 15:05:01 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:58188 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:05:01 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:58188 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 15:05:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 15:05:01 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 15:05:01 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:58188 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 15:05:01 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 15:05:01 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 15:05:01 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 15:05:01 INFO CodeGenerator: Code generated in 20.669542 ms
19/08/28 15:05:01 INFO CodeGenerator: Code generated in 178.610175 ms
19/08/28 15:05:05 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 15:05:05 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:58188 (size: 22.5 MB, free: 889.8 MB)
19/08/28 15:05:05 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4591 ms on localhost (executor driver) (1/1)
19/08/28 15:05:05 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 15:05:05 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 4,591 s
19/08/28 15:05:05 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:05 INFO DAGScheduler: running: Set()
19/08/28 15:05:05 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 15:05:05 INFO DAGScheduler: failed: Set()
19/08/28 15:05:05 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:05:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:05:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 15:05:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:05 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 15:05:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:05:05 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1452 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:05:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 15:05:05 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,007 s
19/08/28 15:05:05 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 4,634663 s
19/08/28 15:05:05 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 15:05:05 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:05 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:05 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:05 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 15:05:05 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:05 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 15:05:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 15:05:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 15:05:05 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 15:05:05 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:58188 (size: 11.8 KB, free: 889.8 MB)
19/08/28 15:05:05 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:05 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 15:05:05 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:05:05 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 15:05:05 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:05:05 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 455 ms on localhost (executor driver) (1/1)
19/08/28 15:05:05 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 15:05:05 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,457 s
19/08/28 15:05:05 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:05 INFO DAGScheduler: running: Set()
19/08/28 15:05:05 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 15:05:05 INFO DAGScheduler: failed: Set()
19/08/28 15:05:05 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:05:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:05:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:05 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 15:05:05 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:05 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 15:05:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1495 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:05:05 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 15:05:05 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,007 s
19/08/28 15:05:05 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,490584 s
19/08/28 15:05:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 15:05:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:05:05 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:05 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:05 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:05 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:05:05 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:05:05 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:05:05 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 15:05:05 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 15:05:05 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:05 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:05 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 15:05:05 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 15:05:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:58188 (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:05:05 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 15:05:05 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 15:05:05 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:05 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:05 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 15:05:05 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 15:05:05 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 894 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 7 ms on localhost (executor driver) (1/2)
19/08/28 15:05:05 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 934 bytes result sent to driver
19/08/28 15:05:05 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 10 ms on localhost (executor driver) (2/2)
19/08/28 15:05:05 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 15:05:05 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,013 s
19/08/28 15:05:05 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,021313 s
19/08/28 15:05:07 INFO SparkSqlParser: Parsing command: batting
19/08/28 15:05:07 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 15:05:07 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 15:05:07 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:05:07 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 15:05:07 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:05:07 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 15:05:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 15:05:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 15:05:07 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:07 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.6 MB)
19/08/28 15:05:07 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 15:05:07 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:58188 (size: 11.6 KB, free: 889.7 MB)
19/08/28 15:05:07 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 15:05:07 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:05:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 15:05:07 INFO CodeGenerator: Code generated in 31.278011 ms
19/08/28 15:05:08 INFO CodeGenerator: Code generated in 63.566045 ms
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 290
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 294
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 15:05:08 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:05:08 INFO ContextCleaner: Cleaned shuffle 3
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 291
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 298
19/08/28 15:05:08 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:58188 in memory (size: 11.8 KB, free: 889.8 MB)
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 292
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 297
19/08/28 15:05:08 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 296
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 295
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 287
19/08/28 15:05:08 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:58188 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 293
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 289
19/08/28 15:05:08 INFO ContextCleaner: Cleaned accumulator 288
19/08/28 15:05:09 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 15:05:09 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:58188 (size: 3.4 MB, free: 886.4 MB)
19/08/28 15:05:09 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 15:05:09 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 1649 ms on localhost (executor driver) (1/1)
19/08/28 15:05:09 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 1,650 s
19/08/28 15:05:09 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:09 INFO DAGScheduler: running: Set()
19/08/28 15:05:09 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 15:05:09 INFO DAGScheduler: failed: Set()
19/08/28 15:05:09 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 15:05:09 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 15:05:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:05:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:09 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 15:05:09 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:09 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 15:05:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:05:09 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1495 bytes result sent to driver
19/08/28 15:05:09 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 13 ms on localhost (executor driver) (1/1)
19/08/28 15:05:09 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,014 s
19/08/28 15:05:09 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 15:05:09 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 1,732182 s
19/08/28 15:05:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 15:05:09 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:09 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:09 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 15:05:09 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:09 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 15:05:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 15:05:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 15:05:09 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.3 MB)
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.3 MB)
19/08/28 15:05:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:58188 (size: 11.6 KB, free: 886.4 MB)
19/08/28 15:05:09 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:09 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 15:05:09 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:09 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:05:09 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 15:05:09 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 15:05:09 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:05:09 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 15:05:09 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1690 bytes result sent to driver
19/08/28 15:05:09 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 139 ms on localhost (executor driver) (1/1)
19/08/28 15:05:09 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,140 s
19/08/28 15:05:09 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:09 INFO DAGScheduler: running: Set()
19/08/28 15:05:09 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 15:05:09 INFO DAGScheduler: failed: Set()
19/08/28 15:05:09 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 15:05:09 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 15:05:09 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 15:05:09 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:05:09 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:09 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 15:05:09 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:09 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 15:05:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:09 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1452 bytes result sent to driver
19/08/28 15:05:09 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 11 ms on localhost (executor driver) (1/1)
19/08/28 15:05:09 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 15:05:09 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,012 s
19/08/28 15:05:09 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,208519 s
19/08/28 15:05:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 15:05:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:05:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:05:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:05:10 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:05:10 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:05:10 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 15:05:10 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:10 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:10 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 15:05:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.2 MB)
19/08/28 15:05:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.1 MB)
19/08/28 15:05:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:58188 (size: 34.7 KB, free: 886.3 MB)
19/08/28 15:05:10 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:10 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 15:05:10 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:05:10 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 15:05:10 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:05:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:05:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:05:10 INFO FileOutputCommitter: Saved output of task 'attempt_20190828150510_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/RtmpUJRM0O/file38246ce628bd.csv/_temporary/0/task_20190828150510_0016_m_000000
19/08/28 15:05:10 INFO SparkHadoopMapRedUtil: attempt_20190828150510_0016_m_000000_0: Committed
19/08/28 15:05:10 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 15:05:10 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 198 ms on localhost (executor driver) (1/1)
19/08/28 15:05:10 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 15:05:10 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,199 s
19/08/28 15:05:10 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,222482 s
19/08/28 15:05:10 INFO FileFormatWriter: Job null committed.
19/08/28 15:05:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:05:10 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:10 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:05:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:05:10 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:05:10 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 15:05:10 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 15:05:10 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:10 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:10 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 15:05:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.1 MB)
19/08/28 15:05:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.1 MB)
19/08/28 15:05:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:58188 (size: 3.5 KB, free: 886.3 MB)
19/08/28 15:05:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:10 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 15:05:10 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 15:05:10 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:10 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:10 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:10 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 15:05:10 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 15:05:10 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 937 bytes result sent to driver
19/08/28 15:05:10 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 894 bytes result sent to driver
19/08/28 15:05:10 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 15:05:10 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 8 ms on localhost (executor driver) (1/3)
19/08/28 15:05:10 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 9 ms on localhost (executor driver) (2/3)
19/08/28 15:05:10 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 891 bytes result sent to driver
19/08/28 15:05:10 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 11 ms on localhost (executor driver) (3/3)
19/08/28 15:05:10 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 15:05:10 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,012 s
19/08/28 15:05:10 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,017473 s
19/08/28 15:05:11 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:05:11 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 15:05:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:05:11 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:05:11 INFO CodeGenerator: Code generated in 8.279373 ms
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 885.9 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.9 KB, free 885.8 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:58188 (size: 23.9 KB, free: 886.3 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 15:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:05:11 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:05:11 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:05:11 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 15:05:11 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:11 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:11 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 885.8 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 885.8 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:58188 (size: 4.3 KB, free: 886.3 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 15:05:11 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpUJRM0O/file38246ce628bd.csv/part-00000-9dad1cde-7a1e-4a64-96d0-700fd22bd4b8-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:05:11 INFO CodeGenerator: Code generated in 6.438752 ms
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1308 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 40 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,041 s
19/08/28 15:05:11 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,050657 s
19/08/28 15:05:11 INFO CodeGenerator: Code generated in 4.396659 ms
19/08/28 15:05:11 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:05:11 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:05:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:05:11 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:05:11 INFO CodeGenerator: Code generated in 4.215333 ms
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.5 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.9 KB, free 885.5 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:58188 (size: 23.9 KB, free: 886.3 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 15:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:05:11 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:05:11 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:05:11 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 15:05:11 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:11 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:11 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.5 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.5 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:58188 (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 15:05:11 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpUJRM0O/file38246ce628bd.csv/part-00000-9dad1cde-7a1e-4a64-96d0-700fd22bd4b8-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1495 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 28 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,029 s
19/08/28 15:05:11 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,041041 s
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:05:11 INFO CodeGenerator: Code generated in 7.29824 ms
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 15:05:11 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:05:11 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:05:11 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 15:05:11 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.2 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.2 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:58188 (size: 24.1 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 15:05:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:05:11 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:05:11 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 15:05:11 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:05:11 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 15:05:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 15:05:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 15:05:11 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.2 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.2 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:58188 (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 15:05:11 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpUJRM0O/file38246ce628bd.csv/part-00000-9dad1cde-7a1e-4a64-96d0-700fd22bd4b8-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:05:11 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 885.2 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:58188 (size: 5.6 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2418 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 41 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,041 s
19/08/28 15:05:11 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:11 INFO DAGScheduler: running: Set()
19/08/28 15:05:11 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 15:05:11 INFO DAGScheduler: failed: Set()
19/08/28 15:05:11 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 885.2 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.2 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 15:05:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1495 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 4 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,005 s
19/08/28 15:05:11 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,063221 s
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:11 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:11 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 15:05:11 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:11 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 15:05:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 15:05:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 15:05:11 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 885.1 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.1 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:58188 (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 15:05:11 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1737 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 14 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,015 s
19/08/28 15:05:11 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:11 INFO DAGScheduler: running: Set()
19/08/28 15:05:11 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 15:05:11 INFO DAGScheduler: failed: Set()
19/08/28 15:05:11 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.1 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.1 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 15:05:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1495 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,006 s
19/08/28 15:05:11 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,054829 s
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 15:05:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:05:11 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:05:11 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:05:11 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:05:11 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 15:05:11 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:11 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:11 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.1 MB)
19/08/28 15:05:11 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.1 MB)
19/08/28 15:05:11 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:58188 (size: 3.6 KB, free: 886.2 MB)
19/08/28 15:05:11 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:05:11 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:11 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:11 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:11 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:11 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 15:05:11 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 15:05:11 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 15:05:11 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 15:05:11 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 895 bytes result sent to driver
19/08/28 15:05:11 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 15:05:11 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 10 ms on localhost (executor driver) (1/4)
19/08/28 15:05:11 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 11 ms on localhost (executor driver) (2/4)
19/08/28 15:05:11 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 13 ms on localhost (executor driver) (3/4)
19/08/28 15:05:11 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 891 bytes result sent to driver
19/08/28 15:05:11 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 15 ms on localhost (executor driver) (4/4)
19/08/28 15:05:11 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 15:05:11 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,016 s
19/08/28 15:05:11 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,025088 s
19/08/28 15:05:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:05:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:05:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:05:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:05:12 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1479 - dep_delay.nullCount#1478) > 0)
19/08/28 15:05:12 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1477 <= 2.0) && (2.0 <= dep_delay.upperBound#1476))
19/08/28 15:05:12 INFO CodeGenerator: Code generated in 26.300124 ms
19/08/28 15:05:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:12 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:12 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/08/28 15:05:12 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:12 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:12 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:12 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.7 KB, free 885.1 MB)
19/08/28 15:05:12 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 885.1 MB)
19/08/28 15:05:12 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:58188 (size: 12.5 KB, free: 886.2 MB)
19/08/28 15:05:12 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:12 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 15:05:12 WARN TaskSetManager: Stage 25 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:12 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 15:05:12 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
19/08/28 15:05:13 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 673
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:58188 in memory (size: 4.3 KB, free: 886.2 MB)
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:58188 in memory (size: 3.5 KB, free: 886.2 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 679
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 521
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:58188 in memory (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 677
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 15:05:13 INFO ContextCleaner: Cleaned shuffle 6
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:58188 in memory (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 15:05:13 INFO CodeGenerator: Code generated in 96.631079 ms
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:58188 in memory (size: 23.9 KB, free: 886.2 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 681
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 733
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:58188 in memory (size: 23.9 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 682
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:58188 in memory (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 680
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 676
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 678
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 684
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 674
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:58188 in memory (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 675
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:58188 in memory (size: 34.7 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO CodeGenerator: Code generated in 33.098105 ms
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 15:05:13 INFO ContextCleaner: Cleaned accumulator 683
19/08/28 15:05:13 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:05:13 INFO ContextCleaner: Cleaned shuffle 7
19/08/28 15:05:13 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_33_0]
19/08/28 15:05:13 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2273 bytes result sent to driver
19/08/28 15:05:13 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 734 ms on localhost (executor driver) (1/1)
19/08/28 15:05:13 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 15:05:13 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0,736 s
19/08/28 15:05:13 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0,761196 s
19/08/28 15:05:13 INFO CodeGenerator: Code generated in 19.751132 ms
19/08/28 15:05:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:05:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `izxmnazzhw`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `dyyluramol`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `sodbcskbdb`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ejwmamieyl`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:14 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:14 INFO CodeGenerator: Code generated in 46.372471 ms
19/08/28 15:05:14 INFO CodeGenerator: Code generated in 52.269149 ms
19/08/28 15:05:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:14 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:204)
19/08/28 15:05:14 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:14 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/08/28 15:05:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/08/28 15:05:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/08/28 15:05:14 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:14 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 15:05:14 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KB, free 885.9 MB)
19/08/28 15:05:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:58188 (size: 19.8 KB, free: 886.3 MB)
19/08/28 15:05:14 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:14 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 15:05:15 WARN TaskSetManager: Stage 26 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:05:15 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
19/08/28 15:05:15 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 14.748536 ms
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 5.12424 ms
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 6.247924 ms
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 7.951696 ms
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 11.187037 ms
19/08/28 15:05:15 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1921 bytes result sent to driver
19/08/28 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 859 ms on localhost (executor driver) (1/1)
19/08/28 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 15:05:15 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0,859 s
19/08/28 15:05:15 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:15 INFO DAGScheduler: running: Set()
19/08/28 15:05:15 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/08/28 15:05:15 INFO DAGScheduler: failed: Set()
19/08/28 15:05:15 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 27.0 KB, free 885.8 MB)
19/08/28 15:05:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.8 MB)
19/08/28 15:05:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:58188 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:05:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:15 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:15 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
19/08/28 15:05:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:15 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 33
19/08/28 15:05:15 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 2605 bytes result sent to driver
19/08/28 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 20 ms on localhost (executor driver) (1/1)
19/08/28 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 15:05:15 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0,020 s
19/08/28 15:05:15 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0,898378 s
19/08/28 15:05:15 INFO CodeGenerator: Code generated in 7.356782 ms
19/08/28 15:05:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `wummyisvzn`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `pdvjjrzndp`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `apidkvvzfx`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:16 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:16 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/08/28 15:05:16 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 4 output partitions
19/08/28 15:05:16 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/08/28 15:05:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/08/28 15:05:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/08/28 15:05:16 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:16 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 50.3 KB, free 885.8 MB)
19/08/28 15:05:16 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.0 KB, free 885.7 MB)
19/08/28 15:05:16 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:58188 (size: 20.0 KB, free: 886.3 MB)
19/08/28 15:05:16 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:16 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 15:05:16 WARN TaskSetManager: Stage 28 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:05:16 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:05:16 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 786
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 791
19/08/28 15:05:16 INFO ContextCleaner: Cleaned shuffle 8
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 794
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 798
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 793
19/08/28 15:05:16 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:58188 in memory (size: 19.8 KB, free: 886.3 MB)
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 788
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 787
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 785
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 789
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 797
19/08/28 15:05:16 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:58188 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 790
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 792
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 796
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 847
19/08/28 15:05:16 INFO ContextCleaner: Cleaned accumulator 795
19/08/28 15:05:16 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:05:16 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 1964 bytes result sent to driver
19/08/28 15:05:16 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 625 ms on localhost (executor driver) (1/1)
19/08/28 15:05:16 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0,626 s
19/08/28 15:05:16 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:16 INFO DAGScheduler: running: Set()
19/08/28 15:05:16 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/08/28 15:05:16 INFO DAGScheduler: failed: Set()
19/08/28 15:05:16 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:16 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 27.2 KB, free 885.8 MB)
19/08/28 15:05:16 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.8 MB)
19/08/28 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 15:05:17 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:58188 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:05:17 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:05:17 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
19/08/28 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:17 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 36, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 15:05:17 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 37, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 15:05:17 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 38, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 15:05:17 INFO Executor: Running task 2.0 in stage 29.0 (TID 37)
19/08/28 15:05:17 INFO Executor: Running task 1.0 in stage 29.0 (TID 36)
19/08/28 15:05:17 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:17 INFO Executor: Running task 3.0 in stage 29.0 (TID 38)
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:17 INFO Executor: Finished task 3.0 in stage 29.0 (TID 38). 20842 bytes result sent to driver
19/08/28 15:05:17 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 21599 bytes result sent to driver
19/08/28 15:05:17 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 38) in 33 ms on localhost (executor driver) (1/4)
19/08/28 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 35 ms on localhost (executor driver) (2/4)
19/08/28 15:05:17 INFO Executor: Finished task 2.0 in stage 29.0 (TID 37). 22702 bytes result sent to driver
19/08/28 15:05:17 INFO Executor: Finished task 1.0 in stage 29.0 (TID 36). 21775 bytes result sent to driver
19/08/28 15:05:17 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 36) in 51 ms on localhost (executor driver) (3/4)
19/08/28 15:05:17 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 37) in 51 ms on localhost (executor driver) (4/4)
19/08/28 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 15:05:17 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0,052 s
19/08/28 15:05:17 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0,699991 s
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:05:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:05:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:05:19 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:05:19 INFO DAGScheduler: Got job 20 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:05:19 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
19/08/28 15:05:19 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:19 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:19 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41), which has no missing parents
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.5 KB, free 885.8 MB)
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.8 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:58188 (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:05:19 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/08/28 15:05:19 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:19 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:19 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:19 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:05:19 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
19/08/28 15:05:19 INFO Executor: Running task 1.0 in stage 30.0 (TID 40)
19/08/28 15:05:19 INFO Executor: Running task 3.0 in stage 30.0 (TID 42)
19/08/28 15:05:19 INFO Executor: Running task 2.0 in stage 30.0 (TID 41)
19/08/28 15:05:19 INFO Executor: Finished task 3.0 in stage 30.0 (TID 42). 938 bytes result sent to driver
19/08/28 15:05:19 INFO Executor: Finished task 1.0 in stage 30.0 (TID 40). 894 bytes result sent to driver
19/08/28 15:05:19 INFO Executor: Finished task 2.0 in stage 30.0 (TID 41). 934 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 42) in 9 ms on localhost (executor driver) (1/4)
19/08/28 15:05:19 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 40) in 9 ms on localhost (executor driver) (2/4)
19/08/28 15:05:19 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 894 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 41) in 10 ms on localhost (executor driver) (3/4)
19/08/28 15:05:19 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 10 ms on localhost (executor driver) (4/4)
19/08/28 15:05:19 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 15:05:19 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0,010 s
19/08/28 15:05:19 INFO DAGScheduler: Job 20 finished: collect at utils.scala:44, took 0,020564 s
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 15:05:19 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:05:19 INFO DAGScheduler: Registering RDD 131 (sql at <unknown>:0)
19/08/28 15:05:19 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:05:19 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
19/08/28 15:05:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 15:05:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 15:05:19 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 22.4 KB, free 885.8 MB)
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.8 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:58188 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:19 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 15:05:19 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:05:19 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
19/08/28 15:05:19 INFO CodeGenerator: Code generated in 8.560674 ms
19/08/28 15:05:19 INFO CodeGenerator: Code generated in 30.888752 ms
19/08/28 15:05:19 INFO MemoryStore: Block rdd_128_0 stored as values in memory (estimated size 4.2 KB, free 885.8 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added rdd_128_0 in memory on 127.0.0.1:58188 (size: 4.2 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2242 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 61 ms on localhost (executor driver) (1/1)
19/08/28 15:05:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 15:05:19 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0,062 s
19/08/28 15:05:19 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:19 INFO DAGScheduler: running: Set()
19/08/28 15:05:19 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 15:05:19 INFO DAGScheduler: failed: Set()
19/08/28 15:05:19 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 885.8 MB)
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.8 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:19 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 15:05:19 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:19 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
19/08/28 15:05:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:19 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 1538 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 5 ms on localhost (executor driver) (1/1)
19/08/28 15:05:19 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0,006 s
19/08/28 15:05:19 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 15:05:19 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0,080333 s
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 15:05:19 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:05:19 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:05:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:05:19 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:204)
19/08/28 15:05:19 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:05:19 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/08/28 15:05:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 15:05:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 15:05:19 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 22.4 KB, free 885.7 MB)
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.7 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:58188 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:19 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 15:05:19 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:05:19 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
19/08/28 15:05:19 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:19 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 1604 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 15 ms on localhost (executor driver) (1/1)
19/08/28 15:05:19 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 15:05:19 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0,016 s
19/08/28 15:05:19 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:19 INFO DAGScheduler: running: Set()
19/08/28 15:05:19 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 15:05:19 INFO DAGScheduler: failed: Set()
19/08/28 15:05:19 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 885.7 MB)
19/08/28 15:05:19 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.7 MB)
19/08/28 15:05:19 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:05:19 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:19 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 15:05:19 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:19 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
19/08/28 15:05:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:19 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 1495 bytes result sent to driver
19/08/28 15:05:19 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 10 ms on localhost (executor driver) (1/1)
19/08/28 15:05:19 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 15:05:19 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0,010 s
19/08/28 15:05:19 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0,042274 s
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_38242c001314
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38242c001314` AS `zzz6`
WHERE (0 = 1)
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: sparklyr_tmp_38247a7f2414
19/08/28 15:05:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38247a7f2414` AS `zzz7`
WHERE (0 = 1)
19/08/28 15:05:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38242c001314`
19/08/28 15:05:21 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2292 - hp.nullCount#2291) > 0)
19/08/28 15:05:21 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2289)
19/08/28 15:05:21 INFO CodeGenerator: Code generated in 155.331377 ms
19/08/28 15:05:21 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 15:05:21 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 15:05:21 INFO DAGScheduler: Final stage: ResultStage 35 (first at LinearRegression.scala:198)
19/08/28 15:05:21 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:21 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:21 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 15:05:21 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 41.3 KB, free 885.7 MB)
19/08/28 15:05:21 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.4 KB, free 885.7 MB)
19/08/28 15:05:21 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:58188 (size: 16.4 KB, free: 886.2 MB)
19/08/28 15:05:21 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:21 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 15:05:21 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:05:21 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
19/08/28 15:05:21 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:21 INFO CodeGenerator: Code generated in 20.676005 ms
19/08/28 15:05:21 INFO CodeGenerator: Code generated in 48.662794 ms
19/08/28 15:05:21 INFO CodeGenerator: Code generated in 62.330601 ms
19/08/28 15:05:21 INFO CodeGenerator: Code generated in 33.985343 ms
19/08/28 15:05:22 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 1786 bytes result sent to driver
19/08/28 15:05:22 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 515 ms on localhost (executor driver) (1/1)
19/08/28 15:05:22 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 15:05:22 INFO DAGScheduler: ResultStage 35 (first at LinearRegression.scala:198) finished in 0,517 s
19/08/28 15:05:22 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0,573214 s
19/08/28 15:05:22 INFO CodeGenerator: Code generated in 15.429741 ms
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2353 - hp.nullCount#2352) > 0)
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2350)
19/08/28 15:05:22 INFO CodeGenerator: Code generated in 84.922114 ms
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2409 - hp.nullCount#2408) > 0)
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2406)
19/08/28 15:05:22 INFO CodeGenerator: Code generated in 44.799847 ms
19/08/28 15:05:22 INFO Instrumentation: LinearRegression-linear_regression_38247ea31c9b-648206052-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 15:05:22 INFO Instrumentation: LinearRegression-linear_regression_38247ea31c9b-648206052-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 15:05:22 INFO Instrumentation: LinearRegression-linear_regression_38247ea31c9b-648206052-1: {"numFeatures":2}
19/08/28 15:05:22 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 15:05:22 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 15:05:22 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 15:05:22 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 15:05:22 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:22 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:22 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 15:05:22 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 885.6 MB)
19/08/28 15:05:22 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.6 KB, free 885.6 MB)
19/08/28 15:05:22 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:58188 (size: 17.6 KB, free: 886.2 MB)
19/08/28 15:05:22 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:22 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/08/28 15:05:22 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:05:22 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
19/08/28 15:05:22 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:22 INFO CodeGenerator: Code generated in 10.699322 ms
19/08/28 15:05:22 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 15:05:22 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 15:05:22 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 2227 bytes result sent to driver
19/08/28 15:05:22 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 69 ms on localhost (executor driver) (1/1)
19/08/28 15:05:22 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/08/28 15:05:22 INFO DAGScheduler: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,070 s
19/08/28 15:05:22 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,082081 s
19/08/28 15:05:22 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 15:05:22 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 15:05:22 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2486 - hp.nullCount#2485) > 0)
19/08/28 15:05:22 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2483)
19/08/28 15:05:23 INFO CodeGenerator: Code generated in 30.460338 ms
19/08/28 15:05:23 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 15:05:23 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 15:05:23 INFO DAGScheduler: Final stage: ResultStage 37 (aggregate at RegressionMetrics.scala:57)
19/08/28 15:05:23 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:23 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:23 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.2 KB, free 885.6 MB)
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.9 KB, free 885.5 MB)
19/08/28 15:05:23 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:58188 (size: 17.9 KB, free: 886.2 MB)
19/08/28 15:05:23 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:23 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/08/28 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:05:23 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
19/08/28 15:05:23 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:23 INFO CodeGenerator: Code generated in 11.629516 ms
19/08/28 15:05:23 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2223 bytes result sent to driver
19/08/28 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 65 ms on localhost (executor driver) (1/1)
19/08/28 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/08/28 15:05:23 INFO DAGScheduler: ResultStage 37 (aggregate at RegressionMetrics.scala:57) finished in 0,065 s
19/08/28 15:05:23 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0,077237 s
19/08/28 15:05:23 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 15:05:23 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 15:05:23 INFO DAGScheduler: Final stage: ResultStage 38 (sum at RegressionMetrics.scala:71)
19/08/28 15:05:23 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:23 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:23 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 43.8 KB, free 885.5 MB)
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.5 MB)
19/08/28 15:05:23 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:58188 (size: 17.8 KB, free: 886.2 MB)
19/08/28 15:05:23 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:23 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/08/28 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:05:23 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
19/08/28 15:05:23 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:23 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 1654 bytes result sent to driver
19/08/28 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 14 ms on localhost (executor driver) (1/1)
19/08/28 15:05:23 INFO DAGScheduler: ResultStage 38 (sum at RegressionMetrics.scala:71) finished in 0,015 s
19/08/28 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/08/28 15:05:23 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0,023892 s
19/08/28 15:05:23 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2561 - hp.nullCount#2560) > 0)
19/08/28 15:05:23 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2558)
19/08/28 15:05:23 INFO CodeGenerator: Code generated in 21.841123 ms
19/08/28 15:05:23 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 15:05:23 INFO DAGScheduler: Registering RDD 163 (count at LinearRegression.scala:696)
19/08/28 15:05:23 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 15:05:23 INFO DAGScheduler: Final stage: ResultStage 40 (count at LinearRegression.scala:696)
19/08/28 15:05:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/08/28 15:05:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/08/28 15:05:23 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 36.6 KB, free 885.4 MB)
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.4 MB)
19/08/28 15:05:23 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:58188 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:05:23 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:23 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/08/28 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:05:23 INFO Executor: Running task 0.0 in stage 39.0 (TID 51)
19/08/28 15:05:23 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:23 INFO Executor: Finished task 0.0 in stage 39.0 (TID 51). 2318 bytes result sent to driver
19/08/28 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 51) in 37 ms on localhost (executor driver) (1/1)
19/08/28 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/08/28 15:05:23 INFO DAGScheduler: ShuffleMapStage 39 (count at LinearRegression.scala:696) finished in 0,038 s
19/08/28 15:05:23 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:23 INFO DAGScheduler: running: Set()
19/08/28 15:05:23 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/08/28 15:05:23 INFO DAGScheduler: failed: Set()
19/08/28 15:05:23 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 885.4 MB)
19/08/28 15:05:23 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.4 MB)
19/08/28 15:05:23 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:23 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:23 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/08/28 15:05:23 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 52, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:23 INFO Executor: Running task 0.0 in stage 40.0 (TID 52)
19/08/28 15:05:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:23 INFO Executor: Finished task 0.0 in stage 40.0 (TID 52). 1538 bytes result sent to driver
19/08/28 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 52) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/08/28 15:05:23 INFO DAGScheduler: ResultStage 40 (count at LinearRegression.scala:696) finished in 0,007 s
19/08/28 15:05:23 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:696, took 0,074396 s
19/08/28 15:05:23 INFO Instrumentation: LinearRegression-linear_regression_38247ea31c9b-648206052-1: training finished
19/08/28 15:05:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_382471531772
19/08/28 15:05:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_382471531772` AS `zzz8`
WHERE (0 = 1)
19/08/28 15:05:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38242c001314`
19/08/28 15:05:23 INFO SparkSqlParser: Parsing command: sparklyr_tmp_38243432997
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38243432997` AS `zzz9`
WHERE (0 = 1)
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38243432997`
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: sparklyr_tmp_382466f23241
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_382466f23241` AS `zzz10`
WHERE (0 = 1)
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: sparklyr_tmp_38241caf757e
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38241caf757e` AS `zzz11`
WHERE (0 = 1)
19/08/28 15:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_38241caf757e`
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1063
19/08/28 15:05:24 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2783 - hp.nullCount#2782) > 0)
19/08/28 15:05:24 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2780)
19/08/28 15:05:24 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:58188 in memory (size: 16.4 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1199
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1098
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 939
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1185
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1062
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1195
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 947
19/08/28 15:05:24 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 15:05:24 INFO DAGScheduler: Registering RDD 169 (count at <unknown>:0)
19/08/28 15:05:24 INFO DAGScheduler: Got job 28 (count at <unknown>:0) with 1 output partitions
19/08/28 15:05:24 INFO DAGScheduler: Final stage: ResultStage 42 (count at <unknown>:0)
19/08/28 15:05:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/08/28 15:05:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/08/28 15:05:24 INFO ContextCleaner: Cleaned shuffle 12
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1093
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1101
19/08/28 15:05:24 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents
19/08/28 15:05:24 INFO ContextCleaner: Cleaned shuffle 11
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1194
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1190
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 943
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1189
19/08/28 15:05:24 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 36.6 KB, free 885.4 MB)
19/08/28 15:05:24 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.4 MB)
19/08/28 15:05:24 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:58188 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:58188 in memory (size: 17.6 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1188
19/08/28 15:05:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:24 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/08/28 15:05:24 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:05:24 INFO Executor: Running task 0.0 in stage 41.0 (TID 53)
19/08/28 15:05:24 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:58188 in memory (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:24 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1096
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1089
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1186
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 938
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 999
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 941
19/08/28 15:05:24 INFO Executor: Finished task 0.0 in stage 41.0 (TID 53). 2232 bytes result sent to driver
19/08/28 15:05:24 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 53) in 23 ms on localhost (executor driver) (1/1)
19/08/28 15:05:24 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/08/28 15:05:24 INFO DAGScheduler: ShuffleMapStage 41 (count at <unknown>:0) finished in 0,023 s
19/08/28 15:05:24 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:05:24 INFO DAGScheduler: running: Set()
19/08/28 15:05:24 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/08/28 15:05:24 INFO DAGScheduler: failed: Set()
19/08/28 15:05:24 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0), which has no missing parents
19/08/28 15:05:24 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 885.6 MB)
19/08/28 15:05:24 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.5 MB)
19/08/28 15:05:24 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:58188 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:24 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:24 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/08/28 15:05:24 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:05:24 INFO Executor: Running task 0.0 in stage 42.0 (TID 54)
19/08/28 15:05:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:05:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:05:24 INFO Executor: Finished task 0.0 in stage 42.0 (TID 54). 1495 bytes result sent to driver
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1187
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1003
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1094
19/08/28 15:05:24 INFO ContextCleaner: Cleaned accumulator 1009
19/08/28 15:05:24 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 54) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:05:24 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/08/28 15:05:24 INFO DAGScheduler: ResultStage 42 (count at <unknown>:0) finished in 0,008 s
19/08/28 15:05:24 INFO DAGScheduler: Job 28 finished: count at <unknown>:0, took 0,060786 s
19/08/28 15:05:24 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2843 - hp.nullCount#2842) > 0)
19/08/28 15:05:24 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2840)
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:58188 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO CodeGenerator: Code generated in 41.937039 ms
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 937
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1001
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 946
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1007
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1006
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1002
19/08/28 15:05:25 INFO ContextCleaner: Cleaned shuffle 10
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1193
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1191
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1183
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1000
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1060
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1197
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1091
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1184
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1192
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:58188 in memory (size: 11.6 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1102
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 942
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1090
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 936
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1100
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1064
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:58188 in memory (size: 17.8 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 15:05:25 INFO DAGScheduler: Got job 29 (collect at utils.scala:37) with 1 output partitions
19/08/28 15:05:25 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:37)
19/08/28 15:05:25 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:05:25 INFO DAGScheduler: Missing parents: List()
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1061
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1198
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1005
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 944
19/08/28 15:05:25 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34), which has no missing parents
19/08/28 15:05:25 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 885.6 MB)
19/08/28 15:05:25 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.6 MB)
19/08/28 15:05:25 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:58188 (size: 19.3 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/08/28 15:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 15:05:25 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/08/28 15:05:25 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:05:25 INFO Executor: Running task 0.0 in stage 43.0 (TID 55)
19/08/28 15:05:25 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:58188 in memory (size: 17.9 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1059
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1182
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1092
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 945
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 998
19/08/28 15:05:25 INFO CodeGenerator: Code generated in 5.177459 ms
19/08/28 15:05:25 INFO Executor: Finished task 0.0 in stage 43.0 (TID 55). 1747 bytes result sent to driver
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:58188 in memory (size: 3.6 KB, free: 886.2 MB)
19/08/28 15:05:25 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 55) in 23 ms on localhost (executor driver) (1/1)
19/08/28 15:05:25 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/08/28 15:05:25 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:37) finished in 0,026 s
19/08/28 15:05:25 INFO DAGScheduler: Job 29 finished: collect at utils.scala:37, took 0,039708 s
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1008
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1099
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 909
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1058
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1097
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1196
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1095
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 940
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:58188 in memory (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 948
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 997
19/08/28 15:05:25 INFO ContextCleaner: Cleaned accumulator 1004
19/08/28 15:05:25 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:58188 in memory (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:05:26 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 15:05:26 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 15:05:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 15:05:27 INFO MemoryStore: MemoryStore cleared
19/08/28 15:05:27 INFO BlockManager: BlockManager stopped
19/08/28 15:05:27 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 15:05:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 15:05:27 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:05:27 INFO SparkContext: Successfully stopped SparkContext
19/08/28 15:05:27 INFO ShutdownHookManager: Shutdown hook called
19/08/28 15:05:27 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f
19/08/28 15:05:27 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996\userFiles-6e1b376e-868e-4cef-9430-3c99bc2af65f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:05:27 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996
19/08/28 15:05:27 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-d5cf553f-cab8-40c0-8773-14c8df94a996
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:06:01 INFO SparkContext: Running Spark version 2.2.0
19/08/28 15:06:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/08/28 15:06:02 INFO SparkContext: Submitted application: sparklyr
19/08/28 15:06:02 INFO SecurityManager: Changing view acls to: Donnet
19/08/28 15:06:02 INFO SecurityManager: Changing modify acls to: Donnet
19/08/28 15:06:02 INFO SecurityManager: Changing view acls groups to: 
19/08/28 15:06:02 INFO SecurityManager: Changing modify acls groups to: 
19/08/28 15:06:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Donnet); groups with view permissions: Set(); users  with modify permissions: Set(Donnet); groups with modify permissions: Set()
19/08/28 15:06:02 INFO Utils: Successfully started service 'sparkDriver' on port 58248.
19/08/28 15:06:02 INFO SparkEnv: Registering MapOutputTracker
19/08/28 15:06:02 INFO SparkEnv: Registering BlockManagerMaster
19/08/28 15:06:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/08/28 15:06:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/08/28 15:06:02 INFO DiskBlockManager: Created local directory at C:\Users\Donnet\AppData\Local\Temp\blockmgr-11d45536-8086-489d-a123-41ffae2dbf27
19/08/28 15:06:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/08/28 15:06:02 INFO SparkEnv: Registering OutputCommitCoordinator
19/08/28 15:06:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/08/28 15:06:02 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/08/28 15:06:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/08/28 15:06:02 INFO SparkContext: Added JAR file:/C:/Program%20Files/R/R-3.5.2/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:58248/jars/sparklyr-2.0-2.11.jar with timestamp 1566997562734
19/08/28 15:06:02 INFO Executor: Starting executor ID driver on host localhost
19/08/28 15:06:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58269.
19/08/28 15:06:02 INFO NettyBlockTransferService: Server created on 127.0.0.1:58269
19/08/28 15:06:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/08/28 15:06:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58269, None)
19/08/28 15:06:02 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58269 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 58269, None)
19/08/28 15:06:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58269, None)
19/08/28 15:06:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58269, None)
19/08/28 15:06:03 INFO SharedState: loading hive config file: file:/C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/08/28 15:06:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive').
19/08/28 15:06:03 INFO SharedState: Warehouse path is 'C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive'.
19/08/28 15:06:04 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/08/28 15:06:04 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/08/28 15:06:05 INFO ObjectStore: ObjectStore, initialize called
19/08/28 15:06:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/08/28 15:06:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/08/28 15:06:07 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/08/28 15:06:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:06:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:06:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:06:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:06:09 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/08/28 15:06:09 INFO ObjectStore: Initialized ObjectStore
19/08/28 15:06:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/08/28 15:06:09 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/08/28 15:06:09 INFO HiveMetaStore: Added admin role in metastore
19/08/28 15:06:09 INFO HiveMetaStore: Added public role in metastore
19/08/28 15:06:09 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/08/28 15:06:09 INFO HiveMetaStore: 0: get_all_databases
19/08/28 15:06:09 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_all_databases	
19/08/28 15:06:10 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/08/28 15:06:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/08/28 15:06:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/08/28 15:06:10 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/3fd20433-ecf4-4bd5-b2d9-38eb5f14f799_resources
19/08/28 15:06:10 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/3fd20433-ecf4-4bd5-b2d9-38eb5f14f799
19/08/28 15:06:10 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/3fd20433-ecf4-4bd5-b2d9-38eb5f14f799
19/08/28 15:06:10 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/3fd20433-ecf4-4bd5-b2d9-38eb5f14f799/_tmp_space.db
19/08/28 15:06:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:06:10 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:10 INFO HiveMetaStore: 0: get_database: global_temp
19/08/28 15:06:10 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/08/28 15:06:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/08/28 15:06:10 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/Temp/4732c5d9-609d-4022-99d0-2693ca6c654f_resources
19/08/28 15:06:10 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/4732c5d9-609d-4022-99d0-2693ca6c654f
19/08/28 15:06:10 INFO SessionState: Created local directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/4732c5d9-609d-4022-99d0-2693ca6c654f
19/08/28 15:06:10 INFO SessionState: Created HDFS directory: C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive/Donnet/4732c5d9-609d-4022-99d0-2693ca6c654f/_tmp_space.db
19/08/28 15:06:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:/Users/Donnet/AppData/Local/spark/spark-2.2.0-bin-hadoop2.7/tmp/hive
19/08/28 15:06:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/08/28 15:06:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:13 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:13 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:13 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:13 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:13 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:13 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:13 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:06:13 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/08/28 15:06:13 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:13 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/08/28 15:06:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/08/28 15:06:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:58269 (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:06:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/08/28 15:06:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/08/28 15:06:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/08/28 15:06:13 INFO Executor: Fetching spark://127.0.0.1:58248/jars/sparklyr-2.0-2.11.jar with timestamp 1566997562734
19/08/28 15:06:13 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:58248 after 18 ms (0 ms spent in bootstraps)
19/08/28 15:06:13 INFO Utils: Fetching spark://127.0.0.1:58248/jars/sparklyr-2.0-2.11.jar to C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9\fetchFileTemp4351026241535278867.tmp
19/08/28 15:06:14 INFO Executor: Adding file:/C:/Users/Donnet/AppData/Local/Temp/spark-edc9258f-864f-4ccd-be83-78153e43d356/userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9/sparklyr-2.0-2.11.jar to class loader
19/08/28 15:06:14 INFO CodeGenerator: Code generated in 279.803272 ms
19/08/28 15:06:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/08/28 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 733 ms on localhost (executor driver) (1/1)
19/08/28 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/08/28 15:06:14 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0,754 s
19/08/28 15:06:14 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0,934995 s
19/08/28 15:06:14 INFO SparkSqlParser: Parsing command: iris
19/08/28 15:06:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris`
19/08/28 15:06:14 INFO SparkSqlParser: Parsing command: `iris`
19/08/28 15:06:14 INFO ContextCleaner: Cleaned accumulator 0
19/08/28 15:06:14 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:58269 in memory (size: 3.4 KB, free: 912.3 MB)
19/08/28 15:06:14 INFO CodeGenerator: Code generated in 16.977656 ms
19/08/28 15:06:14 INFO CodeGenerator: Code generated in 12.046906 ms
19/08/28 15:06:15 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:06:15 INFO DAGScheduler: Registering RDD 12 (sql at <unknown>:0)
19/08/28 15:06:15 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:06:15 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
19/08/28 15:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/08/28 15:06:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/08/28 15:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.4 KB, free 912.3 MB)
19/08/28 15:06:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:58269 (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/08/28 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:06:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/08/28 15:06:15 INFO CodeGenerator: Code generated in 11.846954 ms
19/08/28 15:06:15 INFO CodeGenerator: Code generated in 53.059452 ms
19/08/28 15:06:15 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 5.6 KB, free 912.3 MB)
19/08/28 15:06:15 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:58269 (size: 5.6 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO CodeGenerator: Code generated in 5.073682 ms
19/08/28 15:06:15 INFO CodeGenerator: Code generated in 17.404549 ms
19/08/28 15:06:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2328 bytes result sent to driver
19/08/28 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 240 ms on localhost (executor driver) (1/1)
19/08/28 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/08/28 15:06:15 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0,243 s
19/08/28 15:06:15 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:15 INFO DAGScheduler: running: Set()
19/08/28 15:06:15 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/08/28 15:06:15 INFO DAGScheduler: failed: Set()
19/08/28 15:06:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.3 MB)
19/08/28 15:06:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/08/28 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/08/28 15:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/08/28 15:06:15 INFO ContextCleaner: Cleaned accumulator 51
19/08/28 15:06:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:58269 in memory (size: 8.4 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1581 bytes result sent to driver
19/08/28 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 165 ms on localhost (executor driver) (1/1)
19/08/28 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/08/28 15:06:15 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0,166 s
19/08/28 15:06:15 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0,465096 s
19/08/28 15:06:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `iris`
19/08/28 15:06:15 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:15 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:15 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:204)
19/08/28 15:06:15 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:15 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/08/28 15:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/08/28 15:06:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/08/28 15:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.3 KB, free 912.3 MB)
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.5 KB, free 912.3 MB)
19/08/28 15:06:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:58269 (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/08/28 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8774 bytes)
19/08/28 15:06:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/08/28 15:06:15 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:06:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1647 bytes result sent to driver
19/08/28 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on localhost (executor driver) (1/1)
19/08/28 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/08/28 15:06:15 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0,021 s
19/08/28 15:06:15 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:15 INFO DAGScheduler: running: Set()
19/08/28 15:06:15 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/08/28 15:06:15 INFO DAGScheduler: failed: Set()
19/08/28 15:06:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 912.3 MB)
19/08/28 15:06:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 912.2 MB)
19/08/28 15:06:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:06:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/08/28 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:15 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/08/28 15:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:06:15 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1495 bytes result sent to driver
19/08/28 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
19/08/28 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/08/28 15:06:15 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0,009 s
19/08/28 15:06:15 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0,055767 s
19/08/28 15:06:15 INFO CodeGenerator: Code generated in 8.823728 ms
19/08/28 15:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris` AS `zzz1`
WHERE (0 = 1)
19/08/28 15:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
LIMIT 11
19/08/28 15:06:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:16 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:16 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
19/08/28 15:06:16 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:16 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 912.2 MB)
19/08/28 15:06:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 912.2 MB)
19/08/28 15:06:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:58269 (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:06:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/08/28 15:06:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:06:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/08/28 15:06:16 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:06:16 INFO CodeGenerator: Code generated in 28.204228 ms
19/08/28 15:06:16 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_9_0]
19/08/28 15:06:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1355 bytes result sent to driver
19/08/28 15:06:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 66 ms on localhost (executor driver) (1/1)
19/08/28 15:06:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/08/28 15:06:16 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0,071 s
19/08/28 15:06:16 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0,090270 s
19/08/28 15:06:16 INFO CodeGenerator: Code generated in 10.675753 ms
19/08/28 15:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:06:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:18 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:18 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:18 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:18 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:18 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:18 INFO CodeGenerator: Code generated in 28.248324 ms
19/08/28 15:06:18 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:18 INFO DAGScheduler: Got job 4 (collect at utils.scala:44) with 1 output partitions
19/08/28 15:06:18 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:44)
19/08/28 15:06:18 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:18 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.3 KB, free 912.2 MB)
19/08/28 15:06:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 912.2 MB)
19/08/28 15:06:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:58269 (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:06:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/08/28 15:06:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/08/28 15:06:18 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 977 bytes result sent to driver
19/08/28 15:06:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 29 ms on localhost (executor driver) (1/1)
19/08/28 15:06:18 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/08/28 15:06:18 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:44) finished in 0,031 s
19/08/28 15:06:18 INFO DAGScheduler: Job 4 finished: collect at utils.scala:44, took 0,057728 s
19/08/28 15:06:32 INFO SparkSqlParser: Parsing command: flights
19/08/28 15:06:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/08/28 15:06:32 INFO SparkSqlParser: Parsing command: `flights`
19/08/28 15:06:33 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:06:33 INFO DAGScheduler: Registering RDD 36 (sql at <unknown>:0)
19/08/28 15:06:33 INFO DAGScheduler: Got job 5 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:06:33 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
19/08/28 15:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
19/08/28 15:06:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
19/08/28 15:06:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 30.7 KB, free 912.2 MB)
19/08/28 15:06:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.7 KB, free 912.2 MB)
19/08/28 15:06:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:58269 (size: 11.7 KB, free: 912.3 MB)
19/08/28 15:06:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[36] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/08/28 15:06:33 WARN TaskSetManager: Stage 7 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:06:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 114
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 123
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 122
19/08/28 15:06:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:58269 in memory (size: 6.5 KB, free: 912.3 MB)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 116
19/08/28 15:06:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:58269 in memory (size: 8.5 KB, free: 912.3 MB)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 124
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 119
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 112
19/08/28 15:06:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:58269 in memory (size: 3.5 KB, free: 912.3 MB)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 118
19/08/28 15:06:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 113
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 173
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 117
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 198
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 225
19/08/28 15:06:34 INFO ContextCleaner: Cleaned shuffle 1
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 121
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 115
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 120
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 59
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 55
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 61
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 54
19/08/28 15:06:34 INFO ContextCleaner: Cleaned shuffle 0
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 56
19/08/28 15:06:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 912.3 MB)
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 53
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 63
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 60
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 57
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 58
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 62
19/08/28 15:06:34 INFO ContextCleaner: Cleaned accumulator 52
19/08/28 15:06:34 INFO CodeGenerator: Code generated in 18.153419 ms
19/08/28 15:06:34 INFO CodeGenerator: Code generated in 111.173581 ms
19/08/28 15:06:38 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/08/28 15:06:38 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:58269 (size: 22.5 MB, free: 889.8 MB)
19/08/28 15:06:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2328 bytes result sent to driver
19/08/28 15:06:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5064 ms on localhost (executor driver) (1/1)
19/08/28 15:06:38 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 5,065 s
19/08/28 15:06:38 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:38 INFO DAGScheduler: running: Set()
19/08/28 15:06:38 INFO DAGScheduler: waiting: Set(ResultStage 8)
19/08/28 15:06:38 INFO DAGScheduler: failed: Set()
19/08/28 15:06:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:06:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:06:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/08/28 15:06:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/08/28 15:06:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/08/28 15:06:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:38 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1538 bytes result sent to driver
19/08/28 15:06:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 18 ms on localhost (executor driver) (1/1)
19/08/28 15:06:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/08/28 15:06:38 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0,020 s
19/08/28 15:06:38 INFO DAGScheduler: Job 5 finished: sql at <unknown>:0, took 5,149418 s
19/08/28 15:06:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/08/28 15:06:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:38 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/08/28 15:06:38 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:38 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/08/28 15:06:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
19/08/28 15:06:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
19/08/28 15:06:38 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.8 KB, free 889.7 MB)
19/08/28 15:06:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:58269 (size: 11.8 KB, free: 889.8 MB)
19/08/28 15:06:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/08/28 15:06:38 WARN TaskSetManager: Stage 9 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:06:38 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/08/28 15:06:38 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:06:38 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1690 bytes result sent to driver
19/08/28 15:06:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 462 ms on localhost (executor driver) (1/1)
19/08/28 15:06:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/08/28 15:06:38 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:204) finished in 0,466 s
19/08/28 15:06:38 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:38 INFO DAGScheduler: running: Set()
19/08/28 15:06:38 INFO DAGScheduler: waiting: Set(ResultStage 10)
19/08/28 15:06:38 INFO DAGScheduler: failed: Set()
19/08/28 15:06:38 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/08/28 15:06:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/08/28 15:06:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:06:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:38 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/08/28 15:06:38 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:38 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/08/28 15:06:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:06:38 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1495 bytes result sent to driver
19/08/28 15:06:38 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
19/08/28 15:06:38 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0,012 s
19/08/28 15:06:38 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/08/28 15:06:38 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0,498570 s
19/08/28 15:06:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz2`
WHERE (0 = 1)
19/08/28 15:06:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:38 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:38 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:39 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:39 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 2 output partitions
19/08/28 15:06:39 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:44)
19/08/28 15:06:39 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:39 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.4 KB, free 889.7 MB)
19/08/28 15:06:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.5 KB, free 889.7 MB)
19/08/28 15:06:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:58269 (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:06:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:39 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/08/28 15:06:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
19/08/28 15:06:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:39 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/08/28 15:06:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 894 bytes result sent to driver
19/08/28 15:06:39 INFO Executor: Running task 1.0 in stage 11.0 (TID 12)
19/08/28 15:06:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 7 ms on localhost (executor driver) (1/2)
19/08/28 15:06:39 INFO Executor: Finished task 1.0 in stage 11.0 (TID 12). 934 bytes result sent to driver
19/08/28 15:06:39 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 12) in 11 ms on localhost (executor driver) (2/2)
19/08/28 15:06:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/08/28 15:06:39 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:44) finished in 0,011 s
19/08/28 15:06:39 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0,021188 s
19/08/28 15:06:40 INFO SparkSqlParser: Parsing command: batting
19/08/28 15:06:40 INFO SparkSqlParser: Parsing command: CACHE TABLE `batting`
19/08/28 15:06:40 INFO SparkSqlParser: Parsing command: `batting`
19/08/28 15:06:40 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:06:40 INFO DAGScheduler: Registering RDD 58 (sql at <unknown>:0)
19/08/28 15:06:40 INFO DAGScheduler: Got job 8 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:06:40 INFO DAGScheduler: Final stage: ResultStage 13 (sql at <unknown>:0)
19/08/28 15:06:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/08/28 15:06:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/08/28 15:06:40 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.9 KB, free 889.6 MB)
19/08/28 15:06:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 889.6 MB)
19/08/28 15:06:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:58269 (size: 11.6 KB, free: 889.7 MB)
19/08/28 15:06:40 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[58] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/08/28 15:06:40 WARN TaskSetManager: Stage 12 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:06:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
19/08/28 15:06:41 INFO CodeGenerator: Code generated in 18.148477 ms
19/08/28 15:06:41 INFO CodeGenerator: Code generated in 98.059631 ms
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 287
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 296
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 294
19/08/28 15:06:41 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:58269 in memory (size: 11.8 KB, free: 889.8 MB)
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 298
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 297
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 289
19/08/28 15:06:41 INFO ContextCleaner: Cleaned shuffle 3
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 286
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 290
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 295
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 291
19/08/28 15:06:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:58269 in memory (size: 3.5 KB, free: 889.8 MB)
19/08/28 15:06:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 293
19/08/28 15:06:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 889.8 MB)
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 288
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 374
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 292
19/08/28 15:06:41 INFO ContextCleaner: Cleaned accumulator 347
19/08/28 15:06:42 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 3.4 MB, free 886.3 MB)
19/08/28 15:06:42 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:58269 (size: 3.4 MB, free: 886.4 MB)
19/08/28 15:06:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 2328 bytes result sent to driver
19/08/28 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 1847 ms on localhost (executor driver) (1/1)
19/08/28 15:06:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/08/28 15:06:42 INFO DAGScheduler: ShuffleMapStage 12 (sql at <unknown>:0) finished in 1,849 s
19/08/28 15:06:42 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:42 INFO DAGScheduler: running: Set()
19/08/28 15:06:42 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/08/28 15:06:42 INFO DAGScheduler: failed: Set()
19/08/28 15:06:42 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 15:06:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:06:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/08/28 15:06:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
19/08/28 15:06:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1495 bytes result sent to driver
19/08/28 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
19/08/28 15:06:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/08/28 15:06:42 INFO DAGScheduler: ResultStage 13 (sql at <unknown>:0) finished in 0,008 s
19/08/28 15:06:42 INFO DAGScheduler: Job 8 finished: sql at <unknown>:0, took 1,926642 s
19/08/28 15:06:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `batting`
19/08/28 15:06:42 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:42 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:42 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204)
19/08/28 15:06:42 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:42 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/08/28 15:06:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/08/28 15:06:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/08/28 15:06:42 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.9 KB, free 886.3 MB)
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.6 KB, free 886.3 MB)
19/08/28 15:06:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:58269 (size: 11.6 KB, free: 886.4 MB)
19/08/28 15:06:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/08/28 15:06:42 WARN TaskSetManager: Stage 14 contains a task of very large size (6842 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7006312 bytes)
19/08/28 15:06:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
19/08/28 15:06:42 INFO BlockManager: Found block rdd_55_0 locally
19/08/28 15:06:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1647 bytes result sent to driver
19/08/28 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 91 ms on localhost (executor driver) (1/1)
19/08/28 15:06:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/08/28 15:06:42 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0,092 s
19/08/28 15:06:42 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:42 INFO DAGScheduler: running: Set()
19/08/28 15:06:42 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/08/28 15:06:42 INFO DAGScheduler: failed: Set()
19/08/28 15:06:42 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 886.3 MB)
19/08/28 15:06:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 886.3 MB)
19/08/28 15:06:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:06:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/08/28 15:06:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
19/08/28 15:06:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:06:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1452 bytes result sent to driver
19/08/28 15:06:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 4 ms on localhost (executor driver) (1/1)
19/08/28 15:06:42 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0,005 s
19/08/28 15:06:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/08/28 15:06:42 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0,115252 s
19/08/28 15:06:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `batting` AS `zzz3`
WHERE (0 = 1)
19/08/28 15:06:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris`
19/08/28 15:06:43 INFO ContextCleaner: Cleaned accumulator 435
19/08/28 15:06:43 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:06:43 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 886.4 MB)
19/08/28 15:06:43 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:58269 in memory (size: 11.6 KB, free: 886.4 MB)
19/08/28 15:06:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:06:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:06:43 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:06:43 INFO DAGScheduler: Got job 10 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:06:43 INFO DAGScheduler: Final stage: ResultStage 16 (csv at <unknown>:0)
19/08/28 15:06:43 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:43 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:43 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0), which has no missing parents
19/08/28 15:06:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 89.4 KB, free 886.2 MB)
19/08/28 15:06:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.7 KB, free 886.2 MB)
19/08/28 15:06:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:58269 (size: 34.7 KB, free: 886.3 MB)
19/08/28 15:06:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:43 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/08/28 15:06:43 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8785 bytes)
19/08/28 15:06:43 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/08/28 15:06:43 INFO BlockManager: Found block rdd_9_0 locally
19/08/28 15:06:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/08/28 15:06:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/08/28 15:06:43 INFO FileOutputCommitter: Saved output of task 'attempt_20190828150643_0016_m_000000_0' to file:/C:/Users/Donnet/AppData/Local/Temp/RtmpaMAxgE/file35841ed422ba.csv/_temporary/0/task_20190828150643_0016_m_000000
19/08/28 15:06:43 INFO SparkHadoopMapRedUtil: attempt_20190828150643_0016_m_000000_0: Committed
19/08/28 15:06:43 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1619 bytes result sent to driver
19/08/28 15:06:43 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 177 ms on localhost (executor driver) (1/1)
19/08/28 15:06:43 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/08/28 15:06:43 INFO DAGScheduler: ResultStage 16 (csv at <unknown>:0) finished in 0,177 s
19/08/28 15:06:43 INFO DAGScheduler: Job 10 finished: csv at <unknown>:0, took 0,198621 s
19/08/28 15:06:43 INFO FileFormatWriter: Job null committed.
19/08/28 15:06:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:43 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:43 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:43 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:43 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:43 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 3 output partitions
19/08/28 15:06:43 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:44)
19/08/28 15:06:43 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:43 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:43 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:43 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.4 KB, free 886.2 MB)
19/08/28 15:06:43 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.5 KB, free 886.2 MB)
19/08/28 15:06:43 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:58269 (size: 3.5 KB, free: 886.3 MB)
19/08/28 15:06:43 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:43 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 17 (MapPartitionsRDD[75] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
19/08/28 15:06:43 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
19/08/28 15:06:43 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:43 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:43 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 20, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:43 INFO Executor: Running task 1.0 in stage 17.0 (TID 19)
19/08/28 15:06:43 INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
19/08/28 15:06:43 INFO Executor: Running task 2.0 in stage 17.0 (TID 20)
19/08/28 15:06:43 INFO Executor: Finished task 1.0 in stage 17.0 (TID 19). 894 bytes result sent to driver
19/08/28 15:06:43 INFO Executor: Finished task 2.0 in stage 17.0 (TID 20). 891 bytes result sent to driver
19/08/28 15:06:43 INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 894 bytes result sent to driver
19/08/28 15:06:43 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 19) in 5 ms on localhost (executor driver) (1/3)
19/08/28 15:06:43 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 20) in 5 ms on localhost (executor driver) (2/3)
19/08/28 15:06:43 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 5 ms on localhost (executor driver) (3/3)
19/08/28 15:06:43 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/08/28 15:06:43 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:44) finished in 0,006 s
19/08/28 15:06:43 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0,011088 s
19/08/28 15:06:45 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:06:45 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1213)) > 0)
19/08/28 15:06:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:06:45 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:06:45 INFO CodeGenerator: Code generated in 15.102062 ms
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 281.6 KB, free 885.9 MB)
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.9 MB)
19/08/28 15:06:45 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:58269 (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:06:45 INFO SparkContext: Created broadcast 18 from csv at <unknown>:0
19/08/28 15:06:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:06:45 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:06:45 INFO DAGScheduler: Got job 12 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:06:45 INFO DAGScheduler: Final stage: ResultStage 18 (csv at <unknown>:0)
19/08/28 15:06:45 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:45 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:45 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0), which has no missing parents
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KB, free 885.9 MB)
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.3 KB, free 885.9 MB)
19/08/28 15:06:45 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:58269 (size: 4.3 KB, free: 886.3 MB)
19/08/28 15:06:45 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:45 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/08/28 15:06:45 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 15:06:45 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
19/08/28 15:06:45 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpaMAxgE/file35841ed422ba.csv/part-00000-90d7d60f-5aca-471b-9ca6-fc92c1fd5c9b-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:06:45 INFO CodeGenerator: Code generated in 11.97544 ms
19/08/28 15:06:45 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1265 bytes result sent to driver
19/08/28 15:06:45 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 110 ms on localhost (executor driver) (1/1)
19/08/28 15:06:45 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/08/28 15:06:45 INFO DAGScheduler: ResultStage 18 (csv at <unknown>:0) finished in 0,112 s
19/08/28 15:06:45 INFO DAGScheduler: Job 12 finished: csv at <unknown>:0, took 0,138170 s
19/08/28 15:06:45 INFO CodeGenerator: Code generated in 11.285492 ms
19/08/28 15:06:45 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:06:45 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:06:45 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/08/28 15:06:45 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:06:45 INFO CodeGenerator: Code generated in 9.63494 ms
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.6 KB, free 885.6 MB)
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 24.0 KB, free 885.6 MB)
19/08/28 15:06:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:58269 (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:06:45 INFO SparkContext: Created broadcast 20 from csv at <unknown>:0
19/08/28 15:06:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:06:45 INFO SparkContext: Starting job: csv at <unknown>:0
19/08/28 15:06:45 INFO DAGScheduler: Got job 13 (csv at <unknown>:0) with 1 output partitions
19/08/28 15:06:45 INFO DAGScheduler: Final stage: ResultStage 19 (csv at <unknown>:0)
19/08/28 15:06:45 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:45 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:45 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0), which has no missing parents
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.3 KB, free 885.6 MB)
19/08/28 15:06:45 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KB, free 885.6 MB)
19/08/28 15:06:45 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:58269 (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:06:45 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[83] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:45 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/08/28 15:06:45 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5368 bytes)
19/08/28 15:06:45 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
19/08/28 15:06:45 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpaMAxgE/file35841ed422ba.csv/part-00000-90d7d60f-5aca-471b-9ca6-fc92c1fd5c9b-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:06:45 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 1495 bytes result sent to driver
19/08/28 15:06:45 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 65 ms on localhost (executor driver) (1/1)
19/08/28 15:06:45 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/08/28 15:06:45 INFO DAGScheduler: ResultStage 19 (csv at <unknown>:0) finished in 0,066 s
19/08/28 15:06:45 INFO DAGScheduler: Job 13 finished: csv at <unknown>:0, took 0,089072 s
19/08/28 15:06:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:45 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:45 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:45 INFO CodeGenerator: Code generated in 12.916278 ms
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: iris_csv
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: CACHE TABLE `iris_csv`
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: `iris_csv`
19/08/28 15:06:46 INFO FileSourceStrategy: Pruning directories with: 
19/08/28 15:06:46 INFO FileSourceStrategy: Post-Scan Filters: 
19/08/28 15:06:46 INFO FileSourceStrategy: Output Data Schema: struct<Sepal_Length: double, Sepal_Width: double, Petal_Length: double, Petal_Width: double, Species: string ... 3 more fields>
19/08/28 15:06:46 INFO FileSourceScanExec: Pushed Filters: 
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 282.7 KB, free 885.3 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.1 KB, free 885.3 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:58269 (size: 24.1 KB, free: 886.3 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 22 from sql at <unknown>:0
19/08/28 15:06:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/08/28 15:06:46 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:06:46 INFO DAGScheduler: Registering RDD 89 (sql at <unknown>:0)
19/08/28 15:06:46 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:06:46 INFO DAGScheduler: Final stage: ResultStage 21 (sql at <unknown>:0)
19/08/28 15:06:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/08/28 15:06:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/08/28 15:06:46 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 19.9 KB, free 885.2 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.2 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:58269 (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[89] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:46 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/08/28 15:06:46 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 15:06:46 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
19/08/28 15:06:46 INFO FileScanRDD: Reading File path: file:///C:/Users/Donnet/AppData/Local/Temp/RtmpaMAxgE/file35841ed422ba.csv/part-00000-90d7d60f-5aca-471b-9ca6-fc92c1fd5c9b-c000.csv, range: 0-4009, partition values: [empty row]
19/08/28 15:06:46 INFO MemoryStore: Block rdd_86_0 stored as values in memory (estimated size 5.6 KB, free 885.2 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added rdd_86_0 in memory on 127.0.0.1:58269 (size: 5.6 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2461 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 80 ms on localhost (executor driver) (1/1)
19/08/28 15:06:46 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/08/28 15:06:46 INFO DAGScheduler: ShuffleMapStage 20 (sql at <unknown>:0) finished in 0,082 s
19/08/28 15:06:46 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:46 INFO DAGScheduler: running: Set()
19/08/28 15:06:46 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/08/28 15:06:46 INFO DAGScheduler: failed: Set()
19/08/28 15:06:46 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 7.0 KB, free 885.2 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.2 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[92] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:46 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/08/28 15:06:46 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:46 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
19/08/28 15:06:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:46 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 1581 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:06:46 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/08/28 15:06:46 INFO DAGScheduler: ResultStage 21 (sql at <unknown>:0) finished in 0,009 s
19/08/28 15:06:46 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0,118821 s
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `iris_csv`
19/08/28 15:06:46 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:46 INFO DAGScheduler: Registering RDD 95 (collect at utils.scala:204)
19/08/28 15:06:46 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:46 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/08/28 15:06:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/08/28 15:06:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/08/28 15:06:46 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.9 KB, free 885.2 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.9 KB, free 885.2 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:58269 (size: 9.9 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:46 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/08/28 15:06:46 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5357 bytes)
19/08/28 15:06:46 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
19/08/28 15:06:46 INFO BlockManager: Found block rdd_86_0 locally
19/08/28 15:06:46 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1737 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 16 ms on localhost (executor driver) (1/1)
19/08/28 15:06:46 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0,017 s
19/08/28 15:06:46 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:46 INFO DAGScheduler: running: Set()
19/08/28 15:06:46 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/08/28 15:06:46 INFO DAGScheduler: failed: Set()
19/08/28 15:06:46 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 885.2 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.2 MB)
19/08/28 15:06:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[98] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:46 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/08/28 15:06:46 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:46 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
19/08/28 15:06:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:46 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1538 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 7 ms on localhost (executor driver) (1/1)
19/08/28 15:06:46 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/08/28 15:06:46 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0,009 s
19/08/28 15:06:46 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0,044567 s
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `iris_csv` AS `zzz4`
WHERE (0 = 1)
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:46 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:46 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:46 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:46 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:46 INFO DAGScheduler: Got job 16 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:06:46 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/08/28 15:06:46 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:46 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:46 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.5 KB, free 885.2 MB)
19/08/28 15:06:46 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.2 MB)
19/08/28 15:06:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:58269 (size: 3.6 KB, free: 886.2 MB)
19/08/28 15:06:46 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[103] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:06:46 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/08/28 15:06:46 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:46 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:46 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 29, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:46 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 30, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:46 INFO Executor: Running task 1.0 in stage 24.0 (TID 28)
19/08/28 15:06:46 INFO Executor: Running task 2.0 in stage 24.0 (TID 29)
19/08/28 15:06:46 INFO Executor: Running task 3.0 in stage 24.0 (TID 30)
19/08/28 15:06:46 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/08/28 15:06:46 INFO Executor: Finished task 3.0 in stage 24.0 (TID 30). 938 bytes result sent to driver
19/08/28 15:06:46 INFO Executor: Finished task 2.0 in stage 24.0 (TID 29). 891 bytes result sent to driver
19/08/28 15:06:46 INFO Executor: Finished task 1.0 in stage 24.0 (TID 28). 894 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 30) in 15 ms on localhost (executor driver) (1/4)
19/08/28 15:06:46 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 894 bytes result sent to driver
19/08/28 15:06:46 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 29) in 20 ms on localhost (executor driver) (2/4)
19/08/28 15:06:46 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 28) in 21 ms on localhost (executor driver) (3/4)
19/08/28 15:06:46 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 22 ms on localhost (executor driver) (4/4)
19/08/28 15:06:46 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/08/28 15:06:46 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0,023 s
19/08/28 15:06:46 INFO DAGScheduler: Job 16 finished: collect at utils.scala:44, took 0,035773 s
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:06:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:06:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:06:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
LIMIT 11
19/08/28 15:06:47 INFO InMemoryTableScanExec: Predicate isnotnull(dep_delay#228) generates partition filter: ((dep_delay.count#1479 - dep_delay.nullCount#1478) > 0)
19/08/28 15:06:47 INFO InMemoryTableScanExec: Predicate (dep_delay#228 = 2.0) generates partition filter: ((dep_delay.lowerBound#1477 <= 2.0) && (2.0 <= dep_delay.upperBound#1476))
19/08/28 15:06:47 INFO CodeGenerator: Code generated in 18.359072 ms
19/08/28 15:06:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:47 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:47 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/08/28 15:06:47 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:47 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:47 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:47 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.7 KB, free 885.1 MB)
19/08/28 15:06:47 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 885.1 MB)
19/08/28 15:06:47 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:58269 (size: 12.5 KB, free: 886.2 MB)
19/08/28 15:06:47 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[106] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:47 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/08/28 15:06:47 WARN TaskSetManager: Stage 25 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:47 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364187 bytes)
19/08/28 15:06:47 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
19/08/28 15:06:48 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:06:48 INFO CodeGenerator: Code generated in 8.79978 ms
19/08/28 15:06:48 INFO CodeGenerator: Code generated in 26.119939 ms
19/08/28 15:06:48 INFO Executor: 1 block locks were not released by TID = 31:
[rdd_33_0]
19/08/28 15:06:48 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2230 bytes result sent to driver
19/08/28 15:06:48 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 525 ms on localhost (executor driver) (1/1)
19/08/28 15:06:48 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/08/28 15:06:48 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0,526 s
19/08/28 15:06:48 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0,550145 s
19/08/28 15:06:48 INFO CodeGenerator: Code generated in 16.900488 ms
19/08/28 15:06:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights`
WHERE (`dep_delay` = 2.0)
19/08/28 15:06:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ujgnhchkis`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `oizbxbvjyg`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ehjoqgwamz`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:48 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:48 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `shtigabhxm`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
LIMIT 11
19/08/28 15:06:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:49 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:49 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 580
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 611
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:58269 in memory (size: 34.7 KB, free: 886.2 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 683
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 521
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 677
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:58269 in memory (size: 3.6 KB, free: 886.2 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 680
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 623
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 672
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 546
19/08/28 15:06:49 INFO ContextCleaner: Cleaned shuffle 7
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 673
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 614
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 577
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 758
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 616
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:58269 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 31.30158 ms
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 617
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 675
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 549
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 622
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 676
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 613
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 621
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 684
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 496
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 579
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 548
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 679
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 678
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:58269 in memory (size: 3.5 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 612
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:58269 in memory (size: 4.3 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 682
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 578
19/08/28 15:06:49 INFO ContextCleaner: Cleaned shuffle 6
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:58269 in memory (size: 8.2 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 45.024507 ms
19/08/28 15:06:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:49 INFO DAGScheduler: Registering RDD 109 (collect at utils.scala:204)
19/08/28 15:06:49 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:49 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/08/28 15:06:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/08/28 15:06:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/08/28 15:06:49 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:49 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 50.3 KB, free 885.6 MB)
19/08/28 15:06:49 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 19.8 KB, free 885.5 MB)
19/08/28 15:06:49 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:58269 (size: 19.8 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:49 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 733
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 551
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 620
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:58269 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:58269 in memory (size: 12.5 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 576
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 674
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:58269 in memory (size: 9.9 KB, free: 886.3 MB)
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 681
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 618
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 619
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 615
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 759
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 547
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 550
19/08/28 15:06:49 INFO ContextCleaner: Cleaned accumulator 760
19/08/28 15:06:49 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:58269 in memory (size: 24.0 KB, free: 886.3 MB)
19/08/28 15:06:49 WARN TaskSetManager: Stage 26 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:49 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:06:49 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
19/08/28 15:06:49 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 19.136832 ms
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 7.013138 ms
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 6.681279 ms
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 6.914683 ms
19/08/28 15:06:49 INFO CodeGenerator: Code generated in 12.515614 ms
19/08/28 15:06:50 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 1921 bytes result sent to driver
19/08/28 15:06:50 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 827 ms on localhost (executor driver) (1/1)
19/08/28 15:06:50 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/08/28 15:06:50 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0,828 s
19/08/28 15:06:50 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:50 INFO DAGScheduler: running: Set()
19/08/28 15:06:50 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/08/28 15:06:50 INFO DAGScheduler: failed: Set()
19/08/28 15:06:50 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:50 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 27.0 KB, free 885.9 MB)
19/08/28 15:06:50 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.9 MB)
19/08/28 15:06:50 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:58269 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:06:50 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:50 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/08/28 15:06:50 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:50 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
19/08/28 15:06:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:50 WARN Executor: Managed memory leak detected; size = 8650752 bytes, TID = 33
19/08/28 15:06:50 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 2648 bytes result sent to driver
19/08/28 15:06:50 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 22 ms on localhost (executor driver) (1/1)
19/08/28 15:06:50 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/08/28 15:06:50 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0,023 s
19/08/28 15:06:50 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0,877338 s
19/08/28 15:06:50 INFO CodeGenerator: Code generated in 7.200926 ms
19/08/28 15:06:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `bzwggrdwbj`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `sbqxvezmdz`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `ejkgwtzzks`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:50 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:50 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/08/28 15:06:50 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 4 output partitions
19/08/28 15:06:50 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/08/28 15:06:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/08/28 15:06:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/08/28 15:06:50 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:50 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 50.3 KB, free 885.9 MB)
19/08/28 15:06:50 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 20.0 KB, free 885.8 MB)
19/08/28 15:06:50 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:58269 (size: 20.0 KB, free: 886.3 MB)
19/08/28 15:06:50 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:50 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/08/28 15:06:50 WARN TaskSetManager: Stage 28 contains a task of very large size (27699 KB). The maximum recommended task size is 100 KB.
19/08/28 15:06:50 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 28364176 bytes)
19/08/28 15:06:50 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 789
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 788
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 794
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 786
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 787
19/08/28 15:06:50 INFO ContextCleaner: Cleaned accumulator 795
19/08/28 15:06:50 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:58269 in memory (size: 19.8 KB, free: 886.3 MB)
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 796
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 797
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 790
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 791
19/08/28 15:06:51 INFO ContextCleaner: Cleaned shuffle 8
19/08/28 15:06:51 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:58269 in memory (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 792
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 785
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 847
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 793
19/08/28 15:06:51 INFO ContextCleaner: Cleaned accumulator 798
19/08/28 15:06:51 INFO BlockManager: Found block rdd_33_0 locally
19/08/28 15:06:51 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 1964 bytes result sent to driver
19/08/28 15:06:51 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 580 ms on localhost (executor driver) (1/1)
19/08/28 15:06:51 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/08/28 15:06:51 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0,590 s
19/08/28 15:06:51 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:51 INFO DAGScheduler: running: Set()
19/08/28 15:06:51 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/08/28 15:06:51 INFO DAGScheduler: failed: Set()
19/08/28 15:06:51 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:51 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 27.2 KB, free 885.9 MB)
19/08/28 15:06:51 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.6 KB, free 885.9 MB)
19/08/28 15:06:51 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:58269 (size: 11.6 KB, free: 886.3 MB)
19/08/28 15:06:51 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:06:51 INFO TaskSchedulerImpl: Adding task set 29.0 with 4 tasks
19/08/28 15:06:51 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:51 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 36, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/08/28 15:06:51 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 37, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/08/28 15:06:51 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 38, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/08/28 15:06:51 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
19/08/28 15:06:51 INFO Executor: Running task 1.0 in stage 29.0 (TID 36)
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/08/28 15:06:51 INFO Executor: Running task 3.0 in stage 29.0 (TID 38)
19/08/28 15:06:51 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 21599 bytes result sent to driver
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:51 INFO Executor: Running task 2.0 in stage 29.0 (TID 37)
19/08/28 15:06:51 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 26 ms on localhost (executor driver) (1/4)
19/08/28 15:06:51 INFO Executor: Finished task 3.0 in stage 29.0 (TID 38). 20842 bytes result sent to driver
19/08/28 15:06:51 INFO Executor: Finished task 1.0 in stage 29.0 (TID 36). 21861 bytes result sent to driver
19/08/28 15:06:51 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 38) in 29 ms on localhost (executor driver) (2/4)
19/08/28 15:06:51 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 36) in 31 ms on localhost (executor driver) (3/4)
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:51 INFO Executor: Finished task 2.0 in stage 29.0 (TID 37). 22702 bytes result sent to driver
19/08/28 15:06:51 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 37) in 39 ms on localhost (executor driver) (4/4)
19/08/28 15:06:51 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/08/28 15:06:51 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0,039 s
19/08/28 15:06:51 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0,650323 s
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/08/28 15:06:53 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:53 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:53 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:53 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/08/28 15:06:53 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/08/28 15:06:53 INFO SparkContext: Starting job: collect at utils.scala:44
19/08/28 15:06:53 INFO DAGScheduler: Got job 20 (collect at utils.scala:44) with 4 output partitions
19/08/28 15:06:53 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:44)
19/08/28 15:06:53 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:53 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:53 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41), which has no missing parents
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.5 KB, free 885.9 MB)
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.6 KB, free 885.9 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:58269 (size: 3.6 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/08/28 15:06:53 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/08/28 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:53 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:53 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:53 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 5011 bytes)
19/08/28 15:06:53 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
19/08/28 15:06:53 INFO Executor: Running task 3.0 in stage 30.0 (TID 42)
19/08/28 15:06:53 INFO Executor: Running task 2.0 in stage 30.0 (TID 41)
19/08/28 15:06:53 INFO Executor: Running task 1.0 in stage 30.0 (TID 40)
19/08/28 15:06:53 INFO Executor: Finished task 1.0 in stage 30.0 (TID 40). 894 bytes result sent to driver
19/08/28 15:06:53 INFO Executor: Finished task 2.0 in stage 30.0 (TID 41). 891 bytes result sent to driver
19/08/28 15:06:53 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 937 bytes result sent to driver
19/08/28 15:06:53 INFO Executor: Finished task 3.0 in stage 30.0 (TID 42). 895 bytes result sent to driver
19/08/28 15:06:53 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 40) in 16 ms on localhost (executor driver) (1/4)
19/08/28 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 16 ms on localhost (executor driver) (2/4)
19/08/28 15:06:53 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 41) in 20 ms on localhost (executor driver) (3/4)
19/08/28 15:06:53 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 42) in 35 ms on localhost (executor driver) (4/4)
19/08/28 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/08/28 15:06:53 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:44) finished in 0,037 s
19/08/28 15:06:53 INFO DAGScheduler: Job 20 finished: collect at utils.scala:44, took 0,044510 s
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: mtcars
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: CACHE TABLE `mtcars`
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: `mtcars`
19/08/28 15:06:53 INFO SparkContext: Starting job: sql at <unknown>:0
19/08/28 15:06:53 INFO DAGScheduler: Registering RDD 131 (sql at <unknown>:0)
19/08/28 15:06:53 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/08/28 15:06:53 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
19/08/28 15:06:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
19/08/28 15:06:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
19/08/28 15:06:53 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 22.4 KB, free 885.9 MB)
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.9 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:58269 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[131] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:53 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/08/28 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:06:53 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
19/08/28 15:06:53 INFO CodeGenerator: Code generated in 7.392135 ms
19/08/28 15:06:53 INFO CodeGenerator: Code generated in 37.519473 ms
19/08/28 15:06:53 INFO MemoryStore: Block rdd_128_0 stored as values in memory (estimated size 4.2 KB, free 885.9 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added rdd_128_0 in memory on 127.0.0.1:58269 (size: 4.2 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2285 bytes result sent to driver
19/08/28 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 70 ms on localhost (executor driver) (1/1)
19/08/28 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/08/28 15:06:53 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0,071 s
19/08/28 15:06:53 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:53 INFO DAGScheduler: running: Set()
19/08/28 15:06:53 INFO DAGScheduler: waiting: Set(ResultStage 32)
19/08/28 15:06:53 INFO DAGScheduler: failed: Set()
19/08/28 15:06:53 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 7.0 KB, free 885.9 MB)
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.9 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[134] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:53 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/08/28 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:53 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
19/08/28 15:06:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:53 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 1495 bytes result sent to driver
19/08/28 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
19/08/28 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/08/28 15:06:53 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0,008 s
19/08/28 15:06:53 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0,091263 s
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `mtcars`
19/08/28 15:06:53 INFO HiveMetaStore: 0: get_database: default
19/08/28 15:06:53 INFO audit: ugi=Donnet	ip=unknown-ip-addr	cmd=get_database: default	
19/08/28 15:06:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/08/28 15:06:53 INFO DAGScheduler: Registering RDD 137 (collect at utils.scala:204)
19/08/28 15:06:53 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/08/28 15:06:53 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/08/28 15:06:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/08/28 15:06:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/08/28 15:06:53 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 22.4 KB, free 885.8 MB)
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.3 KB, free 885.8 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:58269 (size: 9.3 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[137] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:53 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/08/28 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:06:53 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
19/08/28 15:06:53 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:53 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 1647 bytes result sent to driver
19/08/28 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 18 ms on localhost (executor driver) (1/1)
19/08/28 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/08/28 15:06:53 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0,018 s
19/08/28 15:06:53 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:53 INFO DAGScheduler: running: Set()
19/08/28 15:06:53 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/08/28 15:06:53 INFO DAGScheduler: failed: Set()
19/08/28 15:06:53 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 885.8 MB)
19/08/28 15:06:53 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.8 MB)
19/08/28 15:06:53 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.3 MB)
19/08/28 15:06:53 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:53 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/08/28 15:06:53 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:53 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
19/08/28 15:06:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:53 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 1538 bytes result sent to driver
19/08/28 15:06:53 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 12 ms on localhost (executor driver) (1/1)
19/08/28 15:06:53 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/08/28 15:06:53 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0,012 s
19/08/28 15:06:53 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0,048851 s
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `mtcars` AS `zzz5`
WHERE (0 = 1)
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: SELECT `mpg`, `cyl`, `disp`, `hp`, `drat`, `wt`, `qsec`, `vs`, `am`, `gear`, `carb`, `cyl` = 8.0 AS `cyl8`
FROM `mtcars`
WHERE (`hp` >= 100.0)
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: sparklyr_tmp_3584a3d3d13
19/08/28 15:06:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584a3d3d13` AS `zzz6`
WHERE (0 = 1)
19/08/28 15:06:54 INFO SparkSqlParser: Parsing command: sparklyr_tmp_3584731476de
19/08/28 15:06:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584731476de` AS `zzz7`
WHERE (0 = 1)
19/08/28 15:06:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584a3d3d13`
19/08/28 15:06:54 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2292 - hp.nullCount#2291) > 0)
19/08/28 15:06:54 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2289)
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 42.349106 ms
19/08/28 15:06:54 INFO SparkContext: Starting job: first at LinearRegression.scala:198
19/08/28 15:06:54 INFO DAGScheduler: Got job 23 (first at LinearRegression.scala:198) with 1 output partitions
19/08/28 15:06:54 INFO DAGScheduler: Final stage: ResultStage 35 (first at LinearRegression.scala:198)
19/08/28 15:06:54 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:54 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:54 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198), which has no missing parents
19/08/28 15:06:54 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 41.3 KB, free 885.8 MB)
19/08/28 15:06:54 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.3 KB, free 885.8 MB)
19/08/28 15:06:54 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:58269 (size: 16.3 KB, free: 886.3 MB)
19/08/28 15:06:54 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[143] at first at LinearRegression.scala:198) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:54 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/08/28 15:06:54 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:06:54 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
19/08/28 15:06:54 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 10.569695 ms
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 17.476776 ms
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 41.833262 ms
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 15.052645 ms
19/08/28 15:06:54 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 1743 bytes result sent to driver
19/08/28 15:06:54 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 188 ms on localhost (executor driver) (1/1)
19/08/28 15:06:54 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/08/28 15:06:54 INFO DAGScheduler: ResultStage 35 (first at LinearRegression.scala:198) finished in 0,190 s
19/08/28 15:06:54 INFO DAGScheduler: Job 23 finished: first at LinearRegression.scala:198, took 0,200002 s
19/08/28 15:06:54 INFO CodeGenerator: Code generated in 10.224152 ms
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2353 - hp.nullCount#2352) > 0)
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2350)
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 27.253126 ms
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2409 - hp.nullCount#2408) > 0)
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2406)
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 23.650193 ms
19/08/28 15:06:55 INFO Instrumentation: LinearRegression-linear_regression_358453754faf-993604084-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
19/08/28 15:06:55 INFO Instrumentation: LinearRegression-linear_regression_358453754faf-993604084-1: {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"regParam":0.0,"tol":1.0E-6,"maxIter":100}
19/08/28 15:06:55 INFO Instrumentation: LinearRegression-linear_regression_358453754faf-993604084-1: {"numFeatures":2}
19/08/28 15:06:55 WARN WeightedLeastSquares: regParam is zero, which might cause numerical instability and overfitting.
19/08/28 15:06:55 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:100
19/08/28 15:06:55 INFO DAGScheduler: Got job 24 (treeAggregate at WeightedLeastSquares.scala:100) with 1 output partitions
19/08/28 15:06:55 INFO DAGScheduler: Final stage: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100)
19/08/28 15:06:55 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:55 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:55 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100), which has no missing parents
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 885.7 MB)
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 17.6 KB, free 885.7 MB)
19/08/28 15:06:55 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:58269 (size: 17.6 KB, free: 886.3 MB)
19/08/28 15:06:55 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[153] at treeAggregate at WeightedLeastSquares.scala:100) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:55 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/08/28 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:06:55 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
19/08/28 15:06:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 6.677858 ms
19/08/28 15:06:55 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
19/08/28 15:06:55 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
19/08/28 15:06:55 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 2184 bytes result sent to driver
19/08/28 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 45 ms on localhost (executor driver) (1/1)
19/08/28 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/08/28 15:06:55 INFO DAGScheduler: ResultStage 36 (treeAggregate at WeightedLeastSquares.scala:100) finished in 0,045 s
19/08/28 15:06:55 INFO DAGScheduler: Job 24 finished: treeAggregate at WeightedLeastSquares.scala:100, took 0,055411 s
19/08/28 15:06:55 INFO WeightedLeastSquares: Number of instances: 8.
19/08/28 15:06:55 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
19/08/28 15:06:55 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2486 - hp.nullCount#2485) > 0)
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2483)
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 21.543095 ms
19/08/28 15:06:55 INFO SparkContext: Starting job: aggregate at RegressionMetrics.scala:57
19/08/28 15:06:55 INFO DAGScheduler: Got job 25 (aggregate at RegressionMetrics.scala:57) with 1 output partitions
19/08/28 15:06:55 INFO DAGScheduler: Final stage: ResultStage 37 (aggregate at RegressionMetrics.scala:57)
19/08/28 15:06:55 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:55 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:55 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55), which has no missing parents
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 44.2 KB, free 885.6 MB)
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 17.9 KB, free 885.6 MB)
19/08/28 15:06:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:58269 (size: 17.9 KB, free: 886.2 MB)
19/08/28 15:06:55 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[159] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:55 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/08/28 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:06:55 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
19/08/28 15:06:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 12.786651 ms
19/08/28 15:06:55 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2180 bytes result sent to driver
19/08/28 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 43 ms on localhost (executor driver) (1/1)
19/08/28 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/08/28 15:06:55 INFO DAGScheduler: ResultStage 37 (aggregate at RegressionMetrics.scala:57) finished in 0,044 s
19/08/28 15:06:55 INFO DAGScheduler: Job 25 finished: aggregate at RegressionMetrics.scala:57, took 0,053158 s
19/08/28 15:06:55 INFO SparkContext: Starting job: sum at RegressionMetrics.scala:71
19/08/28 15:06:55 INFO DAGScheduler: Got job 26 (sum at RegressionMetrics.scala:71) with 1 output partitions
19/08/28 15:06:55 INFO DAGScheduler: Final stage: ResultStage 38 (sum at RegressionMetrics.scala:71)
19/08/28 15:06:55 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:55 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:55 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69), which has no missing parents
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 43.8 KB, free 885.6 MB)
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.8 KB, free 885.6 MB)
19/08/28 15:06:55 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:58269 (size: 17.8 KB, free: 886.2 MB)
19/08/28 15:06:55 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[160] at map at RegressionMetrics.scala:69) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:55 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/08/28 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:06:55 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
19/08/28 15:06:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:55 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 1697 bytes result sent to driver
19/08/28 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 9 ms on localhost (executor driver) (1/1)
19/08/28 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/08/28 15:06:55 INFO DAGScheduler: ResultStage 38 (sum at RegressionMetrics.scala:71) finished in 0,010 s
19/08/28 15:06:55 INFO DAGScheduler: Job 26 finished: sum at RegressionMetrics.scala:71, took 0,017389 s
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2561 - hp.nullCount#2560) > 0)
19/08/28 15:06:55 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2558)
19/08/28 15:06:55 INFO CodeGenerator: Code generated in 16.729428 ms
19/08/28 15:06:55 INFO SparkContext: Starting job: count at LinearRegression.scala:696
19/08/28 15:06:55 INFO DAGScheduler: Registering RDD 163 (count at LinearRegression.scala:696)
19/08/28 15:06:55 INFO DAGScheduler: Got job 27 (count at LinearRegression.scala:696) with 1 output partitions
19/08/28 15:06:55 INFO DAGScheduler: Final stage: ResultStage 40 (count at LinearRegression.scala:696)
19/08/28 15:06:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/08/28 15:06:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/08/28 15:06:55 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 36.6 KB, free 885.5 MB)
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.5 MB)
19/08/28 15:06:55 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:58269 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:06:55 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[163] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:55 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/08/28 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:06:55 INFO Executor: Running task 0.0 in stage 39.0 (TID 51)
19/08/28 15:06:55 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:55 INFO Executor: Finished task 0.0 in stage 39.0 (TID 51). 2275 bytes result sent to driver
19/08/28 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 51) in 16 ms on localhost (executor driver) (1/1)
19/08/28 15:06:55 INFO DAGScheduler: ShuffleMapStage 39 (count at LinearRegression.scala:696) finished in 0,016 s
19/08/28 15:06:55 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:55 INFO DAGScheduler: running: Set()
19/08/28 15:06:55 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/08/28 15:06:55 INFO DAGScheduler: failed: Set()
19/08/28 15:06:55 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696), which has no missing parents
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.0 KB, free 885.5 MB)
19/08/28 15:06:55 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.5 MB)
19/08/28 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/08/28 15:06:55 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:06:55 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[166] at count at LinearRegression.scala:696) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:55 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/08/28 15:06:55 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 52, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:55 INFO Executor: Running task 0.0 in stage 40.0 (TID 52)
19/08/28 15:06:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:55 INFO Executor: Finished task 0.0 in stage 40.0 (TID 52). 1495 bytes result sent to driver
19/08/28 15:06:55 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
19/08/28 15:06:55 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/08/28 15:06:55 INFO DAGScheduler: ResultStage 40 (count at LinearRegression.scala:696) finished in 0,005 s
19/08/28 15:06:55 INFO DAGScheduler: Job 27 finished: count at LinearRegression.scala:696, took 0,038258 s
19/08/28 15:06:55 INFO Instrumentation: LinearRegression-linear_regression_358453754faf-993604084-1: training finished
19/08/28 15:06:55 INFO SparkSqlParser: Parsing command: sparklyr_tmp_3584525e4523
19/08/28 15:06:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584525e4523` AS `zzz8`
WHERE (0 = 1)
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584a3d3d13`
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_3584a14674c
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584a14674c` AS `zzz9`
WHERE (0 = 1)
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_3584a14674c`
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_35844e076b3
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_35844e076b3` AS `zzz10`
WHERE (0 = 1)
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: sparklyr_tmp_35847d7c3bc0
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_35847d7c3bc0` AS `zzz11`
WHERE (0 = 1)
19/08/28 15:06:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_35847d7c3bc0`
19/08/28 15:06:56 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2783 - hp.nullCount#2782) > 0)
19/08/28 15:06:56 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2780)
19/08/28 15:06:56 INFO SparkContext: Starting job: count at <unknown>:0
19/08/28 15:06:56 INFO DAGScheduler: Registering RDD 169 (count at <unknown>:0)
19/08/28 15:06:56 INFO DAGScheduler: Got job 28 (count at <unknown>:0) with 1 output partitions
19/08/28 15:06:56 INFO DAGScheduler: Final stage: ResultStage 42 (count at <unknown>:0)
19/08/28 15:06:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/08/28 15:06:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/08/28 15:06:56 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0), which has no missing parents
19/08/28 15:06:56 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 36.6 KB, free 885.5 MB)
19/08/28 15:06:56 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 14.8 KB, free 885.5 MB)
19/08/28 15:06:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:58269 (size: 14.8 KB, free: 886.2 MB)
19/08/28 15:06:56 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[169] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:56 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/08/28 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6116 bytes)
19/08/28 15:06:56 INFO Executor: Running task 0.0 in stage 41.0 (TID 53)
19/08/28 15:06:56 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:56 INFO Executor: Finished task 0.0 in stage 41.0 (TID 53). 2318 bytes result sent to driver
19/08/28 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 53) in 22 ms on localhost (executor driver) (1/1)
19/08/28 15:06:56 INFO DAGScheduler: ShuffleMapStage 41 (count at <unknown>:0) finished in 0,026 s
19/08/28 15:06:56 INFO DAGScheduler: looking for newly runnable stages
19/08/28 15:06:56 INFO DAGScheduler: running: Set()
19/08/28 15:06:56 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/08/28 15:06:56 INFO DAGScheduler: failed: Set()
19/08/28 15:06:56 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0), which has no missing parents
19/08/28 15:06:56 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.0 KB, free 885.5 MB)
19/08/28 15:06:56 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 885.5 MB)
19/08/28 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/08/28 15:06:56 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:58269 (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:06:56 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[172] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:56 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/08/28 15:06:56 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 54, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/08/28 15:06:56 INFO Executor: Running task 0.0 in stage 42.0 (TID 54)
19/08/28 15:06:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/08/28 15:06:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/08/28 15:06:56 INFO Executor: Finished task 0.0 in stage 42.0 (TID 54). 1538 bytes result sent to driver
19/08/28 15:06:56 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 54) in 16 ms on localhost (executor driver) (1/1)
19/08/28 15:06:56 INFO DAGScheduler: ResultStage 42 (count at <unknown>:0) finished in 0,017 s
19/08/28 15:06:56 INFO DAGScheduler: Job 28 finished: count at <unknown>:0, took 0,123156 s
19/08/28 15:06:56 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/08/28 15:06:57 INFO InMemoryTableScanExec: Predicate isnotnull(hp#1877) generates partition filter: ((hp.count#2843 - hp.nullCount#2842) > 0)
19/08/28 15:06:57 INFO InMemoryTableScanExec: Predicate (hp#1877 >= 100.0) generates partition filter: (100.0 <= hp.upperBound#2840)
19/08/28 15:06:57 INFO CodeGenerator: Code generated in 30.220471 ms
19/08/28 15:06:57 INFO SparkContext: Starting job: collect at utils.scala:37
19/08/28 15:06:57 INFO DAGScheduler: Got job 29 (collect at utils.scala:37) with 1 output partitions
19/08/28 15:06:57 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:37)
19/08/28 15:06:57 INFO DAGScheduler: Parents of final stage: List()
19/08/28 15:06:57 INFO DAGScheduler: Missing parents: List()
19/08/28 15:06:57 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34), which has no missing parents
19/08/28 15:06:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 885.4 MB)
19/08/28 15:06:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 19.3 KB, free 885.4 MB)
19/08/28 15:06:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:58269 (size: 19.3 KB, free: 886.2 MB)
19/08/28 15:06:57 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/08/28 15:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[177] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
19/08/28 15:06:57 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/08/28 15:06:57 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 6127 bytes)
19/08/28 15:06:57 INFO Executor: Running task 0.0 in stage 43.0 (TID 55)
19/08/28 15:06:57 INFO BlockManager: Found block rdd_128_0 locally
19/08/28 15:06:57 INFO CodeGenerator: Code generated in 9.741378 ms
19/08/28 15:06:57 INFO Executor: Finished task 0.0 in stage 43.0 (TID 55). 1704 bytes result sent to driver
19/08/28 15:06:57 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 55) in 39 ms on localhost (executor driver) (1/1)
19/08/28 15:06:57 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/08/28 15:06:57 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:37) finished in 0,046 s
19/08/28 15:06:57 INFO DAGScheduler: Job 29 finished: collect at utils.scala:37, took 0,058750 s
19/08/28 15:06:58 INFO SparkContext: Invoking stop() from shutdown hook
19/08/28 15:06:58 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:58269 in memory (size: 19.3 KB, free: 886.2 MB)
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1182
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 850
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 856
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1257
19/08/28 15:06:58 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:58269 in memory (size: 3.6 KB, free: 886.2 MB)
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1320
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1060
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1062
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 848
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1183
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1256
19/08/28 15:06:58 INFO ContextCleaner: Cleaned shuffle 10
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1196
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1100
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1318
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1255
19/08/28 15:06:58 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:58269 in memory (size: 3.7 KB, free: 886.2 MB)
19/08/28 15:06:58 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1004
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 909
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 859
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1250
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1099
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 942
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 946
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1061
19/08/28 15:06:58 INFO ContextCleaner: Cleaned shuffle 9
19/08/28 15:06:58 INFO ContextCleaner: Cleaned accumulator 1264
19/08/28 15:06:58 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:58269 in memory (size: 9.3 KB, free: 886.2 MB)
19/08/28 15:06:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/08/28 15:06:59 INFO MemoryStore: MemoryStore cleared
19/08/28 15:06:59 INFO BlockManager: BlockManager stopped
19/08/28 15:06:59 INFO BlockManagerMaster: BlockManagerMaster stopped
19/08/28 15:06:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/08/28 15:06:59 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1937)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1936)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:06:59 INFO SparkContext: Successfully stopped SparkContext
19/08/28 15:06:59 INFO ShutdownHookManager: Shutdown hook called
19/08/28 15:06:59 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9
19/08/28 15:06:59 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356\userFiles-49993c9c-0a9b-402d-96b2-968173fe4ae9
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
19/08/28 15:06:59 INFO ShutdownHookManager: Deleting directory C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356
19/08/28 15:06:59 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356
java.io.IOException: Failed to delete: C:\Users\Donnet\AppData\Local\Temp\spark-edc9258f-864f-4ccd-be83-78153e43d356
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1031)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
