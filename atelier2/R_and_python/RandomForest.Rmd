---
title: "Random Forests"
author: "Pierre Navaro"
date: "`r Sys.Date()`"
output: 
  html_document:
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      cache = TRUE, 
                      warning = TRUE)

knitr::knit_engines$set(python = reticulate::eng_python)
#knitr::opts_chunk$set('python', engine.path = '/home/metienne/miniconda3/bin/python3')
```




Test de classification avec la méthode des Forêts aléatoires et
[scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).

L'exemple provient de
[A minimal benchmark for scalability, speed and accuracy of commonly used open source implementations (R packages, Python scikit-learn, H2O, xgboost, Spark MLlib etc.) of the top machine learning algorithms for binary classification (random forests, gradient boosted trees, deep neural networks etc.)](https://github.com/szilard/benchm-ml)

```{r}
library(reticulate)
use_python("/home/claire/Applications/python/conda/bin/python")
```

```{python}
<<<<<<< HEAD

=======
import sys
print(sys.version)
>>>>>>> 1ff1c471688033756764f0f799fa4215e2c18796
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
import time


d_train = pd.read_csv("http://s3.amazonaws.com/benchm-ml--main/train-0.1m.csv")
d_test = pd.read_csv("http://s3.amazonaws.com/benchm-ml--main/test.csv")
d_train_test = d_train.append(d_test)

vars_categ = ["Month","DayofMonth","DayOfWeek","UniqueCarrier", "Origin", "Dest"]
vars_num = ["DepTime","Distance"]

def get_dummies(d, col):
    dd = pd.get_dummies(d.loc[:, col])
    dd.columns = [col + "_%s" % c for c in dd.columns]
    return(dd)
```

```{python}
d_train.head()
```

```{python}
<<<<<<< HEAD
#%time
=======
>>>>>>> 1ff1c471688033756764f0f799fa4215e2c18796
X_train_test_categ = pd.concat([get_dummies(d_train_test, col) for col in vars_categ], axis = 1)
```


```{python}
X_train_test_categ.head()
```
<!-- <!-- ```{python} --> -->
<!-- <!-- print(RandomForestClassifier.__doc__) --> -->
<!-- <!-- ``` --> -->

<!-- ```{python} -->

<!-- X_train_test = pd.concat([X_train_test_categ, d_train_test.loc[:,vars_num]], axis = 1) -->
<!-- y_train_test = np.where(d_train_test["dep_delayed_15min"]=="Y", 1, 0) -->

<!-- n_obs = d_train.shape[0] -->

<!-- X_train = X_train_test[0:n_obs] -->
<!-- y_train = y_train_test[0:n_obs] -->
<!-- X_test = X_train_test[n_obs:] -->
<!-- y_test = y_train_test[n_obs:] -->

<<<<<<< HEAD
```{python}
# %time 
phat = md.predict_proba(X_test)[:,1]
metrics.roc_auc_score(y_test, phat)
```
=======
<!-- md = RandomForestClassifier(n_estimators = 100, -->
<!--                             n_jobs = 4) -->
<!-- start =  time.perf_counter() -->
<!-- md.fit(X_train, y_train) -->
<!-- end = time.perf_counter() -->
<!-- print('AUC: %.3f' %(end - start) ) -->
<!-- ``` -->

<!-- <!-- ```{python} --> 
<!-- <!-- start =  time.perf_counter() --> 
<!-- <!-- phat = md.predict_proba(X_test)[:,1] --> 
<!-- <!-- end = time.perf_counter() --> 
<!-- <!-- print('AUC: %.3f' %(end - start) ) --> 

<!-- <!-- auc = metrics.roc_auc_score(y_test, phat) --> -->
<!-- <!-- print('AUC: %.3f' % auc) --> -->

<!-- <!-- fpr, tpr, thresholds = metrics.roc_curve(y_test, phat) --> -->
<!-- <!-- pyplot.plot([0, 1], [0, 1], linestyle='--') --> -->
<!-- <!-- ``` --> -->
>>>>>>> 1ff1c471688033756764f0f799fa4215e2c18796
